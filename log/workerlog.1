/ssd3/sunting/anaconda3/envs/industry/lib/python3.7/site-packages/sklearn/utils/validation.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  LARGE_SPARSE_SUPPORTED = LooseVersion(scipy_version) >= '0.14.0'
/ssd3/sunting/anaconda3/envs/industry/lib/python3.7/site-packages/setuptools/_distutils/version.py:346: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  other = LooseVersion(other)
Warning: Unable to use numba in PP-Tracking, please install numba, for example(python3.7): `pip install numba==0.56.4`
Warning: Unable to use numba in PP-Tracking, please install numba, for example(python3.7): `pip install numba==0.56.4`
which: no nvcc in (/ssd3/sunting/anaconda3/envs/industry/bin:/ssd3/sunting/anaconda3/envs/industry/bin:/ssd3/sunting/anaconda3/condabin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/ssd3/sunting/bin:/usr/local/sbin:/usr/sbin:/opt/bin:/home/opt/bin:/ssd3/sunting/bin:/opt/bin:/home/opt/bin)
W0306 19:38:04.982383  3384 gpu_resources.cc:61] Please NOTE: device: 1, GPU Compute Capability: 7.0, Driver API Version: 11.7, Runtime API Version: 10.2
W0306 19:38:04.982457  3384 gpu_resources.cc:91] device: 1, cuDNN Version: 7.6.
I0306 19:38:08.653717  3384 tcp_utils.cc:107] Retry to connect to 10.9.189.6:41933 while the server is not yet listening.
I0306 19:38:11.653951  3384 tcp_utils.cc:130] Successfully connected to 10.9.189.6:41933
[2023-03-06 19:38:13,565] [    INFO] topology.py:187 - HybridParallelInfo: rank_id: 1, mp_degree: 1, sharding_degree: 1, pp_degree: 1, dp_degree: 2, mp_group: [1],  sharding_group: [1], pp_group: [1], dp_group: [0, 1], check/clip group: [1]


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   egr::Backward(std::vector<paddle::experimental::Tensor, std::allocator<paddle::experimental::Tensor> > const&, std::vector<paddle::experimental::Tensor, std::allocator<paddle::experimental::Tensor> > const&, bool)
1   egr::RunBackward(std::vector<paddle::experimental::Tensor, std::allocator<paddle::experimental::Tensor> > const&, std::vector<paddle::experimental::Tensor, std::allocator<paddle::experimental::Tensor> > const&, bool, bool, std::vector<paddle::experimental::Tensor, std::allocator<paddle::experimental::Tensor> > const&, bool, std::vector<paddle::experimental::Tensor, std::allocator<paddle::experimental::Tensor> > const&)
2   Conv2dGradNodeFinal::operator()(paddle::small_vector<std::vector<paddle::experimental::Tensor, std::allocator<paddle::experimental::Tensor> >, 15u>&, bool, bool)
3   paddle::experimental::conv2d_grad(paddle::experimental::Tensor const&, paddle::experimental::Tensor const&, paddle::experimental::Tensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, int, std::vector<int, std::allocator<int> > const&, std::string const&, bool, int, bool, paddle::experimental::Tensor*, paddle::experimental::Tensor*)
4   void phi::ConvCudnnGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, int, std::vector<int, std::allocator<int> > const&, std::string const&, bool, int, bool, phi::DenseTensor*, phi::DenseTensor*)
5   phi::DnnWorkspaceHandle::RunFunc(std::function<void (void*)> const&, unsigned long)
6   std::_Function_handler<void (void*), phi::ConvCudnnGradKernel<float, phi::GPUContext>(phi::GPUContext const&, phi::DenseTensor const&, phi::DenseTensor const&, phi::DenseTensor const&, std::vector<int, std::allocator<int> > const&, std::vector<int, std::allocator<int> > const&, std::string const&, int, std::vector<int, std::allocator<int> > const&, std::string const&, bool, int, bool, phi::DenseTensor*, phi::DenseTensor*)::{lambda(void*)#1}>::_M_invoke(std::_Any_data const&, void*&&)
7   cudnnConvolutionBackwardData

----------------------
Error Message Summary:
----------------------
FatalError: `Termination signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1678102805 (unix time) try "date -d @1678102805" if you are using GNU date ***]
  [SignalInfo: *** SIGTERM (@0x41400000cfc) received by PID 3384 (TID 0x7fca842ca700) from PID 3324 ***]

/ssd3/sunting/anaconda3/envs/industry/lib/python3.7/site-packages/sklearn/utils/validation.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  LARGE_SPARSE_SUPPORTED = LooseVersion(scipy_version) >= '0.14.0'
/ssd3/sunting/anaconda3/envs/industry/lib/python3.7/site-packages/setuptools/_distutils/version.py:346: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  other = LooseVersion(other)
Warning: Unable to use numba in PP-Tracking, please install numba, for example(python3.7): `pip install numba==0.56.4`
Warning: Unable to use numba in PP-Tracking, please install numba, for example(python3.7): `pip install numba==0.56.4`
which: no nvcc in (/ssd3/sunting/anaconda3/envs/industry/bin:/ssd3/sunting/anaconda3/envs/industry/bin:/ssd3/sunting/anaconda3/condabin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/ssd3/sunting/bin:/usr/local/sbin:/usr/sbin:/opt/bin:/home/opt/bin:/ssd3/sunting/bin:/opt/bin:/home/opt/bin)
W0306 19:40:53.167418 23873 gpu_resources.cc:61] Please NOTE: device: 1, GPU Compute Capability: 7.0, Driver API Version: 11.7, Runtime API Version: 10.2
W0306 19:40:53.167500 23873 gpu_resources.cc:91] device: 1, cuDNN Version: 7.6.
I0306 19:40:57.904001 23873 tcp_utils.cc:107] Retry to connect to 10.9.189.6:61668 while the server is not yet listening.
I0306 19:41:00.904317 23873 tcp_utils.cc:130] Successfully connected to 10.9.189.6:61668
[2023-03-06 19:41:02,845] [    INFO] topology.py:187 - HybridParallelInfo: rank_id: 1, mp_degree: 1, sharding_degree: 1, pp_degree: 1, dp_degree: 2, mp_group: [1],  sharding_group: [1], pp_group: [1], dp_group: [0, 1], check/clip group: [1]
