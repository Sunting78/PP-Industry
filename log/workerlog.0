/ssd3/sunting/anaconda3/envs/industry/bin/python3: can't open file 'tools/train.py': [Errno 2] No such file or directory
/ssd3/sunting/anaconda3/envs/industry/lib/python3.7/site-packages/sklearn/utils/validation.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  LARGE_SPARSE_SUPPORTED = LooseVersion(scipy_version) >= '0.14.0'
/ssd3/sunting/anaconda3/envs/industry/lib/python3.7/site-packages/setuptools/_distutils/version.py:346: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  other = LooseVersion(other)
Warning: Unable to use numba in PP-Tracking, please install numba, for example(python3.7): `pip install numba==0.56.4`
Warning: Unable to use numba in PP-Tracking, please install numba, for example(python3.7): `pip install numba==0.56.4`
which: no nvcc in (/ssd3/sunting/anaconda3/envs/industry/bin:/ssd3/sunting/anaconda3/envs/industry/bin:/ssd3/sunting/anaconda3/condabin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/ssd3/sunting/bin:/usr/local/sbin:/usr/sbin:/opt/bin:/home/opt/bin:/ssd3/sunting/bin:/opt/bin:/home/opt/bin)
2023-03-06 19:38:05 [INFO]	
------------Environment Information-------------
platform: Linux-3.10.0-1062.18.1.el7.x86_64-x86_64-with-centos-7.7.1908-Core
Python: 3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
Paddle compiled with cuda: True
NVCC: Cuda compilation tools, release 10.2, V10.2.89
cudnn: 7.6
GPUs used: 2
CUDA_VISIBLE_DEVICES: 0,1
GPU: ['GPU 0: Tesla V100-SXM2-16GB', 'GPU 1: Tesla V100-SXM2-16GB', 'GPU 2: Tesla V100-SXM2-16GB', 'GPU 3: Tesla V100-SXM2-16GB', 'GPU 4: Tesla V100-SXM2-16GB', 'GPU 5: Tesla V100-SXM2-16GB', 'GPU 6: Tesla V100-SXM2-16GB', 'GPU 7: Tesla V100-SXM2-16GB']
GCC: gcc (GCC) 8.2.0
PaddleSeg: 2.7.0
PaddlePaddle: 2.4.1
OpenCV: 4.5.5
------------------------------------------------
2023-03-06 19:38:05 [INFO]	
---------------Config Information---------------
batch_size: 8
iters: 160000
loss:
  coef:
  - 1
  - 0.4
  types:
  - ignore_index: 255
    type: CrossEntropyLoss
  - ignore_index: 255
    type: CrossEntropyLoss
lr_scheduler:
  end_lr: 0
  learning_rate: 0.01
  power: 0.9
  type: PolynomialDecay
model:
  backbone:
    in_channels: 3
    pretrained: https://bj.bcebos.com/paddleseg/dygraph/hrnet_w18_ssld.tar.gz
    type: HRNet_W18
  backbone_indices:
  - 0
  num_classes: 2
  type: OCRNet
optimizer:
  momentum: 0.9
  type: sgd
  weight_decay: 4.0e-05
train_dataset:
  dataset_root: dataset/kolektor2/ROI/
  img_channels: 3
  mode: train
  num_classes: 2
  train_path: dataset/kolektor2/ROI/train.txt
  transforms:
  - max_scale_factor: 2.5
    min_scale_factor: 0.5
    scale_step_size: 0.25
    type: ResizeStepScaling
  - crop_size:
    - 60
    - 60
    type: RandomPaddingCrop
  - type: RandomHorizontalFlip
  - brightness_range: 0.5
    contrast_range: 0.5
    saturation_range: 0.5
    type: RandomDistort
  - type: Normalize
  type: Dataset
val_dataset:
  dataset_root: dataset/kolektor2/ROI/
  img_channels: 3
  mode: val
  num_classes: 2
  transforms:
  - type: Normalize
  type: Dataset
  val_path: dataset/kolektor2/ROI/val.txt
------------------------------------------------
W0306 19:38:05.366168  3382 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.7, Runtime API Version: 10.2
W0306 19:38:05.366219  3382 gpu_resources.cc:91] device: 0, cuDNN Version: 7.6.
2023-03-06 19:38:08 [INFO]	Loading pretrained model from https://bj.bcebos.com/paddleseg/dygraph/hrnet_w18_ssld.tar.gz
2023-03-06 19:38:09 [INFO]	There are 1525/1525 variables loaded into HRNet.
I0306 19:38:09.957808  3382 tcp_utils.cc:181] The server starts to listen on IP_ANY:41933
I0306 19:38:09.958654  3382 tcp_utils.cc:130] Successfully connected to 10.9.189.6:41933
[2023-03-06 19:38:14,805] [    INFO] topology.py:187 - HybridParallelInfo: rank_id: 0, mp_degree: 1, sharding_degree: 1, pp_degree: 1, dp_degree: 2, mp_group: [0],  sharding_group: [0], pp_group: [0], dp_group: [0, 1], check/clip group: [0]
2023-03-06 19:38:19 [INFO]	[TRAIN] epoch: 1, iter: 10/160000, loss: 0.7563, lr: 0.009999, batch_cost: 0.4588, reader_cost: 0.07643, ips: 17.4365 samples/sec | ETA 20:23:24
2023-03-06 19:38:22 [INFO]	[TRAIN] epoch: 2, iter: 20/160000, loss: 0.8728, lr: 0.009999, batch_cost: 0.2704, reader_cost: 0.03712, ips: 29.5812 samples/sec | ETA 12:01:05
2023-03-06 19:38:24 [INFO]	[TRAIN] epoch: 2, iter: 30/160000, loss: 0.6996, lr: 0.009998, batch_cost: 0.1992, reader_cost: 0.00028, ips: 40.1586 samples/sec | ETA 08:51:07
2023-03-06 19:38:27 [INFO]	[TRAIN] epoch: 3, iter: 40/160000, loss: 0.5943, lr: 0.009998, batch_cost: 0.2720, reader_cost: 0.04315, ips: 29.4116 samples/sec | ETA 12:05:09
2023-03-06 19:38:29 [INFO]	[TRAIN] epoch: 3, iter: 50/160000, loss: 0.5833, lr: 0.009997, batch_cost: 0.1919, reader_cost: 0.00027, ips: 41.6861 samples/sec | ETA 08:31:36
2023-03-06 19:38:31 [INFO]	[TRAIN] epoch: 4, iter: 60/160000, loss: 0.5811, lr: 0.009997, batch_cost: 0.2585, reader_cost: 0.05711, ips: 30.9534 samples/sec | ETA 11:28:56
2023-03-06 19:38:34 [INFO]	[TRAIN] epoch: 5, iter: 70/160000, loss: 0.5493, lr: 0.009996, batch_cost: 0.2510, reader_cost: 0.03170, ips: 31.8683 samples/sec | ETA 11:09:07
2023-03-06 19:38:36 [INFO]	[TRAIN] epoch: 5, iter: 80/160000, loss: 0.5005, lr: 0.009996, batch_cost: 0.1870, reader_cost: 0.00029, ips: 42.7741 samples/sec | ETA 08:18:29
2023-03-06 19:38:38 [INFO]	[TRAIN] epoch: 6, iter: 90/160000, loss: 0.3812, lr: 0.009995, batch_cost: 0.2503, reader_cost: 0.03688, ips: 31.9638 samples/sec | ETA 11:07:02
2023-03-06 19:38:40 [INFO]	[TRAIN] epoch: 6, iter: 100/160000, loss: 0.6030, lr: 0.009994, batch_cost: 0.1976, reader_cost: 0.00030, ips: 40.4937 samples/sec | ETA 08:46:30
2023-03-06 19:38:43 [INFO]	[TRAIN] epoch: 7, iter: 110/160000, loss: 0.4896, lr: 0.009994, batch_cost: 0.2742, reader_cost: 0.04597, ips: 29.1751 samples/sec | ETA 12:10:42
2023-03-06 19:38:46 [INFO]	[TRAIN] epoch: 8, iter: 120/160000, loss: 0.4685, lr: 0.009993, batch_cost: 0.2740, reader_cost: 0.04658, ips: 29.2008 samples/sec | ETA 12:10:01
2023-03-06 19:38:48 [INFO]	[TRAIN] epoch: 8, iter: 130/160000, loss: 0.5869, lr: 0.009993, batch_cost: 0.1961, reader_cost: 0.00033, ips: 40.8039 samples/sec | ETA 08:42:24
2023-03-06 19:38:51 [INFO]	[TRAIN] epoch: 9, iter: 140/160000, loss: 0.4283, lr: 0.009992, batch_cost: 0.2967, reader_cost: 0.04501, ips: 26.9601 samples/sec | ETA 13:10:36
2023-03-06 19:38:54 [INFO]	[TRAIN] epoch: 9, iter: 150/160000, loss: 0.4117, lr: 0.009992, batch_cost: 0.3009, reader_cost: 0.00061, ips: 26.5837 samples/sec | ETA 13:21:44
2023-03-06 19:38:56 [INFO]	[TRAIN] epoch: 10, iter: 160/160000, loss: 0.4155, lr: 0.009991, batch_cost: 0.2912, reader_cost: 0.05598, ips: 27.4700 samples/sec | ETA 12:55:49
2023-03-06 19:38:59 [INFO]	[TRAIN] epoch: 10, iter: 170/160000, loss: 0.4775, lr: 0.009990, batch_cost: 0.2126, reader_cost: 0.00028, ips: 37.6260 samples/sec | ETA 09:26:22
2023-03-06 19:39:03 [INFO]	[TRAIN] epoch: 11, iter: 180/160000, loss: 0.5049, lr: 0.009990, batch_cost: 0.4192, reader_cost: 0.04483, ips: 19.0819 samples/sec | ETA 18:36:43
2023-03-06 19:39:06 [INFO]	[TRAIN] epoch: 12, iter: 190/160000, loss: 0.4499, lr: 0.009989, batch_cost: 0.3370, reader_cost: 0.06450, ips: 23.7410 samples/sec | ETA 14:57:31
2023-03-06 19:39:09 [INFO]	[TRAIN] epoch: 12, iter: 200/160000, loss: 0.4810, lr: 0.009989, batch_cost: 0.3199, reader_cost: 0.00035, ips: 25.0102 samples/sec | ETA 14:11:55
2023-03-06 19:39:13 [INFO]	[TRAIN] epoch: 13, iter: 210/160000, loss: 0.4354, lr: 0.009988, batch_cost: 0.3544, reader_cost: 0.05535, ips: 22.5752 samples/sec | ETA 15:43:45
2023-03-06 19:39:16 [INFO]	[TRAIN] epoch: 13, iter: 220/160000, loss: 0.5123, lr: 0.009988, batch_cost: 0.2975, reader_cost: 0.00028, ips: 26.8949 samples/sec | ETA 13:12:07
2023-03-06 19:39:21 [INFO]	[TRAIN] epoch: 14, iter: 230/160000, loss: 0.4339, lr: 0.009987, batch_cost: 0.4651, reader_cost: 0.05773, ips: 17.1994 samples/sec | ETA 20:38:34
2023-03-06 19:39:25 [INFO]	[TRAIN] epoch: 15, iter: 240/160000, loss: 0.3419, lr: 0.009987, batch_cost: 0.4049, reader_cost: 0.04946, ips: 19.7599 samples/sec | ETA 17:58:00
2023-03-06 19:39:27 [INFO]	[TRAIN] epoch: 15, iter: 250/160000, loss: 0.3522, lr: 0.009986, batch_cost: 0.2175, reader_cost: 0.00035, ips: 36.7855 samples/sec | ETA 09:39:01
2023-03-06 19:39:30 [INFO]	[TRAIN] epoch: 16, iter: 260/160000, loss: 0.3701, lr: 0.009985, batch_cost: 0.2862, reader_cost: 0.05661, ips: 27.9565 samples/sec | ETA 12:41:50
2023-03-06 19:39:32 [INFO]	[TRAIN] epoch: 16, iter: 270/160000, loss: 0.3846, lr: 0.009985, batch_cost: 0.2591, reader_cost: 0.00031, ips: 30.8793 samples/sec | ETA 11:29:41
2023-03-06 19:39:36 [INFO]	[TRAIN] epoch: 17, iter: 280/160000, loss: 0.4167, lr: 0.009984, batch_cost: 0.3927, reader_cost: 0.05311, ips: 20.3717 samples/sec | ETA 17:25:22
2023-03-06 19:39:40 [INFO]	[TRAIN] epoch: 18, iter: 290/160000, loss: 0.4199, lr: 0.009984, batch_cost: 0.3726, reader_cost: 0.05709, ips: 21.4708 samples/sec | ETA 16:31:47
2023-03-06 19:39:43 [INFO]	[TRAIN] epoch: 18, iter: 300/160000, loss: 0.4042, lr: 0.009983, batch_cost: 0.3227, reader_cost: 0.00054, ips: 24.7876 samples/sec | ETA 14:19:01
2023-03-06 19:39:46 [INFO]	[TRAIN] epoch: 19, iter: 310/160000, loss: 0.5958, lr: 0.009983, batch_cost: 0.3144, reader_cost: 0.04400, ips: 25.4473 samples/sec | ETA 13:56:42
2023-03-06 19:39:49 [INFO]	[TRAIN] epoch: 19, iter: 320/160000, loss: 0.4007, lr: 0.009982, batch_cost: 0.2955, reader_cost: 0.00038, ips: 27.0711 samples/sec | ETA 13:06:28
2023-03-06 19:39:53 [INFO]	[TRAIN] epoch: 20, iter: 330/160000, loss: 0.4102, lr: 0.009981, batch_cost: 0.3608, reader_cost: 0.06247, ips: 22.1749 samples/sec | ETA 16:00:03
2023-03-06 19:39:56 [INFO]	[TRAIN] epoch: 20, iter: 340/160000, loss: 0.3627, lr: 0.009981, batch_cost: 0.2985, reader_cost: 0.00041, ips: 26.7999 samples/sec | ETA 13:14:19
2023-03-06 19:40:00 [INFO]	[TRAIN] epoch: 21, iter: 350/160000, loss: 0.4759, lr: 0.009980, batch_cost: 0.4397, reader_cost: 0.08382, ips: 18.1960 samples/sec | ETA 19:29:51
2023-03-06 19:40:04 [INFO]	[TRAIN] epoch: 22, iter: 360/160000, loss: 0.5441, lr: 0.009980, batch_cost: 0.3893, reader_cost: 0.04425, ips: 20.5474 samples/sec | ETA 17:15:54


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   conv2d_ad_func(paddle::experimental::Tensor const&, paddle::experimental::Tensor const&, std::vector<int, std::allocator<int> >, std::vector<int, std::allocator<int> >, std::string, int, std::vector<int, std::allocator<int> >, std::string, bool, int, bool)
1   phi::backends::gpu::TensorCoreAvailable()
2   phi::backends::gpu::GetCurrentDeviceId()

----------------------
Error Message Summary:
----------------------
FatalError: `Termination signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1678102804 (unix time) try "date -d @1678102804" if you are using GNU date ***]
  [SignalInfo: *** SIGTERM (@0x41400000cfc) received by PID 3382 (TID 0x7f0875cf4700) from PID 3324 ***]

/ssd3/sunting/anaconda3/envs/industry/lib/python3.7/site-packages/sklearn/utils/validation.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  LARGE_SPARSE_SUPPORTED = LooseVersion(scipy_version) >= '0.14.0'
/ssd3/sunting/anaconda3/envs/industry/lib/python3.7/site-packages/setuptools/_distutils/version.py:346: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  other = LooseVersion(other)
Warning: Unable to use numba in PP-Tracking, please install numba, for example(python3.7): `pip install numba==0.56.4`
Warning: Unable to use numba in PP-Tracking, please install numba, for example(python3.7): `pip install numba==0.56.4`
which: no nvcc in (/ssd3/sunting/anaconda3/envs/industry/bin:/ssd3/sunting/anaconda3/envs/industry/bin:/ssd3/sunting/anaconda3/condabin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/ssd3/sunting/bin:/usr/local/sbin:/usr/sbin:/opt/bin:/home/opt/bin:/ssd3/sunting/bin:/opt/bin:/home/opt/bin)
2023-03-06 19:40:53 [INFO]	
------------Environment Information-------------
platform: Linux-3.10.0-1062.18.1.el7.x86_64-x86_64-with-centos-7.7.1908-Core
Python: 3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
Paddle compiled with cuda: True
NVCC: Cuda compilation tools, release 10.2, V10.2.89
cudnn: 7.6
GPUs used: 2
CUDA_VISIBLE_DEVICES: 6,7
GPU: ['GPU 0: Tesla V100-SXM2-16GB', 'GPU 1: Tesla V100-SXM2-16GB', 'GPU 2: Tesla V100-SXM2-16GB', 'GPU 3: Tesla V100-SXM2-16GB', 'GPU 4: Tesla V100-SXM2-16GB', 'GPU 5: Tesla V100-SXM2-16GB', 'GPU 6: Tesla V100-SXM2-16GB', 'GPU 7: Tesla V100-SXM2-16GB']
GCC: gcc (GCC) 8.2.0
PaddleSeg: 2.7.0
PaddlePaddle: 2.4.1
OpenCV: 4.5.5
------------------------------------------------
2023-03-06 19:40:53 [INFO]	
---------------Config Information---------------
batch_size: 8
iters: 16000
loss:
  coef:
  - 1
  - 0.4
  types:
  - ignore_index: 255
    type: CrossEntropyLoss
  - ignore_index: 255
    type: CrossEntropyLoss
lr_scheduler:
  end_lr: 0
  learning_rate: 0.01
  power: 0.9
  type: PolynomialDecay
model:
  backbone:
    in_channels: 3
    pretrained: https://bj.bcebos.com/paddleseg/dygraph/hrnet_w18_ssld.tar.gz
    type: HRNet_W18
  backbone_indices:
  - 0
  num_classes: 2
  type: OCRNet
optimizer:
  momentum: 0.9
  type: sgd
  weight_decay: 4.0e-05
train_dataset:
  dataset_root: dataset/kolektor2/ROI/
  img_channels: 3
  mode: train
  num_classes: 2
  train_path: dataset/kolektor2/ROI/train.txt
  transforms:
  - max_scale_factor: 2.5
    min_scale_factor: 0.5
    scale_step_size: 0.25
    type: ResizeStepScaling
  - crop_size:
    - 60
    - 60
    type: RandomPaddingCrop
  - type: RandomHorizontalFlip
  - brightness_range: 0.5
    contrast_range: 0.5
    saturation_range: 0.5
    type: RandomDistort
  - type: Normalize
  type: Dataset
val_dataset:
  dataset_root: dataset/kolektor2/ROI/
  img_channels: 3
  mode: val
  num_classes: 2
  transforms:
  - type: Normalize
  type: Dataset
  val_path: dataset/kolektor2/ROI/val.txt
------------------------------------------------
W0306 19:40:53.236357 23870 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.7, Runtime API Version: 10.2
W0306 19:40:53.236439 23870 gpu_resources.cc:91] device: 0, cuDNN Version: 7.6.
2023-03-06 19:40:56 [INFO]	Loading pretrained model from https://bj.bcebos.com/paddleseg/dygraph/hrnet_w18_ssld.tar.gz
2023-03-06 19:40:58 [INFO]	There are 1525/1525 variables loaded into HRNet.
I0306 19:40:58.586339 23870 tcp_utils.cc:181] The server starts to listen on IP_ANY:61668
I0306 19:40:58.586611 23870 tcp_utils.cc:130] Successfully connected to 10.9.189.6:61668
[2023-03-06 19:41:04,091] [    INFO] topology.py:187 - HybridParallelInfo: rank_id: 0, mp_degree: 1, sharding_degree: 1, pp_degree: 1, dp_degree: 2, mp_group: [0],  sharding_group: [0], pp_group: [0], dp_group: [0, 1], check/clip group: [0]
2023-03-06 19:41:09 [INFO]	[TRAIN] epoch: 1, iter: 10/16000, loss: 0.7206, lr: 0.009995, batch_cost: 0.4955, reader_cost: 0.09250, ips: 16.1466 samples/sec | ETA 02:12:02
2023-03-06 19:41:12 [INFO]	[TRAIN] epoch: 2, iter: 20/16000, loss: 0.7963, lr: 0.009989, batch_cost: 0.2876, reader_cost: 0.04845, ips: 27.8150 samples/sec | ETA 01:16:36
2023-03-06 19:41:14 [INFO]	[TRAIN] epoch: 2, iter: 30/16000, loss: 0.5503, lr: 0.009984, batch_cost: 0.2098, reader_cost: 0.00521, ips: 38.1314 samples/sec | ETA 00:55:50
2023-03-06 19:41:17 [INFO]	[TRAIN] epoch: 3, iter: 40/16000, loss: 0.5738, lr: 0.009978, batch_cost: 0.2707, reader_cost: 0.05338, ips: 29.5511 samples/sec | ETA 01:12:00
2023-03-06 19:41:19 [INFO]	[TRAIN] epoch: 3, iter: 50/16000, loss: 0.5514, lr: 0.009972, batch_cost: 0.2071, reader_cost: 0.00027, ips: 38.6339 samples/sec | ETA 00:55:02
2023-03-06 19:41:22 [INFO]	[TRAIN] epoch: 4, iter: 60/16000, loss: 0.4207, lr: 0.009967, batch_cost: 0.2929, reader_cost: 0.03984, ips: 27.3170 samples/sec | ETA 01:17:48
2023-03-06 19:41:24 [INFO]	[TRAIN] epoch: 5, iter: 70/16000, loss: 0.4084, lr: 0.009961, batch_cost: 0.2564, reader_cost: 0.04510, ips: 31.2058 samples/sec | ETA 01:08:03
2023-03-06 19:41:27 [INFO]	[TRAIN] epoch: 5, iter: 80/16000, loss: 0.5600, lr: 0.009956, batch_cost: 0.2268, reader_cost: 0.00033, ips: 35.2762 samples/sec | ETA 01:00:10
2023-03-06 19:41:29 [INFO]	[TRAIN] epoch: 6, iter: 90/16000, loss: 0.4303, lr: 0.009950, batch_cost: 0.2670, reader_cost: 0.03724, ips: 29.9608 samples/sec | ETA 01:10:48
2023-03-06 19:41:31 [INFO]	[TRAIN] epoch: 6, iter: 100/16000, loss: 0.4227, lr: 0.009944, batch_cost: 0.2181, reader_cost: 0.00030, ips: 36.6845 samples/sec | ETA 00:57:47
2023-03-06 19:41:34 [INFO]	[TRAIN] epoch: 7, iter: 110/16000, loss: 0.4873, lr: 0.009939, batch_cost: 0.2757, reader_cost: 0.03747, ips: 29.0146 samples/sec | ETA 01:13:01
2023-03-06 19:41:37 [INFO]	[TRAIN] epoch: 8, iter: 120/16000, loss: 0.4314, lr: 0.009933, batch_cost: 0.2684, reader_cost: 0.04749, ips: 29.8052 samples/sec | ETA 01:11:02
2023-03-06 19:41:39 [INFO]	[TRAIN] epoch: 8, iter: 130/16000, loss: 0.3660, lr: 0.009927, batch_cost: 0.2336, reader_cost: 0.00031, ips: 34.2521 samples/sec | ETA 01:01:46
2023-03-06 19:41:42 [INFO]	[TRAIN] epoch: 9, iter: 140/16000, loss: 0.4820, lr: 0.009922, batch_cost: 0.2846, reader_cost: 0.03943, ips: 28.1049 samples/sec | ETA 01:15:14
2023-03-06 19:41:44 [INFO]	[TRAIN] epoch: 9, iter: 150/16000, loss: 0.4895, lr: 0.009916, batch_cost: 0.1947, reader_cost: 0.00031, ips: 41.0930 samples/sec | ETA 00:51:25
2023-03-06 19:41:46 [INFO]	[TRAIN] epoch: 10, iter: 160/16000, loss: 0.4014, lr: 0.009911, batch_cost: 0.2458, reader_cost: 0.03547, ips: 32.5423 samples/sec | ETA 01:04:54
2023-03-06 19:41:48 [INFO]	[TRAIN] epoch: 10, iter: 170/16000, loss: 0.4465, lr: 0.009905, batch_cost: 0.1929, reader_cost: 0.00262, ips: 41.4763 samples/sec | ETA 00:50:53
2023-03-06 19:41:51 [INFO]	[TRAIN] epoch: 11, iter: 180/16000, loss: 0.3868, lr: 0.009899, batch_cost: 0.2436, reader_cost: 0.04076, ips: 32.8419 samples/sec | ETA 01:04:13
2023-03-06 19:41:53 [INFO]	[TRAIN] epoch: 12, iter: 190/16000, loss: 0.4087, lr: 0.009894, batch_cost: 0.2502, reader_cost: 0.04231, ips: 31.9752 samples/sec | ETA 01:05:55
2023-03-06 19:41:55 [INFO]	[TRAIN] epoch: 12, iter: 200/16000, loss: 0.4076, lr: 0.009888, batch_cost: 0.1898, reader_cost: 0.00031, ips: 42.1563 samples/sec | ETA 00:49:58
2023-03-06 19:41:58 [INFO]	[TRAIN] epoch: 13, iter: 210/16000, loss: 0.4760, lr: 0.009882, batch_cost: 0.2419, reader_cost: 0.04198, ips: 33.0681 samples/sec | ETA 01:03:40
2023-03-06 19:42:00 [INFO]	[TRAIN] epoch: 13, iter: 220/16000, loss: 0.3761, lr: 0.009877, batch_cost: 0.1904, reader_cost: 0.00028, ips: 42.0269 samples/sec | ETA 00:50:03
2023-03-06 19:42:02 [INFO]	[TRAIN] epoch: 14, iter: 230/16000, loss: 0.3799, lr: 0.009871, batch_cost: 0.2420, reader_cost: 0.03932, ips: 33.0596 samples/sec | ETA 01:03:36
2023-03-06 19:42:05 [INFO]	[TRAIN] epoch: 15, iter: 240/16000, loss: 0.4527, lr: 0.009865, batch_cost: 0.2890, reader_cost: 0.07566, ips: 27.6840 samples/sec | ETA 01:15:54
2023-03-06 19:42:07 [INFO]	[TRAIN] epoch: 15, iter: 250/16000, loss: 0.3899, lr: 0.009860, batch_cost: 0.2236, reader_cost: 0.00030, ips: 35.7714 samples/sec | ETA 00:58:42
2023-03-06 19:42:10 [INFO]	[TRAIN] epoch: 16, iter: 260/16000, loss: 0.3540, lr: 0.009854, batch_cost: 0.2728, reader_cost: 0.04862, ips: 29.3248 samples/sec | ETA 01:11:33
2023-03-06 19:42:12 [INFO]	[TRAIN] epoch: 16, iter: 270/16000, loss: 0.4996, lr: 0.009849, batch_cost: 0.1918, reader_cost: 0.00031, ips: 41.7085 samples/sec | ETA 00:50:17
2023-03-06 19:42:14 [INFO]	[TRAIN] epoch: 17, iter: 280/16000, loss: 0.3528, lr: 0.009843, batch_cost: 0.2598, reader_cost: 0.04525, ips: 30.7876 samples/sec | ETA 01:08:04
2023-03-06 19:42:17 [INFO]	[TRAIN] epoch: 18, iter: 290/16000, loss: 0.4646, lr: 0.009837, batch_cost: 0.2648, reader_cost: 0.05173, ips: 30.2090 samples/sec | ETA 01:09:20
2023-03-06 19:42:19 [INFO]	[TRAIN] epoch: 18, iter: 300/16000, loss: 0.3779, lr: 0.009832, batch_cost: 0.2015, reader_cost: 0.00029, ips: 39.6973 samples/sec | ETA 00:52:43
2023-03-06 19:42:22 [INFO]	[TRAIN] epoch: 19, iter: 310/16000, loss: 0.4658, lr: 0.009826, batch_cost: 0.2731, reader_cost: 0.04233, ips: 29.2947 samples/sec | ETA 01:11:24
2023-03-06 19:42:24 [INFO]	[TRAIN] epoch: 19, iter: 320/16000, loss: 0.3014, lr: 0.009820, batch_cost: 0.2243, reader_cost: 0.00032, ips: 35.6669 samples/sec | ETA 00:58:36
2023-03-06 19:42:27 [INFO]	[TRAIN] epoch: 20, iter: 330/16000, loss: 0.5205, lr: 0.009815, batch_cost: 0.2647, reader_cost: 0.04138, ips: 30.2242 samples/sec | ETA 01:09:07
2023-03-06 19:42:29 [INFO]	[TRAIN] epoch: 20, iter: 340/16000, loss: 0.4137, lr: 0.009809, batch_cost: 0.2057, reader_cost: 0.00026, ips: 38.8826 samples/sec | ETA 00:53:42
2023-03-06 19:42:31 [INFO]	[TRAIN] epoch: 21, iter: 350/16000, loss: 0.3447, lr: 0.009803, batch_cost: 0.2575, reader_cost: 0.04542, ips: 31.0693 samples/sec | ETA 01:07:09
2023-03-06 19:42:34 [INFO]	[TRAIN] epoch: 22, iter: 360/16000, loss: 0.3664, lr: 0.009798, batch_cost: 0.2821, reader_cost: 0.04354, ips: 28.3583 samples/sec | ETA 01:13:32
2023-03-06 19:42:38 [INFO]	[TRAIN] epoch: 22, iter: 370/16000, loss: 0.2959, lr: 0.009792, batch_cost: 0.3445, reader_cost: 0.00046, ips: 23.2204 samples/sec | ETA 01:29:44
2023-03-06 19:42:41 [INFO]	[TRAIN] epoch: 23, iter: 380/16000, loss: 0.2915, lr: 0.009787, batch_cost: 0.3826, reader_cost: 0.07776, ips: 20.9074 samples/sec | ETA 01:39:36
2023-03-06 19:42:45 [INFO]	[TRAIN] epoch: 23, iter: 390/16000, loss: 0.4513, lr: 0.009781, batch_cost: 0.3479, reader_cost: 0.00032, ips: 22.9929 samples/sec | ETA 01:30:31
2023-03-06 19:42:48 [INFO]	[TRAIN] epoch: 24, iter: 400/16000, loss: 0.4463, lr: 0.009775, batch_cost: 0.3345, reader_cost: 0.06826, ips: 23.9146 samples/sec | ETA 01:26:58
2023-03-06 19:42:52 [INFO]	[TRAIN] epoch: 25, iter: 410/16000, loss: 0.3418, lr: 0.009770, batch_cost: 0.3675, reader_cost: 0.07109, ips: 21.7710 samples/sec | ETA 01:35:28
2023-03-06 19:42:55 [INFO]	[TRAIN] epoch: 25, iter: 420/16000, loss: 0.4603, lr: 0.009764, batch_cost: 0.3262, reader_cost: 0.00034, ips: 24.5237 samples/sec | ETA 01:24:42
2023-03-06 19:42:59 [INFO]	[TRAIN] epoch: 26, iter: 430/16000, loss: 0.2887, lr: 0.009758, batch_cost: 0.3786, reader_cost: 0.05860, ips: 21.1330 samples/sec | ETA 01:38:14
2023-03-06 19:43:02 [INFO]	[TRAIN] epoch: 26, iter: 440/16000, loss: 0.4305, lr: 0.009753, batch_cost: 0.3140, reader_cost: 0.00033, ips: 25.4809 samples/sec | ETA 01:21:25
2023-03-06 19:43:06 [INFO]	[TRAIN] epoch: 27, iter: 450/16000, loss: 0.3679, lr: 0.009747, batch_cost: 0.3571, reader_cost: 0.05515, ips: 22.4045 samples/sec | ETA 01:32:32
2023-03-06 19:43:09 [INFO]	[TRAIN] epoch: 28, iter: 460/16000, loss: 0.3959, lr: 0.009741, batch_cost: 0.3178, reader_cost: 0.05572, ips: 25.1760 samples/sec | ETA 01:22:18
2023-03-06 19:43:11 [INFO]	[TRAIN] epoch: 28, iter: 470/16000, loss: 0.3875, lr: 0.009736, batch_cost: 0.2505, reader_cost: 0.00043, ips: 31.9357 samples/sec | ETA 01:04:50
2023-03-06 19:43:15 [INFO]	[TRAIN] epoch: 29, iter: 480/16000, loss: 0.3405, lr: 0.009730, batch_cost: 0.3971, reader_cost: 0.05997, ips: 20.1441 samples/sec | ETA 01:42:43
2023-03-06 19:43:18 [INFO]	[TRAIN] epoch: 29, iter: 490/16000, loss: 0.3738, lr: 0.009725, batch_cost: 0.2828, reader_cost: 0.00033, ips: 28.2842 samples/sec | ETA 01:13:06
2023-03-06 19:43:22 [INFO]	[TRAIN] epoch: 30, iter: 500/16000, loss: 0.3995, lr: 0.009719, batch_cost: 0.3746, reader_cost: 0.04406, ips: 21.3533 samples/sec | ETA 01:36:47
2023-03-06 19:43:24 [INFO]	[TRAIN] epoch: 30, iter: 510/16000, loss: 0.4258, lr: 0.009713, batch_cost: 0.2450, reader_cost: 0.00030, ips: 32.6561 samples/sec | ETA 01:03:14
2023-03-06 19:43:28 [INFO]	[TRAIN] epoch: 31, iter: 520/16000, loss: 0.3811, lr: 0.009708, batch_cost: 0.3896, reader_cost: 0.04933, ips: 20.5326 samples/sec | ETA 01:40:31
2023-03-06 19:43:33 [INFO]	[TRAIN] epoch: 32, iter: 530/16000, loss: 0.3529, lr: 0.009702, batch_cost: 0.4490, reader_cost: 0.07308, ips: 17.8188 samples/sec | ETA 01:55:45
2023-03-06 19:43:36 [INFO]	[TRAIN] epoch: 32, iter: 540/16000, loss: 0.3748, lr: 0.009696, batch_cost: 0.3396, reader_cost: 0.00060, ips: 23.5576 samples/sec | ETA 01:27:30
2023-03-06 19:43:40 [INFO]	[TRAIN] epoch: 33, iter: 550/16000, loss: 0.4454, lr: 0.009691, batch_cost: 0.3960, reader_cost: 0.04269, ips: 20.2032 samples/sec | ETA 01:41:57
2023-03-06 19:43:43 [INFO]	[TRAIN] epoch: 33, iter: 560/16000, loss: 0.3360, lr: 0.009685, batch_cost: 0.2765, reader_cost: 0.00035, ips: 28.9346 samples/sec | ETA 01:11:08
2023-03-06 19:43:47 [INFO]	[TRAIN] epoch: 34, iter: 570/16000, loss: 0.4372, lr: 0.009679, batch_cost: 0.4531, reader_cost: 0.04779, ips: 17.6560 samples/sec | ETA 01:56:31
2023-03-06 19:43:51 [INFO]	[TRAIN] epoch: 35, iter: 580/16000, loss: 0.3383, lr: 0.009674, batch_cost: 0.3557, reader_cost: 0.06090, ips: 22.4889 samples/sec | ETA 01:31:25
2023-03-06 19:43:54 [INFO]	[TRAIN] epoch: 35, iter: 590/16000, loss: 0.4268, lr: 0.009668, batch_cost: 0.3313, reader_cost: 0.00091, ips: 24.1508 samples/sec | ETA 01:25:04
2023-03-06 19:43:58 [INFO]	[TRAIN] epoch: 36, iter: 600/16000, loss: 0.3083, lr: 0.009662, batch_cost: 0.3525, reader_cost: 0.06365, ips: 22.6961 samples/sec | ETA 01:30:28
2023-03-06 19:44:00 [INFO]	[TRAIN] epoch: 36, iter: 610/16000, loss: 0.3243, lr: 0.009657, batch_cost: 0.2613, reader_cost: 0.00035, ips: 30.6132 samples/sec | ETA 01:07:01
2023-03-06 19:44:04 [INFO]	[TRAIN] epoch: 37, iter: 620/16000, loss: 0.3884, lr: 0.009651, batch_cost: 0.3225, reader_cost: 0.04755, ips: 24.8079 samples/sec | ETA 01:22:39
2023-03-06 19:44:06 [INFO]	[TRAIN] epoch: 38, iter: 630/16000, loss: 0.3246, lr: 0.009645, batch_cost: 0.2907, reader_cost: 0.04934, ips: 27.5201 samples/sec | ETA 01:14:28
2023-03-06 19:44:10 [INFO]	[TRAIN] epoch: 38, iter: 640/16000, loss: 0.3362, lr: 0.009640, batch_cost: 0.3158, reader_cost: 0.00062, ips: 25.3331 samples/sec | ETA 01:20:50
2023-03-06 19:44:13 [INFO]	[TRAIN] epoch: 39, iter: 650/16000, loss: 0.3084, lr: 0.009634, batch_cost: 0.3459, reader_cost: 0.06888, ips: 23.1277 samples/sec | ETA 01:28:29
2023-03-06 19:44:15 [INFO]	[TRAIN] epoch: 39, iter: 660/16000, loss: 0.3246, lr: 0.009629, batch_cost: 0.2241, reader_cost: 0.00037, ips: 35.7061 samples/sec | ETA 00:57:16
2023-03-06 19:44:19 [INFO]	[TRAIN] epoch: 40, iter: 670/16000, loss: 0.3309, lr: 0.009623, batch_cost: 0.3333, reader_cost: 0.05628, ips: 24.0003 samples/sec | ETA 01:25:09
2023-03-06 19:44:21 [INFO]	[TRAIN] epoch: 40, iter: 680/16000, loss: 0.3979, lr: 0.009617, batch_cost: 0.2807, reader_cost: 0.00031, ips: 28.4951 samples/sec | ETA 01:11:41
2023-03-06 19:44:25 [INFO]	[TRAIN] epoch: 41, iter: 690/16000, loss: 0.3243, lr: 0.009612, batch_cost: 0.3948, reader_cost: 0.06323, ips: 20.2615 samples/sec | ETA 01:40:44
2023-03-06 19:44:29 [INFO]	[TRAIN] epoch: 42, iter: 700/16000, loss: 0.2625, lr: 0.009606, batch_cost: 0.3488, reader_cost: 0.05036, ips: 22.9336 samples/sec | ETA 01:28:57
2023-03-06 19:44:31 [INFO]	[TRAIN] epoch: 42, iter: 710/16000, loss: 0.2625, lr: 0.009600, batch_cost: 0.2295, reader_cost: 0.00034, ips: 34.8622 samples/sec | ETA 00:58:28
2023-03-06 19:44:35 [INFO]	[TRAIN] epoch: 43, iter: 720/16000, loss: 0.4196, lr: 0.009595, batch_cost: 0.3278, reader_cost: 0.05532, ips: 24.4088 samples/sec | ETA 01:23:28
2023-03-06 19:44:37 [INFO]	[TRAIN] epoch: 43, iter: 730/16000, loss: 0.4250, lr: 0.009589, batch_cost: 0.2761, reader_cost: 0.00031, ips: 28.9794 samples/sec | ETA 01:10:15
2023-03-06 19:44:41 [INFO]	[TRAIN] epoch: 44, iter: 740/16000, loss: 0.2863, lr: 0.009583, batch_cost: 0.3795, reader_cost: 0.05398, ips: 21.0802 samples/sec | ETA 01:36:31
2023-03-06 19:44:45 [INFO]	[TRAIN] epoch: 45, iter: 750/16000, loss: 0.3884, lr: 0.009578, batch_cost: 0.4396, reader_cost: 0.05019, ips: 18.1993 samples/sec | ETA 01:51:43
2023-03-06 19:44:48 [INFO]	[TRAIN] epoch: 45, iter: 760/16000, loss: 0.2963, lr: 0.009572, batch_cost: 0.2932, reader_cost: 0.00035, ips: 27.2884 samples/sec | ETA 01:14:27
2023-03-06 19:44:52 [INFO]	[TRAIN] epoch: 46, iter: 770/16000, loss: 0.3733, lr: 0.009566, batch_cost: 0.3138, reader_cost: 0.05065, ips: 25.4949 samples/sec | ETA 01:19:38
2023-03-06 19:44:54 [INFO]	[TRAIN] epoch: 46, iter: 780/16000, loss: 0.2941, lr: 0.009561, batch_cost: 0.2027, reader_cost: 0.00029, ips: 39.4680 samples/sec | ETA 00:51:25
2023-03-06 19:44:56 [INFO]	[TRAIN] epoch: 47, iter: 790/16000, loss: 0.3430, lr: 0.009555, batch_cost: 0.2561, reader_cost: 0.04533, ips: 31.2375 samples/sec | ETA 01:04:55
2023-03-06 19:44:59 [INFO]	[TRAIN] epoch: 48, iter: 800/16000, loss: 0.4150, lr: 0.009549, batch_cost: 0.2557, reader_cost: 0.04928, ips: 31.2860 samples/sec | ETA 01:04:46
2023-03-06 19:45:01 [INFO]	[TRAIN] epoch: 48, iter: 810/16000, loss: 0.2580, lr: 0.009544, batch_cost: 0.2082, reader_cost: 0.00030, ips: 38.4337 samples/sec | ETA 00:52:41
2023-03-06 19:45:03 [INFO]	[TRAIN] epoch: 49, iter: 820/16000, loss: 0.2909, lr: 0.009538, batch_cost: 0.2542, reader_cost: 0.03717, ips: 31.4663 samples/sec | ETA 01:04:19
2023-03-06 19:45:05 [INFO]	[TRAIN] epoch: 49, iter: 830/16000, loss: 0.2731, lr: 0.009532, batch_cost: 0.1933, reader_cost: 0.00030, ips: 41.3930 samples/sec | ETA 00:48:51
2023-03-06 19:45:08 [INFO]	[TRAIN] epoch: 50, iter: 840/16000, loss: 0.4231, lr: 0.009527, batch_cost: 0.2570, reader_cost: 0.04870, ips: 31.1278 samples/sec | ETA 01:04:56
2023-03-06 19:45:10 [INFO]	[TRAIN] epoch: 50, iter: 850/16000, loss: 0.3412, lr: 0.009521, batch_cost: 0.2024, reader_cost: 0.00029, ips: 39.5203 samples/sec | ETA 00:51:06
2023-03-06 19:45:13 [INFO]	[TRAIN] epoch: 51, iter: 860/16000, loss: 0.2779, lr: 0.009515, batch_cost: 0.2718, reader_cost: 0.04670, ips: 29.4365 samples/sec | ETA 01:08:34
2023-03-06 19:45:15 [INFO]	[TRAIN] epoch: 52, iter: 870/16000, loss: 0.3669, lr: 0.009510, batch_cost: 0.2547, reader_cost: 0.03996, ips: 31.4089 samples/sec | ETA 01:04:13
2023-03-06 19:45:17 [INFO]	[TRAIN] epoch: 52, iter: 880/16000, loss: 0.3343, lr: 0.009504, batch_cost: 0.1960, reader_cost: 0.00034, ips: 40.8147 samples/sec | ETA 00:49:23
2023-03-06 19:45:20 [INFO]	[TRAIN] epoch: 53, iter: 890/16000, loss: 0.3642, lr: 0.009499, batch_cost: 0.2629, reader_cost: 0.03979, ips: 30.4331 samples/sec | ETA 01:06:11
2023-03-06 19:45:22 [INFO]	[TRAIN] epoch: 53, iter: 900/16000, loss: 0.3190, lr: 0.009493, batch_cost: 0.2032, reader_cost: 0.00026, ips: 39.3749 samples/sec | ETA 00:51:07
2023-03-06 19:45:24 [INFO]	[TRAIN] epoch: 54, iter: 910/16000, loss: 0.2556, lr: 0.009487, batch_cost: 0.2693, reader_cost: 0.04810, ips: 29.7074 samples/sec | ETA 01:07:43
2023-03-06 19:45:27 [INFO]	[TRAIN] epoch: 55, iter: 920/16000, loss: 0.2401, lr: 0.009482, batch_cost: 0.2569, reader_cost: 0.04331, ips: 31.1428 samples/sec | ETA 01:04:33
2023-03-06 19:45:29 [INFO]	[TRAIN] epoch: 55, iter: 930/16000, loss: 0.3205, lr: 0.009476, batch_cost: 0.2123, reader_cost: 0.00028, ips: 37.6895 samples/sec | ETA 00:53:18
2023-03-06 19:45:33 [INFO]	[TRAIN] epoch: 56, iter: 940/16000, loss: 0.2735, lr: 0.009470, batch_cost: 0.3565, reader_cost: 0.05864, ips: 22.4394 samples/sec | ETA 01:29:29
2023-03-06 19:45:35 [INFO]	[TRAIN] epoch: 56, iter: 950/16000, loss: 0.4040, lr: 0.009465, batch_cost: 0.2590, reader_cost: 0.00029, ips: 30.8867 samples/sec | ETA 01:04:58
2023-03-06 19:45:38 [INFO]	[TRAIN] epoch: 57, iter: 960/16000, loss: 0.3197, lr: 0.009459, batch_cost: 0.2723, reader_cost: 0.04197, ips: 29.3770 samples/sec | ETA 01:08:15
2023-03-06 19:45:41 [INFO]	[TRAIN] epoch: 58, iter: 970/16000, loss: 0.4248, lr: 0.009453, batch_cost: 0.2821, reader_cost: 0.04817, ips: 28.3556 samples/sec | ETA 01:10:40
2023-03-06 19:45:43 [INFO]	[TRAIN] epoch: 58, iter: 980/16000, loss: 0.2830, lr: 0.009448, batch_cost: 0.2336, reader_cost: 0.00037, ips: 34.2505 samples/sec | ETA 00:58:28
2023-03-06 19:45:46 [INFO]	[TRAIN] epoch: 59, iter: 990/16000, loss: 0.3089, lr: 0.009442, batch_cost: 0.2912, reader_cost: 0.04452, ips: 27.4726 samples/sec | ETA 01:12:50
2023-03-06 19:45:48 [INFO]	[TRAIN] epoch: 59, iter: 1000/16000, loss: 0.3822, lr: 0.009436, batch_cost: 0.2069, reader_cost: 0.00027, ips: 38.6600 samples/sec | ETA 00:51:43
2023-03-06 19:45:48 [INFO]	Start evaluating (total_samples: 119, total_iters: 60)...
60/60 - 4s - batch_cost: 0.0627 - reader cost: 0.0021
2023-03-06 19:45:52 [INFO]	[EVAL] #Images: 119 mIoU: 0.7632 Acc: 0.9311 Kappa: 0.7128 Dice: 0.8563
2023-03-06 19:45:52 [INFO]	[EVAL] Class IoU: 
[0.923  0.6034]
2023-03-06 19:45:52 [INFO]	[EVAL] Class Precision: 
[0.9499 0.8056]
2023-03-06 19:45:52 [INFO]	[EVAL] Class Recall: 
[0.9703 0.7063]
2023-03-06 19:45:53 [INFO]	[EVAL] The model with the best validation mIoU (0.7632) was saved at iter 1000.
2023-03-06 19:45:56 [INFO]	[TRAIN] epoch: 60, iter: 1010/16000, loss: 0.2317, lr: 0.009431, batch_cost: 0.3110, reader_cost: 0.04507, ips: 25.7251 samples/sec | ETA 01:17:41
2023-03-06 19:45:58 [INFO]	[TRAIN] epoch: 60, iter: 1020/16000, loss: 0.3292, lr: 0.009425, batch_cost: 0.1942, reader_cost: 0.00028, ips: 41.1956 samples/sec | ETA 00:48:29
2023-03-06 19:46:01 [INFO]	[TRAIN] epoch: 61, iter: 1030/16000, loss: 0.3773, lr: 0.009419, batch_cost: 0.2772, reader_cost: 0.05669, ips: 28.8569 samples/sec | ETA 01:09:10
2023-03-06 19:46:05 [INFO]	[TRAIN] epoch: 62, iter: 1040/16000, loss: 0.3743, lr: 0.009414, batch_cost: 0.3356, reader_cost: 0.12690, ips: 23.8393 samples/sec | ETA 01:23:40
2023-03-06 19:46:07 [INFO]	[TRAIN] epoch: 62, iter: 1050/16000, loss: 0.3419, lr: 0.009408, batch_cost: 0.2077, reader_cost: 0.00028, ips: 38.5152 samples/sec | ETA 00:51:45
2023-03-06 19:46:09 [INFO]	[TRAIN] epoch: 63, iter: 1060/16000, loss: 0.3378, lr: 0.009402, batch_cost: 0.2733, reader_cost: 0.04340, ips: 29.2711 samples/sec | ETA 01:08:03
2023-03-06 19:46:11 [INFO]	[TRAIN] epoch: 63, iter: 1070/16000, loss: 0.4245, lr: 0.009397, batch_cost: 0.2167, reader_cost: 0.00029, ips: 36.9167 samples/sec | ETA 00:53:55
2023-03-06 19:46:14 [INFO]	[TRAIN] epoch: 64, iter: 1080/16000, loss: 0.3915, lr: 0.009391, batch_cost: 0.2939, reader_cost: 0.06785, ips: 27.2229 samples/sec | ETA 01:13:04
2023-03-06 19:46:17 [INFO]	[TRAIN] epoch: 65, iter: 1090/16000, loss: 0.3384, lr: 0.009385, batch_cost: 0.2726, reader_cost: 0.06073, ips: 29.3485 samples/sec | ETA 01:07:44
2023-03-06 19:46:19 [INFO]	[TRAIN] epoch: 65, iter: 1100/16000, loss: 0.2581, lr: 0.009380, batch_cost: 0.1906, reader_cost: 0.00030, ips: 41.9770 samples/sec | ETA 00:47:19
2023-03-06 19:46:22 [INFO]	[TRAIN] epoch: 66, iter: 1110/16000, loss: 0.3353, lr: 0.009374, batch_cost: 0.2519, reader_cost: 0.04740, ips: 31.7530 samples/sec | ETA 01:02:31
2023-03-06 19:46:24 [INFO]	[TRAIN] epoch: 66, iter: 1120/16000, loss: 0.3275, lr: 0.009368, batch_cost: 0.2033, reader_cost: 0.00028, ips: 39.3461 samples/sec | ETA 00:50:25
2023-03-06 19:46:27 [INFO]	[TRAIN] epoch: 67, iter: 1130/16000, loss: 0.3556, lr: 0.009363, batch_cost: 0.3241, reader_cost: 0.04553, ips: 24.6834 samples/sec | ETA 01:20:19
2023-03-06 19:46:30 [INFO]	[TRAIN] epoch: 68, iter: 1140/16000, loss: 0.2613, lr: 0.009357, batch_cost: 0.3090, reader_cost: 0.07713, ips: 25.8941 samples/sec | ETA 01:16:31
2023-03-06 19:46:34 [INFO]	[TRAIN] epoch: 68, iter: 1150/16000, loss: 0.2930, lr: 0.009351, batch_cost: 0.3602, reader_cost: 0.00040, ips: 22.2108 samples/sec | ETA 01:29:08
2023-03-06 19:46:37 [INFO]	[TRAIN] epoch: 69, iter: 1160/16000, loss: 0.2704, lr: 0.009346, batch_cost: 0.3730, reader_cost: 0.08415, ips: 21.4484 samples/sec | ETA 01:32:15
2023-03-06 19:46:40 [INFO]	[TRAIN] epoch: 69, iter: 1170/16000, loss: 0.4991, lr: 0.009340, batch_cost: 0.2583, reader_cost: 0.00036, ips: 30.9772 samples/sec | ETA 01:03:49
2023-03-06 19:46:44 [INFO]	[TRAIN] epoch: 70, iter: 1180/16000, loss: 0.3453, lr: 0.009334, batch_cost: 0.3790, reader_cost: 0.06666, ips: 21.1096 samples/sec | ETA 01:33:36
2023-03-06 19:46:46 [INFO]	[TRAIN] epoch: 70, iter: 1190/16000, loss: 0.3855, lr: 0.009329, batch_cost: 0.2675, reader_cost: 0.00031, ips: 29.9094 samples/sec | ETA 01:06:01
2023-03-06 19:46:50 [INFO]	[TRAIN] epoch: 71, iter: 1200/16000, loss: 0.3323, lr: 0.009323, batch_cost: 0.3738, reader_cost: 0.06395, ips: 21.4037 samples/sec | ETA 01:32:11
2023-03-06 19:46:54 [INFO]	[TRAIN] epoch: 72, iter: 1210/16000, loss: 0.2936, lr: 0.009317, batch_cost: 0.3656, reader_cost: 0.05299, ips: 21.8830 samples/sec | ETA 01:30:06
2023-03-06 19:46:57 [INFO]	[TRAIN] epoch: 72, iter: 1220/16000, loss: 0.3133, lr: 0.009312, batch_cost: 0.3004, reader_cost: 0.00038, ips: 26.6338 samples/sec | ETA 01:13:59
2023-03-06 19:47:01 [INFO]	[TRAIN] epoch: 73, iter: 1230/16000, loss: 0.3204, lr: 0.009306, batch_cost: 0.3763, reader_cost: 0.07261, ips: 21.2624 samples/sec | ETA 01:32:37
2023-03-06 19:47:04 [INFO]	[TRAIN] epoch: 73, iter: 1240/16000, loss: 0.3202, lr: 0.009300, batch_cost: 0.3096, reader_cost: 0.00033, ips: 25.8394 samples/sec | ETA 01:16:09
2023-03-06 19:47:07 [INFO]	[TRAIN] epoch: 74, iter: 1250/16000, loss: 0.3724, lr: 0.009295, batch_cost: 0.3484, reader_cost: 0.05684, ips: 22.9633 samples/sec | ETA 01:25:38
2023-03-06 19:47:11 [INFO]	[TRAIN] epoch: 75, iter: 1260/16000, loss: 0.2768, lr: 0.009289, batch_cost: 0.3616, reader_cost: 0.06439, ips: 22.1210 samples/sec | ETA 01:28:50
2023-03-06 19:47:14 [INFO]	[TRAIN] epoch: 75, iter: 1270/16000, loss: 0.2660, lr: 0.009283, batch_cost: 0.3326, reader_cost: 0.00035, ips: 24.0519 samples/sec | ETA 01:21:39
2023-03-06 19:47:18 [INFO]	[TRAIN] epoch: 76, iter: 1280/16000, loss: 0.3942, lr: 0.009278, batch_cost: 0.3600, reader_cost: 0.06711, ips: 22.2219 samples/sec | ETA 01:28:19
2023-03-06 19:47:20 [INFO]	[TRAIN] epoch: 76, iter: 1290/16000, loss: 0.2817, lr: 0.009272, batch_cost: 0.2316, reader_cost: 0.00032, ips: 34.5373 samples/sec | ETA 00:56:47
2023-03-06 19:47:24 [INFO]	[TRAIN] epoch: 77, iter: 1300/16000, loss: 0.2573, lr: 0.009266, batch_cost: 0.3928, reader_cost: 0.04247, ips: 20.3678 samples/sec | ETA 01:36:13
2023-03-06 19:47:28 [INFO]	[TRAIN] epoch: 78, iter: 1310/16000, loss: 0.2771, lr: 0.009261, batch_cost: 0.3748, reader_cost: 0.05280, ips: 21.3455 samples/sec | ETA 01:31:45
2023-03-06 19:47:31 [INFO]	[TRAIN] epoch: 78, iter: 1320/16000, loss: 0.2810, lr: 0.009255, batch_cost: 0.3590, reader_cost: 0.00311, ips: 22.2845 samples/sec | ETA 01:27:50
2023-03-06 19:47:34 [INFO]	[TRAIN] epoch: 79, iter: 1330/16000, loss: 0.2521, lr: 0.009249, batch_cost: 0.3270, reader_cost: 0.05757, ips: 24.4628 samples/sec | ETA 01:19:57
2023-03-06 19:47:37 [INFO]	[TRAIN] epoch: 79, iter: 1340/16000, loss: 0.2448, lr: 0.009244, batch_cost: 0.2350, reader_cost: 0.00031, ips: 34.0451 samples/sec | ETA 00:57:24
2023-03-06 19:47:41 [INFO]	[TRAIN] epoch: 80, iter: 1350/16000, loss: 0.3299, lr: 0.009238, batch_cost: 0.3751, reader_cost: 0.06300, ips: 21.3249 samples/sec | ETA 01:31:35
2023-03-06 19:47:44 [INFO]	[TRAIN] epoch: 80, iter: 1360/16000, loss: 0.2907, lr: 0.009232, batch_cost: 0.2992, reader_cost: 0.00030, ips: 26.7343 samples/sec | ETA 01:13:00
2023-03-06 19:47:47 [INFO]	[TRAIN] epoch: 81, iter: 1370/16000, loss: 0.3040, lr: 0.009227, batch_cost: 0.3237, reader_cost: 0.06875, ips: 24.7147 samples/sec | ETA 01:18:55
2023-03-06 19:47:50 [INFO]	[TRAIN] epoch: 82, iter: 1380/16000, loss: 0.3094, lr: 0.009221, batch_cost: 0.3351, reader_cost: 0.09666, ips: 23.8728 samples/sec | ETA 01:21:39
2023-03-06 19:47:53 [INFO]	[TRAIN] epoch: 82, iter: 1390/16000, loss: 0.2685, lr: 0.009215, batch_cost: 0.2910, reader_cost: 0.00034, ips: 27.4905 samples/sec | ETA 01:10:51
2023-03-06 19:47:57 [INFO]	[TRAIN] epoch: 83, iter: 1400/16000, loss: 0.3120, lr: 0.009210, batch_cost: 0.3572, reader_cost: 0.04934, ips: 22.3972 samples/sec | ETA 01:26:54
2023-03-06 19:47:59 [INFO]	[TRAIN] epoch: 83, iter: 1410/16000, loss: 0.3133, lr: 0.009204, batch_cost: 0.2679, reader_cost: 0.00032, ips: 29.8635 samples/sec | ETA 01:05:08
2023-03-06 19:48:03 [INFO]	[TRAIN] epoch: 84, iter: 1420/16000, loss: 0.2899, lr: 0.009198, batch_cost: 0.4033, reader_cost: 0.04973, ips: 19.8373 samples/sec | ETA 01:37:59
2023-03-06 19:48:07 [INFO]	[TRAIN] epoch: 85, iter: 1430/16000, loss: 0.3885, lr: 0.009192, batch_cost: 0.4008, reader_cost: 0.08494, ips: 19.9610 samples/sec | ETA 01:37:19
2023-03-06 19:48:10 [INFO]	[TRAIN] epoch: 85, iter: 1440/16000, loss: 0.2774, lr: 0.009187, batch_cost: 0.3098, reader_cost: 0.00044, ips: 25.8190 samples/sec | ETA 01:15:11
2023-03-06 19:48:15 [INFO]	[TRAIN] epoch: 86, iter: 1450/16000, loss: 0.3053, lr: 0.009181, batch_cost: 0.4036, reader_cost: 0.05441, ips: 19.8208 samples/sec | ETA 01:37:52
2023-03-06 19:48:18 [INFO]	[TRAIN] epoch: 86, iter: 1460/16000, loss: 0.3806, lr: 0.009175, batch_cost: 0.3077, reader_cost: 0.00030, ips: 26.0027 samples/sec | ETA 01:14:33
2023-03-06 19:48:21 [INFO]	[TRAIN] epoch: 87, iter: 1470/16000, loss: 0.2323, lr: 0.009170, batch_cost: 0.3842, reader_cost: 0.05923, ips: 20.8199 samples/sec | ETA 01:33:03
2023-03-06 19:48:25 [INFO]	[TRAIN] epoch: 88, iter: 1480/16000, loss: 0.3102, lr: 0.009164, batch_cost: 0.3273, reader_cost: 0.06850, ips: 24.4442 samples/sec | ETA 01:19:12
2023-03-06 19:48:28 [INFO]	[TRAIN] epoch: 88, iter: 1490/16000, loss: 0.3903, lr: 0.009158, batch_cost: 0.3572, reader_cost: 0.00046, ips: 22.3975 samples/sec | ETA 01:26:22
2023-03-06 19:48:33 [INFO]	[TRAIN] epoch: 89, iter: 1500/16000, loss: 0.3151, lr: 0.009153, batch_cost: 0.4286, reader_cost: 0.07840, ips: 18.6646 samples/sec | ETA 01:43:34
2023-03-06 19:48:36 [INFO]	[TRAIN] epoch: 89, iter: 1510/16000, loss: 0.2280, lr: 0.009147, batch_cost: 0.2985, reader_cost: 0.00237, ips: 26.8034 samples/sec | ETA 01:12:04
2023-03-06 19:48:40 [INFO]	[TRAIN] epoch: 90, iter: 1520/16000, loss: 0.3622, lr: 0.009141, batch_cost: 0.4056, reader_cost: 0.07094, ips: 19.7216 samples/sec | ETA 01:37:53
2023-03-06 19:48:43 [INFO]	[TRAIN] epoch: 90, iter: 1530/16000, loss: 0.3027, lr: 0.009136, batch_cost: 0.3335, reader_cost: 0.00045, ips: 23.9877 samples/sec | ETA 01:20:25
2023-03-06 19:48:48 [INFO]	[TRAIN] epoch: 91, iter: 1540/16000, loss: 0.2750, lr: 0.009130, batch_cost: 0.4589, reader_cost: 0.08856, ips: 17.4314 samples/sec | ETA 01:50:36
2023-03-06 19:48:52 [INFO]	[TRAIN] epoch: 92, iter: 1550/16000, loss: 0.2962, lr: 0.009124, batch_cost: 0.4019, reader_cost: 0.05101, ips: 19.9050 samples/sec | ETA 01:36:47
2023-03-06 19:48:54 [INFO]	[TRAIN] epoch: 92, iter: 1560/16000, loss: 0.3430, lr: 0.009119, batch_cost: 0.2066, reader_cost: 0.00029, ips: 38.7165 samples/sec | ETA 00:49:43
2023-03-06 19:48:57 [INFO]	[TRAIN] epoch: 93, iter: 1570/16000, loss: 0.3248, lr: 0.009113, batch_cost: 0.3148, reader_cost: 0.04423, ips: 25.4110 samples/sec | ETA 01:15:42
2023-03-06 19:48:59 [INFO]	[TRAIN] epoch: 93, iter: 1580/16000, loss: 0.3677, lr: 0.009107, batch_cost: 0.2318, reader_cost: 0.00036, ips: 34.5143 samples/sec | ETA 00:55:42
2023-03-06 19:49:03 [INFO]	[TRAIN] epoch: 94, iter: 1590/16000, loss: 0.2882, lr: 0.009102, batch_cost: 0.3412, reader_cost: 0.08097, ips: 23.4451 samples/sec | ETA 01:21:57
2023-03-06 19:49:05 [INFO]	[TRAIN] epoch: 95, iter: 1600/16000, loss: 0.2614, lr: 0.009096, batch_cost: 0.2867, reader_cost: 0.05411, ips: 27.8995 samples/sec | ETA 01:08:49
2023-03-06 19:49:07 [INFO]	[TRAIN] epoch: 95, iter: 1610/16000, loss: 0.2342, lr: 0.009090, batch_cost: 0.1996, reader_cost: 0.00029, ips: 40.0725 samples/sec | ETA 00:47:52
2023-03-06 19:49:10 [INFO]	[TRAIN] epoch: 96, iter: 1620/16000, loss: 0.2296, lr: 0.009085, batch_cost: 0.2772, reader_cost: 0.05936, ips: 28.8647 samples/sec | ETA 01:06:25
2023-03-06 19:49:12 [INFO]	[TRAIN] epoch: 96, iter: 1630/16000, loss: 0.2640, lr: 0.009079, batch_cost: 0.1941, reader_cost: 0.00031, ips: 41.2212 samples/sec | ETA 00:46:28
2023-03-06 19:49:15 [INFO]	[TRAIN] epoch: 97, iter: 1640/16000, loss: 0.2278, lr: 0.009073, batch_cost: 0.2884, reader_cost: 0.04819, ips: 27.7436 samples/sec | ETA 01:09:00
2023-03-06 19:49:18 [INFO]	[TRAIN] epoch: 98, iter: 1650/16000, loss: 0.3534, lr: 0.009067, batch_cost: 0.2823, reader_cost: 0.04647, ips: 28.3432 samples/sec | ETA 01:07:30
2023-03-06 19:49:20 [INFO]	[TRAIN] epoch: 98, iter: 1660/16000, loss: 0.2716, lr: 0.009062, batch_cost: 0.2251, reader_cost: 0.00029, ips: 35.5402 samples/sec | ETA 00:53:47
2023-03-06 19:49:23 [INFO]	[TRAIN] epoch: 99, iter: 1670/16000, loss: 0.3987, lr: 0.009056, batch_cost: 0.2705, reader_cost: 0.05180, ips: 29.5722 samples/sec | ETA 01:04:36
2023-03-06 19:49:25 [INFO]	[TRAIN] epoch: 99, iter: 1680/16000, loss: 0.2723, lr: 0.009050, batch_cost: 0.2129, reader_cost: 0.00029, ips: 37.5800 samples/sec | ETA 00:50:48
2023-03-06 19:49:28 [INFO]	[TRAIN] epoch: 100, iter: 1690/16000, loss: 0.2721, lr: 0.009045, batch_cost: 0.2804, reader_cost: 0.05288, ips: 28.5340 samples/sec | ETA 01:06:52
2023-03-06 19:49:30 [INFO]	[TRAIN] epoch: 100, iter: 1700/16000, loss: 0.3357, lr: 0.009039, batch_cost: 0.2143, reader_cost: 0.00029, ips: 37.3338 samples/sec | ETA 00:51:04
2023-03-06 19:49:33 [INFO]	[TRAIN] epoch: 101, iter: 1710/16000, loss: 0.2972, lr: 0.009033, batch_cost: 0.2757, reader_cost: 0.05256, ips: 29.0163 samples/sec | ETA 01:05:39
2023-03-06 19:49:35 [INFO]	[TRAIN] epoch: 102, iter: 1720/16000, loss: 0.4029, lr: 0.009028, batch_cost: 0.2473, reader_cost: 0.05118, ips: 32.3453 samples/sec | ETA 00:58:51
2023-03-06 19:49:37 [INFO]	[TRAIN] epoch: 102, iter: 1730/16000, loss: 0.4074, lr: 0.009022, batch_cost: 0.1910, reader_cost: 0.00028, ips: 41.8892 samples/sec | ETA 00:45:25
2023-03-06 19:49:39 [INFO]	[TRAIN] epoch: 103, iter: 1740/16000, loss: 0.2489, lr: 0.009016, batch_cost: 0.2511, reader_cost: 0.04067, ips: 31.8594 samples/sec | ETA 00:59:40
2023-03-06 19:49:41 [INFO]	[TRAIN] epoch: 103, iter: 1750/16000, loss: 0.4828, lr: 0.009011, batch_cost: 0.1912, reader_cost: 0.00029, ips: 41.8418 samples/sec | ETA 00:45:24
2023-03-06 19:49:44 [INFO]	[TRAIN] epoch: 104, iter: 1760/16000, loss: 0.3423, lr: 0.009005, batch_cost: 0.2718, reader_cost: 0.05438, ips: 29.4380 samples/sec | ETA 01:04:29
2023-03-06 19:49:47 [INFO]	[TRAIN] epoch: 105, iter: 1770/16000, loss: 0.2706, lr: 0.008999, batch_cost: 0.2796, reader_cost: 0.05762, ips: 28.6128 samples/sec | ETA 01:06:18
2023-03-06 19:49:49 [INFO]	[TRAIN] epoch: 105, iter: 1780/16000, loss: 0.3065, lr: 0.008994, batch_cost: 0.2030, reader_cost: 0.00030, ips: 39.4049 samples/sec | ETA 00:48:06
2023-03-06 19:49:52 [INFO]	[TRAIN] epoch: 106, iter: 1790/16000, loss: 0.3240, lr: 0.008988, batch_cost: 0.2563, reader_cost: 0.04263, ips: 31.2185 samples/sec | ETA 01:00:41
2023-03-06 19:49:54 [INFO]	[TRAIN] epoch: 106, iter: 1800/16000, loss: 0.3033, lr: 0.008982, batch_cost: 0.2016, reader_cost: 0.00030, ips: 39.6843 samples/sec | ETA 00:47:42
2023-03-06 19:49:56 [INFO]	[TRAIN] epoch: 107, iter: 1810/16000, loss: 0.3423, lr: 0.008976, batch_cost: 0.2748, reader_cost: 0.04408, ips: 29.1137 samples/sec | ETA 01:04:59
2023-03-06 19:49:59 [INFO]	[TRAIN] epoch: 108, iter: 1820/16000, loss: 0.2842, lr: 0.008971, batch_cost: 0.2672, reader_cost: 0.03890, ips: 29.9402 samples/sec | ETA 01:03:08
2023-03-06 19:50:01 [INFO]	[TRAIN] epoch: 108, iter: 1830/16000, loss: 0.2342, lr: 0.008965, batch_cost: 0.2162, reader_cost: 0.00032, ips: 37.0074 samples/sec | ETA 00:51:03
2023-03-06 19:50:04 [INFO]	[TRAIN] epoch: 109, iter: 1840/16000, loss: 0.2333, lr: 0.008959, batch_cost: 0.2622, reader_cost: 0.04579, ips: 30.5144 samples/sec | ETA 01:01:52
2023-03-06 19:50:06 [INFO]	[TRAIN] epoch: 109, iter: 1850/16000, loss: 0.3514, lr: 0.008954, batch_cost: 0.2523, reader_cost: 0.00037, ips: 31.7037 samples/sec | ETA 00:59:30
2023-03-06 19:50:09 [INFO]	[TRAIN] epoch: 110, iter: 1860/16000, loss: 0.3306, lr: 0.008948, batch_cost: 0.3035, reader_cost: 0.05397, ips: 26.3556 samples/sec | ETA 01:11:32
2023-03-06 19:50:11 [INFO]	[TRAIN] epoch: 110, iter: 1870/16000, loss: 0.3377, lr: 0.008942, batch_cost: 0.1970, reader_cost: 0.00026, ips: 40.6154 samples/sec | ETA 00:46:23
2023-03-06 19:50:14 [INFO]	[TRAIN] epoch: 111, iter: 1880/16000, loss: 0.2815, lr: 0.008937, batch_cost: 0.2665, reader_cost: 0.05341, ips: 30.0236 samples/sec | ETA 01:02:42
2023-03-06 19:50:17 [INFO]	[TRAIN] epoch: 112, iter: 1890/16000, loss: 0.2938, lr: 0.008931, batch_cost: 0.3197, reader_cost: 0.05957, ips: 25.0207 samples/sec | ETA 01:15:11
2023-03-06 19:50:20 [INFO]	[TRAIN] epoch: 112, iter: 1900/16000, loss: 0.3032, lr: 0.008925, batch_cost: 0.2837, reader_cost: 0.00031, ips: 28.2006 samples/sec | ETA 01:06:39
2023-03-06 19:50:24 [INFO]	[TRAIN] epoch: 113, iter: 1910/16000, loss: 0.2849, lr: 0.008919, batch_cost: 0.3864, reader_cost: 0.06838, ips: 20.7039 samples/sec | ETA 01:30:44
2023-03-06 19:50:27 [INFO]	[TRAIN] epoch: 113, iter: 1920/16000, loss: 0.2433, lr: 0.008914, batch_cost: 0.3391, reader_cost: 0.00029, ips: 23.5912 samples/sec | ETA 01:19:34
2023-03-06 19:50:31 [INFO]	[TRAIN] epoch: 114, iter: 1930/16000, loss: 0.3494, lr: 0.008908, batch_cost: 0.3790, reader_cost: 0.06252, ips: 21.1088 samples/sec | ETA 01:28:52
2023-03-06 19:50:34 [INFO]	[TRAIN] epoch: 115, iter: 1940/16000, loss: 0.2862, lr: 0.008902, batch_cost: 0.3448, reader_cost: 0.05698, ips: 23.2047 samples/sec | ETA 01:20:47
2023-03-06 19:50:38 [INFO]	[TRAIN] epoch: 115, iter: 1950/16000, loss: 0.3170, lr: 0.008897, batch_cost: 0.3569, reader_cost: 0.00037, ips: 22.4163 samples/sec | ETA 01:23:34
2023-03-06 19:50:42 [INFO]	[TRAIN] epoch: 116, iter: 1960/16000, loss: 0.3865, lr: 0.008891, batch_cost: 0.3914, reader_cost: 0.04581, ips: 20.4394 samples/sec | ETA 01:31:35
2023-03-06 19:50:45 [INFO]	[TRAIN] epoch: 116, iter: 1970/16000, loss: 0.2476, lr: 0.008885, batch_cost: 0.2678, reader_cost: 0.00035, ips: 29.8711 samples/sec | ETA 01:02:37
2023-03-06 19:50:49 [INFO]	[TRAIN] epoch: 117, iter: 1980/16000, loss: 0.4156, lr: 0.008880, batch_cost: 0.3908, reader_cost: 0.06588, ips: 20.4728 samples/sec | ETA 01:31:18
2023-03-06 19:50:52 [INFO]	[TRAIN] epoch: 118, iter: 1990/16000, loss: 0.2909, lr: 0.008874, batch_cost: 0.3098, reader_cost: 0.06721, ips: 25.8203 samples/sec | ETA 01:12:20
2023-03-06 19:50:54 [INFO]	[TRAIN] epoch: 118, iter: 2000/16000, loss: 0.3179, lr: 0.008868, batch_cost: 0.2783, reader_cost: 0.00177, ips: 28.7459 samples/sec | ETA 01:04:56
2023-03-06 19:50:54 [INFO]	Start evaluating (total_samples: 119, total_iters: 60)...
60/60 - 5s - batch_cost: 0.0856 - reader cost: 0.0035
2023-03-06 19:51:00 [INFO]	[EVAL] #Images: 119 mIoU: 0.7542 Acc: 0.9249 Kappa: 0.7003 Dice: 0.8502
2023-03-06 19:51:00 [INFO]	[EVAL] Class IoU: 
[0.9157 0.5928]
2023-03-06 19:51:00 [INFO]	[EVAL] Class Precision: 
[0.9542 0.7525]
2023-03-06 19:51:00 [INFO]	[EVAL] Class Recall: 
[0.9578 0.7364]
2023-03-06 19:51:01 [INFO]	[EVAL] The model with the best validation mIoU (0.7632) was saved at iter 1000.
2023-03-06 19:51:04 [INFO]	[TRAIN] epoch: 119, iter: 2010/16000, loss: 0.2428, lr: 0.008862, batch_cost: 0.3644, reader_cost: 0.05988, ips: 21.9516 samples/sec | ETA 01:24:58
2023-03-06 19:51:07 [INFO]	[TRAIN] epoch: 119, iter: 2020/16000, loss: 0.2412, lr: 0.008857, batch_cost: 0.2879, reader_cost: 0.00039, ips: 27.7852 samples/sec | ETA 01:07:05
2023-03-06 19:51:11 [INFO]	[TRAIN] epoch: 120, iter: 2030/16000, loss: 0.3068, lr: 0.008851, batch_cost: 0.3416, reader_cost: 0.04200, ips: 23.4217 samples/sec | ETA 01:19:31
2023-03-06 19:51:13 [INFO]	[TRAIN] epoch: 120, iter: 2040/16000, loss: 0.2852, lr: 0.008845, batch_cost: 0.2739, reader_cost: 0.00036, ips: 29.2068 samples/sec | ETA 01:03:43
2023-03-06 19:51:17 [INFO]	[TRAIN] epoch: 121, iter: 2050/16000, loss: 0.2336, lr: 0.008840, batch_cost: 0.3272, reader_cost: 0.06376, ips: 24.4498 samples/sec | ETA 01:16:04
2023-03-06 19:51:20 [INFO]	[TRAIN] epoch: 122, iter: 2060/16000, loss: 0.3691, lr: 0.008834, batch_cost: 0.3100, reader_cost: 0.07291, ips: 25.8088 samples/sec | ETA 01:12:01
2023-03-06 19:51:22 [INFO]	[TRAIN] epoch: 122, iter: 2070/16000, loss: 0.2959, lr: 0.008828, batch_cost: 0.2702, reader_cost: 0.00038, ips: 29.6113 samples/sec | ETA 01:02:43
2023-03-06 19:51:27 [INFO]	[TRAIN] epoch: 123, iter: 2080/16000, loss: 0.4015, lr: 0.008823, batch_cost: 0.4507, reader_cost: 0.08205, ips: 17.7502 samples/sec | ETA 01:44:33
2023-03-06 19:51:29 [INFO]	[TRAIN] epoch: 123, iter: 2090/16000, loss: 0.3204, lr: 0.008817, batch_cost: 0.2329, reader_cost: 0.00129, ips: 34.3441 samples/sec | ETA 00:54:00
2023-03-06 19:51:33 [INFO]	[TRAIN] epoch: 124, iter: 2100/16000, loss: 0.3585, lr: 0.008811, batch_cost: 0.3297, reader_cost: 0.07005, ips: 24.2662 samples/sec | ETA 01:16:22
2023-03-06 19:51:38 [INFO]	[TRAIN] epoch: 125, iter: 2110/16000, loss: 0.3123, lr: 0.008805, batch_cost: 0.5325, reader_cost: 0.13120, ips: 15.0237 samples/sec | ETA 02:03:16
2023-03-06 19:51:40 [INFO]	[TRAIN] epoch: 125, iter: 2120/16000, loss: 0.2137, lr: 0.008800, batch_cost: 0.2183, reader_cost: 0.00028, ips: 36.6549 samples/sec | ETA 00:50:29
2023-03-06 19:51:44 [INFO]	[TRAIN] epoch: 126, iter: 2130/16000, loss: 0.3555, lr: 0.008794, batch_cost: 0.3878, reader_cost: 0.05152, ips: 20.6269 samples/sec | ETA 01:29:39
2023-03-06 19:51:47 [INFO]	[TRAIN] epoch: 126, iter: 2140/16000, loss: 0.3353, lr: 0.008788, batch_cost: 0.2584, reader_cost: 0.00032, ips: 30.9609 samples/sec | ETA 00:59:41
2023-03-06 19:51:51 [INFO]	[TRAIN] epoch: 127, iter: 2150/16000, loss: 0.3574, lr: 0.008783, batch_cost: 0.4131, reader_cost: 0.05134, ips: 19.3664 samples/sec | ETA 01:35:21
2023-03-06 19:51:55 [INFO]	[TRAIN] epoch: 128, iter: 2160/16000, loss: 0.3223, lr: 0.008777, batch_cost: 0.3789, reader_cost: 0.08385, ips: 21.1124 samples/sec | ETA 01:27:24
2023-03-06 19:51:57 [INFO]	[TRAIN] epoch: 128, iter: 2170/16000, loss: 0.2854, lr: 0.008771, batch_cost: 0.2123, reader_cost: 0.00033, ips: 37.6830 samples/sec | ETA 00:48:56
2023-03-06 19:52:00 [INFO]	[TRAIN] epoch: 129, iter: 2180/16000, loss: 0.3619, lr: 0.008766, batch_cost: 0.3046, reader_cost: 0.06565, ips: 26.2669 samples/sec | ETA 01:10:09
2023-03-06 19:52:03 [INFO]	[TRAIN] epoch: 129, iter: 2190/16000, loss: 0.3631, lr: 0.008760, batch_cost: 0.3444, reader_cost: 0.00029, ips: 23.2310 samples/sec | ETA 01:19:15
2023-03-06 19:52:07 [INFO]	[TRAIN] epoch: 130, iter: 2200/16000, loss: 0.2601, lr: 0.008754, batch_cost: 0.4298, reader_cost: 0.05547, ips: 18.6151 samples/sec | ETA 01:38:50
2023-03-06 19:52:10 [INFO]	[TRAIN] epoch: 130, iter: 2210/16000, loss: 0.2515, lr: 0.008748, batch_cost: 0.2485, reader_cost: 0.00029, ips: 32.1870 samples/sec | ETA 00:57:07
2023-03-06 19:52:14 [INFO]	[TRAIN] epoch: 131, iter: 2220/16000, loss: 0.2262, lr: 0.008743, batch_cost: 0.3844, reader_cost: 0.07650, ips: 20.8131 samples/sec | ETA 01:28:16
2023-03-06 19:52:17 [INFO]	[TRAIN] epoch: 132, iter: 2230/16000, loss: 0.3151, lr: 0.008737, batch_cost: 0.3317, reader_cost: 0.03651, ips: 24.1166 samples/sec | ETA 01:16:07
2023-03-06 19:52:20 [INFO]	[TRAIN] epoch: 132, iter: 2240/16000, loss: 0.2547, lr: 0.008731, batch_cost: 0.3307, reader_cost: 0.00065, ips: 24.1881 samples/sec | ETA 01:15:51
2023-03-06 19:52:24 [INFO]	[TRAIN] epoch: 133, iter: 2250/16000, loss: 0.2763, lr: 0.008726, batch_cost: 0.4028, reader_cost: 0.07382, ips: 19.8604 samples/sec | ETA 01:32:18
2023-03-06 19:52:28 [INFO]	[TRAIN] epoch: 133, iter: 2260/16000, loss: 0.3292, lr: 0.008720, batch_cost: 0.3434, reader_cost: 0.00033, ips: 23.2967 samples/sec | ETA 01:18:38
2023-03-06 19:52:32 [INFO]	[TRAIN] epoch: 134, iter: 2270/16000, loss: 0.3789, lr: 0.008714, batch_cost: 0.3816, reader_cost: 0.09162, ips: 20.9621 samples/sec | ETA 01:27:19
2023-03-06 19:52:35 [INFO]	[TRAIN] epoch: 135, iter: 2280/16000, loss: 0.3134, lr: 0.008708, batch_cost: 0.3052, reader_cost: 0.09233, ips: 26.2083 samples/sec | ETA 01:09:47
2023-03-06 19:52:37 [INFO]	[TRAIN] epoch: 135, iter: 2290/16000, loss: 0.3405, lr: 0.008703, batch_cost: 0.1923, reader_cost: 0.00126, ips: 41.5947 samples/sec | ETA 00:43:56
2023-03-06 19:52:40 [INFO]	[TRAIN] epoch: 136, iter: 2300/16000, loss: 0.2808, lr: 0.008697, batch_cost: 0.3134, reader_cost: 0.07230, ips: 25.5245 samples/sec | ETA 01:11:33
2023-03-06 19:52:44 [INFO]	[TRAIN] epoch: 136, iter: 2310/16000, loss: 0.2189, lr: 0.008691, batch_cost: 0.4071, reader_cost: 0.00028, ips: 19.6492 samples/sec | ETA 01:32:53
2023-03-06 19:52:48 [INFO]	[TRAIN] epoch: 137, iter: 2320/16000, loss: 0.3530, lr: 0.008686, batch_cost: 0.3851, reader_cost: 0.04034, ips: 20.7724 samples/sec | ETA 01:27:48
2023-03-06 19:52:50 [INFO]	[TRAIN] epoch: 138, iter: 2330/16000, loss: 0.2891, lr: 0.008680, batch_cost: 0.2564, reader_cost: 0.03871, ips: 31.1972 samples/sec | ETA 00:58:25
2023-03-06 19:52:52 [INFO]	[TRAIN] epoch: 138, iter: 2340/16000, loss: 0.3365, lr: 0.008674, batch_cost: 0.2191, reader_cost: 0.00036, ips: 36.5117 samples/sec | ETA 00:49:53
2023-03-06 19:52:55 [INFO]	[TRAIN] epoch: 139, iter: 2350/16000, loss: 0.3387, lr: 0.008668, batch_cost: 0.2702, reader_cost: 0.05695, ips: 29.6095 samples/sec | ETA 01:01:28
2023-03-06 19:52:57 [INFO]	[TRAIN] epoch: 139, iter: 2360/16000, loss: 0.2768, lr: 0.008663, batch_cost: 0.2025, reader_cost: 0.00028, ips: 39.5141 samples/sec | ETA 00:46:01
2023-03-06 19:53:00 [INFO]	[TRAIN] epoch: 140, iter: 2370/16000, loss: 0.3297, lr: 0.008657, batch_cost: 0.2715, reader_cost: 0.05113, ips: 29.4613 samples/sec | ETA 01:01:41
2023-03-06 19:53:02 [INFO]	[TRAIN] epoch: 140, iter: 2380/16000, loss: 0.2719, lr: 0.008651, batch_cost: 0.1916, reader_cost: 0.00028, ips: 41.7558 samples/sec | ETA 00:43:29
2023-03-06 19:53:05 [INFO]	[TRAIN] epoch: 141, iter: 2390/16000, loss: 0.3467, lr: 0.008646, batch_cost: 0.3431, reader_cost: 0.04278, ips: 23.3192 samples/sec | ETA 01:17:49
2023-03-06 19:53:08 [INFO]	[TRAIN] epoch: 142, iter: 2400/16000, loss: 0.2687, lr: 0.008640, batch_cost: 0.2479, reader_cost: 0.04014, ips: 32.2705 samples/sec | ETA 00:56:11
2023-03-06 19:53:10 [INFO]	[TRAIN] epoch: 142, iter: 2410/16000, loss: 0.3894, lr: 0.008634, batch_cost: 0.2080, reader_cost: 0.00030, ips: 38.4598 samples/sec | ETA 00:47:06
2023-03-06 19:53:12 [INFO]	[TRAIN] epoch: 143, iter: 2420/16000, loss: 0.2809, lr: 0.008628, batch_cost: 0.2572, reader_cost: 0.05631, ips: 31.1081 samples/sec | ETA 00:58:12
2023-03-06 19:53:14 [INFO]	[TRAIN] epoch: 143, iter: 2430/16000, loss: 0.2261, lr: 0.008623, batch_cost: 0.1931, reader_cost: 0.00028, ips: 41.4301 samples/sec | ETA 00:43:40
2023-03-06 19:53:17 [INFO]	[TRAIN] epoch: 144, iter: 2440/16000, loss: 0.2579, lr: 0.008617, batch_cost: 0.2466, reader_cost: 0.04074, ips: 32.4408 samples/sec | ETA 00:55:43
2023-03-06 19:53:20 [INFO]	[TRAIN] epoch: 145, iter: 2450/16000, loss: 0.2673, lr: 0.008611, batch_cost: 0.2784, reader_cost: 0.03791, ips: 28.7373 samples/sec | ETA 01:02:52
2023-03-06 19:53:23 [INFO]	[TRAIN] epoch: 145, iter: 2460/16000, loss: 0.2614, lr: 0.008606, batch_cost: 0.3316, reader_cost: 0.00039, ips: 24.1272 samples/sec | ETA 01:14:49
2023-03-06 19:53:27 [INFO]	[TRAIN] epoch: 146, iter: 2470/16000, loss: 0.2957, lr: 0.008600, batch_cost: 0.4064, reader_cost: 0.06170, ips: 19.6853 samples/sec | ETA 01:31:38
2023-03-06 19:53:30 [INFO]	[TRAIN] epoch: 146, iter: 2480/16000, loss: 0.2357, lr: 0.008594, batch_cost: 0.3311, reader_cost: 0.00037, ips: 24.1643 samples/sec | ETA 01:14:36
2023-03-06 19:53:33 [INFO]	[TRAIN] epoch: 147, iter: 2490/16000, loss: 0.3688, lr: 0.008588, batch_cost: 0.2894, reader_cost: 0.04774, ips: 27.6420 samples/sec | ETA 01:05:09
2023-03-06 19:53:36 [INFO]	[TRAIN] epoch: 148, iter: 2500/16000, loss: 0.2507, lr: 0.008583, batch_cost: 0.2716, reader_cost: 0.05365, ips: 29.4604 samples/sec | ETA 01:01:05
2023-03-06 19:53:38 [INFO]	[TRAIN] epoch: 148, iter: 2510/16000, loss: 0.3661, lr: 0.008577, batch_cost: 0.1914, reader_cost: 0.00028, ips: 41.8039 samples/sec | ETA 00:43:01
2023-03-06 19:53:40 [INFO]	[TRAIN] epoch: 149, iter: 2520/16000, loss: 0.2939, lr: 0.008571, batch_cost: 0.2651, reader_cost: 0.05497, ips: 30.1808 samples/sec | ETA 00:59:33
2023-03-06 19:53:42 [INFO]	[TRAIN] epoch: 149, iter: 2530/16000, loss: 0.3001, lr: 0.008565, batch_cost: 0.1932, reader_cost: 0.00029, ips: 41.4155 samples/sec | ETA 00:43:21
2023-03-06 19:53:45 [INFO]	[TRAIN] epoch: 150, iter: 2540/16000, loss: 0.3359, lr: 0.008560, batch_cost: 0.2491, reader_cost: 0.04393, ips: 32.1137 samples/sec | ETA 00:55:53
2023-03-06 19:53:47 [INFO]	[TRAIN] epoch: 150, iter: 2550/16000, loss: 0.3208, lr: 0.008554, batch_cost: 0.1980, reader_cost: 0.00028, ips: 40.4073 samples/sec | ETA 00:44:22
2023-03-06 19:53:50 [INFO]	[TRAIN] epoch: 151, iter: 2560/16000, loss: 0.3065, lr: 0.008548, batch_cost: 0.2897, reader_cost: 0.04108, ips: 27.6137 samples/sec | ETA 01:04:53
2023-03-06 19:53:52 [INFO]	[TRAIN] epoch: 152, iter: 2570/16000, loss: 0.2861, lr: 0.008543, batch_cost: 0.2666, reader_cost: 0.04768, ips: 30.0108 samples/sec | ETA 00:59:40
2023-03-06 19:53:54 [INFO]	[TRAIN] epoch: 152, iter: 2580/16000, loss: 0.2880, lr: 0.008537, batch_cost: 0.1956, reader_cost: 0.00031, ips: 40.9067 samples/sec | ETA 00:43:44
2023-03-06 19:53:57 [INFO]	[TRAIN] epoch: 153, iter: 2590/16000, loss: 0.3117, lr: 0.008531, batch_cost: 0.2649, reader_cost: 0.06238, ips: 30.1985 samples/sec | ETA 00:59:12
2023-03-06 19:53:59 [INFO]	[TRAIN] epoch: 153, iter: 2600/16000, loss: 0.2717, lr: 0.008525, batch_cost: 0.2003, reader_cost: 0.00026, ips: 39.9494 samples/sec | ETA 00:44:43
2023-03-06 19:54:02 [INFO]	[TRAIN] epoch: 154, iter: 2610/16000, loss: 0.2011, lr: 0.008520, batch_cost: 0.2791, reader_cost: 0.04797, ips: 28.6681 samples/sec | ETA 01:02:16
2023-03-06 19:54:05 [INFO]	[TRAIN] epoch: 155, iter: 2620/16000, loss: 0.2500, lr: 0.008514, batch_cost: 0.2700, reader_cost: 0.05149, ips: 29.6297 samples/sec | ETA 01:00:12
2023-03-06 19:54:07 [INFO]	[TRAIN] epoch: 155, iter: 2630/16000, loss: 0.3563, lr: 0.008508, batch_cost: 0.2101, reader_cost: 0.00031, ips: 38.0704 samples/sec | ETA 00:46:49
2023-03-06 19:54:09 [INFO]	[TRAIN] epoch: 156, iter: 2640/16000, loss: 0.2843, lr: 0.008503, batch_cost: 0.2678, reader_cost: 0.06082, ips: 29.8784 samples/sec | ETA 00:59:37
2023-03-06 19:54:11 [INFO]	[TRAIN] epoch: 156, iter: 2650/16000, loss: 0.2755, lr: 0.008497, batch_cost: 0.1946, reader_cost: 0.00027, ips: 41.1194 samples/sec | ETA 00:43:17
2023-03-06 19:54:15 [INFO]	[TRAIN] epoch: 157, iter: 2660/16000, loss: 0.2564, lr: 0.008491, batch_cost: 0.3516, reader_cost: 0.05658, ips: 22.7555 samples/sec | ETA 01:18:09
2023-03-06 19:54:18 [INFO]	[TRAIN] epoch: 158, iter: 2670/16000, loss: 0.2693, lr: 0.008485, batch_cost: 0.3517, reader_cost: 0.06664, ips: 22.7491 samples/sec | ETA 01:18:07
2023-03-06 19:54:21 [INFO]	[TRAIN] epoch: 158, iter: 2680/16000, loss: 0.3255, lr: 0.008480, batch_cost: 0.2833, reader_cost: 0.00051, ips: 28.2381 samples/sec | ETA 01:02:53
2023-03-06 19:54:25 [INFO]	[TRAIN] epoch: 159, iter: 2690/16000, loss: 0.2636, lr: 0.008474, batch_cost: 0.3508, reader_cost: 0.06854, ips: 22.8066 samples/sec | ETA 01:17:48
2023-03-06 19:54:27 [INFO]	[TRAIN] epoch: 159, iter: 2700/16000, loss: 0.3485, lr: 0.008468, batch_cost: 0.2582, reader_cost: 0.00044, ips: 30.9879 samples/sec | ETA 00:57:13
2023-03-06 19:54:31 [INFO]	[TRAIN] epoch: 160, iter: 2710/16000, loss: 0.2687, lr: 0.008462, batch_cost: 0.3818, reader_cost: 0.06269, ips: 20.9529 samples/sec | ETA 01:24:34
2023-03-06 19:54:34 [INFO]	[TRAIN] epoch: 160, iter: 2720/16000, loss: 0.2771, lr: 0.008457, batch_cost: 0.2793, reader_cost: 0.00032, ips: 28.6444 samples/sec | ETA 01:01:48
2023-03-06 19:54:38 [INFO]	[TRAIN] epoch: 161, iter: 2730/16000, loss: 0.3015, lr: 0.008451, batch_cost: 0.3918, reader_cost: 0.05543, ips: 20.4180 samples/sec | ETA 01:26:39
2023-03-06 19:54:42 [INFO]	[TRAIN] epoch: 162, iter: 2740/16000, loss: 0.2292, lr: 0.008445, batch_cost: 0.4230, reader_cost: 0.08414, ips: 18.9136 samples/sec | ETA 01:33:28
2023-03-06 19:54:44 [INFO]	[TRAIN] epoch: 162, iter: 2750/16000, loss: 0.1877, lr: 0.008439, batch_cost: 0.2150, reader_cost: 0.00032, ips: 37.2093 samples/sec | ETA 00:47:28
2023-03-06 19:54:48 [INFO]	[TRAIN] epoch: 163, iter: 2760/16000, loss: 0.2329, lr: 0.008434, batch_cost: 0.3688, reader_cost: 0.11711, ips: 21.6929 samples/sec | ETA 01:21:22
2023-03-06 19:54:50 [INFO]	[TRAIN] epoch: 163, iter: 2770/16000, loss: 0.2082, lr: 0.008428, batch_cost: 0.2211, reader_cost: 0.00037, ips: 36.1840 samples/sec | ETA 00:48:45
2023-03-06 19:54:53 [INFO]	[TRAIN] epoch: 164, iter: 2780/16000, loss: 0.3305, lr: 0.008422, batch_cost: 0.3416, reader_cost: 0.08508, ips: 23.4207 samples/sec | ETA 01:15:15
2023-03-06 19:54:56 [INFO]	[TRAIN] epoch: 165, iter: 2790/16000, loss: 0.2679, lr: 0.008417, batch_cost: 0.2952, reader_cost: 0.05418, ips: 27.0961 samples/sec | ETA 01:05:00
2023-03-06 19:55:00 [INFO]	[TRAIN] epoch: 165, iter: 2800/16000, loss: 0.3183, lr: 0.008411, batch_cost: 0.3183, reader_cost: 0.00118, ips: 25.1299 samples/sec | ETA 01:10:02
2023-03-06 19:55:03 [INFO]	[TRAIN] epoch: 166, iter: 2810/16000, loss: 0.2409, lr: 0.008405, batch_cost: 0.3278, reader_cost: 0.06417, ips: 24.4042 samples/sec | ETA 01:12:03
2023-03-06 19:55:05 [INFO]	[TRAIN] epoch: 166, iter: 2820/16000, loss: 0.2607, lr: 0.008399, batch_cost: 0.2555, reader_cost: 0.00038, ips: 31.3096 samples/sec | ETA 00:56:07
2023-03-06 19:55:09 [INFO]	[TRAIN] epoch: 167, iter: 2830/16000, loss: 0.3449, lr: 0.008394, batch_cost: 0.3891, reader_cost: 0.04708, ips: 20.5582 samples/sec | ETA 01:25:24
2023-03-06 19:55:13 [INFO]	[TRAIN] epoch: 168, iter: 2840/16000, loss: 0.2874, lr: 0.008388, batch_cost: 0.4111, reader_cost: 0.05982, ips: 19.4620 samples/sec | ETA 01:30:09
2023-03-06 19:55:16 [INFO]	[TRAIN] epoch: 168, iter: 2850/16000, loss: 0.3060, lr: 0.008382, batch_cost: 0.2988, reader_cost: 0.00031, ips: 26.7731 samples/sec | ETA 01:05:29
2023-03-06 19:55:20 [INFO]	[TRAIN] epoch: 169, iter: 2860/16000, loss: 0.2821, lr: 0.008376, batch_cost: 0.3458, reader_cost: 0.07173, ips: 23.1320 samples/sec | ETA 01:15:44
2023-03-06 19:55:22 [INFO]	[TRAIN] epoch: 169, iter: 2870/16000, loss: 0.2113, lr: 0.008371, batch_cost: 0.2412, reader_cost: 0.00030, ips: 33.1619 samples/sec | ETA 00:52:47
2023-03-06 19:55:26 [INFO]	[TRAIN] epoch: 170, iter: 2880/16000, loss: 0.2522, lr: 0.008365, batch_cost: 0.4141, reader_cost: 0.08837, ips: 19.3177 samples/sec | ETA 01:30:33
2023-03-06 19:55:29 [INFO]	[TRAIN] epoch: 170, iter: 2890/16000, loss: 0.2555, lr: 0.008359, batch_cost: 0.3030, reader_cost: 0.00050, ips: 26.3987 samples/sec | ETA 01:06:12
2023-03-06 19:55:34 [INFO]	[TRAIN] epoch: 171, iter: 2900/16000, loss: 0.2689, lr: 0.008353, batch_cost: 0.4211, reader_cost: 0.06280, ips: 18.9985 samples/sec | ETA 01:31:56
2023-03-06 19:55:38 [INFO]	[TRAIN] epoch: 172, iter: 2910/16000, loss: 0.3312, lr: 0.008348, batch_cost: 0.4414, reader_cost: 0.06969, ips: 18.1245 samples/sec | ETA 01:36:17
2023-03-06 19:55:41 [INFO]	[TRAIN] epoch: 172, iter: 2920/16000, loss: 0.2588, lr: 0.008342, batch_cost: 0.3346, reader_cost: 0.00043, ips: 23.9108 samples/sec | ETA 01:12:56
2023-03-06 19:55:46 [INFO]	[TRAIN] epoch: 173, iter: 2930/16000, loss: 0.2897, lr: 0.008336, batch_cost: 0.4072, reader_cost: 0.07414, ips: 19.6465 samples/sec | ETA 01:28:42
2023-03-06 19:55:48 [INFO]	[TRAIN] epoch: 173, iter: 2940/16000, loss: 0.3519, lr: 0.008330, batch_cost: 0.2912, reader_cost: 0.00030, ips: 27.4742 samples/sec | ETA 01:03:22
2023-03-06 19:55:52 [INFO]	[TRAIN] epoch: 174, iter: 2950/16000, loss: 0.2848, lr: 0.008325, batch_cost: 0.3473, reader_cost: 0.04855, ips: 23.0372 samples/sec | ETA 01:15:31
2023-03-06 19:55:56 [INFO]	[TRAIN] epoch: 175, iter: 2960/16000, loss: 0.2084, lr: 0.008319, batch_cost: 0.3733, reader_cost: 0.05771, ips: 21.4331 samples/sec | ETA 01:21:07
2023-03-06 19:56:00 [INFO]	[TRAIN] epoch: 175, iter: 2970/16000, loss: 0.2433, lr: 0.008313, batch_cost: 0.3922, reader_cost: 0.00040, ips: 20.3961 samples/sec | ETA 01:25:10
2023-03-06 19:56:04 [INFO]	[TRAIN] epoch: 176, iter: 2980/16000, loss: 0.2583, lr: 0.008308, batch_cost: 0.4081, reader_cost: 0.07921, ips: 19.6026 samples/sec | ETA 01:28:33
2023-03-06 19:56:07 [INFO]	[TRAIN] epoch: 176, iter: 2990/16000, loss: 0.3016, lr: 0.008302, batch_cost: 0.3158, reader_cost: 0.00036, ips: 25.3298 samples/sec | ETA 01:08:28
2023-03-06 19:56:11 [INFO]	[TRAIN] epoch: 177, iter: 3000/16000, loss: 0.3203, lr: 0.008296, batch_cost: 0.4333, reader_cost: 0.07395, ips: 18.4617 samples/sec | ETA 01:33:53
2023-03-06 19:56:11 [INFO]	Start evaluating (total_samples: 119, total_iters: 60)...
60/60 - 5s - batch_cost: 0.0900 - reader cost: 0.0036
2023-03-06 19:56:17 [INFO]	[EVAL] #Images: 119 mIoU: 0.7479 Acc: 0.9292 Kappa: 0.6895 Dice: 0.8443
2023-03-06 19:56:17 [INFO]	[EVAL] Class IoU: 
[0.9218 0.574 ]
2023-03-06 19:56:17 [INFO]	[EVAL] Class Precision: 
[0.9401 0.8441]
2023-03-06 19:56:17 [INFO]	[EVAL] Class Recall: 
[0.9793 0.642 ]
2023-03-06 19:56:17 [INFO]	[EVAL] The model with the best validation mIoU (0.7632) was saved at iter 1000.
2023-03-06 19:56:21 [INFO]	[TRAIN] epoch: 178, iter: 3010/16000, loss: 0.2798, lr: 0.008290, batch_cost: 0.3607, reader_cost: 0.06504, ips: 22.1808 samples/sec | ETA 01:18:05
2023-03-06 19:56:24 [INFO]	[TRAIN] epoch: 178, iter: 3020/16000, loss: 0.3199, lr: 0.008285, batch_cost: 0.2817, reader_cost: 0.00035, ips: 28.3972 samples/sec | ETA 01:00:56
2023-03-06 19:56:28 [INFO]	[TRAIN] epoch: 179, iter: 3030/16000, loss: 0.2385, lr: 0.008279, batch_cost: 0.3653, reader_cost: 0.06105, ips: 21.9003 samples/sec | ETA 01:18:57
2023-03-06 19:56:30 [INFO]	[TRAIN] epoch: 179, iter: 3040/16000, loss: 0.2488, lr: 0.008273, batch_cost: 0.2633, reader_cost: 0.00038, ips: 30.3882 samples/sec | ETA 00:56:51
2023-03-06 19:56:33 [INFO]	[TRAIN] epoch: 180, iter: 3050/16000, loss: 0.2529, lr: 0.008267, batch_cost: 0.2692, reader_cost: 0.05921, ips: 29.7203 samples/sec | ETA 00:58:05
2023-03-06 19:56:35 [INFO]	[TRAIN] epoch: 180, iter: 3060/16000, loss: 0.3788, lr: 0.008262, batch_cost: 0.1908, reader_cost: 0.00033, ips: 41.9178 samples/sec | ETA 00:41:09
2023-03-06 19:56:37 [INFO]	[TRAIN] epoch: 181, iter: 3070/16000, loss: 0.2921, lr: 0.008256, batch_cost: 0.2684, reader_cost: 0.05426, ips: 29.8041 samples/sec | ETA 00:57:50
2023-03-06 19:56:40 [INFO]	[TRAIN] epoch: 182, iter: 3080/16000, loss: 0.2519, lr: 0.008250, batch_cost: 0.2563, reader_cost: 0.05349, ips: 31.2192 samples/sec | ETA 00:55:10
2023-03-06 19:56:42 [INFO]	[TRAIN] epoch: 182, iter: 3090/16000, loss: 0.2698, lr: 0.008244, batch_cost: 0.2016, reader_cost: 0.00035, ips: 39.6776 samples/sec | ETA 00:43:22
2023-03-06 19:56:45 [INFO]	[TRAIN] epoch: 183, iter: 3100/16000, loss: 0.2905, lr: 0.008239, batch_cost: 0.2793, reader_cost: 0.05818, ips: 28.6465 samples/sec | ETA 01:00:02
2023-03-06 19:56:47 [INFO]	[TRAIN] epoch: 183, iter: 3110/16000, loss: 0.2751, lr: 0.008233, batch_cost: 0.2011, reader_cost: 0.00027, ips: 39.7864 samples/sec | ETA 00:43:11
2023-03-06 19:56:50 [INFO]	[TRAIN] epoch: 184, iter: 3120/16000, loss: 0.2422, lr: 0.008227, batch_cost: 0.2956, reader_cost: 0.06670, ips: 27.0641 samples/sec | ETA 01:03:27
2023-03-06 19:56:53 [INFO]	[TRAIN] epoch: 185, iter: 3130/16000, loss: 0.3374, lr: 0.008221, batch_cost: 0.2757, reader_cost: 0.05118, ips: 29.0129 samples/sec | ETA 00:59:08
2023-03-06 19:56:55 [INFO]	[TRAIN] epoch: 185, iter: 3140/16000, loss: 0.2224, lr: 0.008216, batch_cost: 0.2119, reader_cost: 0.00030, ips: 37.7479 samples/sec | ETA 00:45:25
2023-03-06 19:56:57 [INFO]	[TRAIN] epoch: 186, iter: 3150/16000, loss: 0.2201, lr: 0.008210, batch_cost: 0.2756, reader_cost: 0.05191, ips: 29.0243 samples/sec | ETA 00:59:01
2023-03-06 19:57:00 [INFO]	[TRAIN] epoch: 186, iter: 3160/16000, loss: 0.3726, lr: 0.008204, batch_cost: 0.2061, reader_cost: 0.00035, ips: 38.8147 samples/sec | ETA 00:44:06
2023-03-06 19:57:02 [INFO]	[TRAIN] epoch: 187, iter: 3170/16000, loss: 0.2315, lr: 0.008198, batch_cost: 0.2537, reader_cost: 0.04953, ips: 31.5302 samples/sec | ETA 00:54:15
2023-03-06 19:57:05 [INFO]	[TRAIN] epoch: 188, iter: 3180/16000, loss: 0.2678, lr: 0.008193, batch_cost: 0.2608, reader_cost: 0.05228, ips: 30.6753 samples/sec | ETA 00:55:43
2023-03-06 19:57:07 [INFO]	[TRAIN] epoch: 188, iter: 3190/16000, loss: 0.4126, lr: 0.008187, batch_cost: 0.2137, reader_cost: 0.00030, ips: 37.4366 samples/sec | ETA 00:45:37
2023-03-06 19:57:10 [INFO]	[TRAIN] epoch: 189, iter: 3200/16000, loss: 0.2546, lr: 0.008181, batch_cost: 0.2742, reader_cost: 0.04197, ips: 29.1758 samples/sec | ETA 00:58:29
2023-03-06 19:57:11 [INFO]	[TRAIN] epoch: 189, iter: 3210/16000, loss: 0.2834, lr: 0.008175, batch_cost: 0.1918, reader_cost: 0.00026, ips: 41.7105 samples/sec | ETA 00:40:53
2023-03-06 19:57:14 [INFO]	[TRAIN] epoch: 190, iter: 3220/16000, loss: 0.2232, lr: 0.008170, batch_cost: 0.2474, reader_cost: 0.04001, ips: 32.3363 samples/sec | ETA 00:52:41
2023-03-06 19:57:16 [INFO]	[TRAIN] epoch: 190, iter: 3230/16000, loss: 0.3387, lr: 0.008164, batch_cost: 0.2024, reader_cost: 0.00030, ips: 39.5344 samples/sec | ETA 00:43:04
2023-03-06 19:57:18 [INFO]	[TRAIN] epoch: 191, iter: 3240/16000, loss: 0.2477, lr: 0.008158, batch_cost: 0.2433, reader_cost: 0.04055, ips: 32.8816 samples/sec | ETA 00:51:44
2023-03-06 19:57:21 [INFO]	[TRAIN] epoch: 192, iter: 3250/16000, loss: 0.2173, lr: 0.008152, batch_cost: 0.2554, reader_cost: 0.05338, ips: 31.3248 samples/sec | ETA 00:54:16
2023-03-06 19:57:23 [INFO]	[TRAIN] epoch: 192, iter: 3260/16000, loss: 0.4238, lr: 0.008147, batch_cost: 0.1933, reader_cost: 0.00032, ips: 41.3836 samples/sec | ETA 00:41:02
2023-03-06 19:57:26 [INFO]	[TRAIN] epoch: 193, iter: 3270/16000, loss: 0.2456, lr: 0.008141, batch_cost: 0.2625, reader_cost: 0.04580, ips: 30.4814 samples/sec | ETA 00:55:41
2023-03-06 19:57:28 [INFO]	[TRAIN] epoch: 193, iter: 3280/16000, loss: 0.2545, lr: 0.008135, batch_cost: 0.2067, reader_cost: 0.00028, ips: 38.6957 samples/sec | ETA 00:43:49
2023-03-06 19:57:30 [INFO]	[TRAIN] epoch: 194, iter: 3290/16000, loss: 0.2564, lr: 0.008129, batch_cost: 0.2808, reader_cost: 0.05698, ips: 28.4909 samples/sec | ETA 00:59:28
2023-03-06 19:57:33 [INFO]	[TRAIN] epoch: 195, iter: 3300/16000, loss: 0.3071, lr: 0.008124, batch_cost: 0.2982, reader_cost: 0.06259, ips: 26.8270 samples/sec | ETA 01:03:07
2023-03-06 19:57:35 [INFO]	[TRAIN] epoch: 195, iter: 3310/16000, loss: 0.2428, lr: 0.008118, batch_cost: 0.1952, reader_cost: 0.00033, ips: 40.9894 samples/sec | ETA 00:41:16
2023-03-06 19:57:38 [INFO]	[TRAIN] epoch: 196, iter: 3320/16000, loss: 0.3217, lr: 0.008112, batch_cost: 0.2596, reader_cost: 0.04774, ips: 30.8161 samples/sec | ETA 00:54:51
2023-03-06 19:57:40 [INFO]	[TRAIN] epoch: 196, iter: 3330/16000, loss: 0.2435, lr: 0.008106, batch_cost: 0.2000, reader_cost: 0.00028, ips: 40.0025 samples/sec | ETA 00:42:13
2023-03-06 19:57:43 [INFO]	[TRAIN] epoch: 197, iter: 3340/16000, loss: 0.2865, lr: 0.008101, batch_cost: 0.2712, reader_cost: 0.04643, ips: 29.5000 samples/sec | ETA 00:57:13
2023-03-06 19:57:45 [INFO]	[TRAIN] epoch: 198, iter: 3350/16000, loss: 0.1985, lr: 0.008095, batch_cost: 0.2641, reader_cost: 0.05085, ips: 30.2903 samples/sec | ETA 00:55:41
2023-03-06 19:57:47 [INFO]	[TRAIN] epoch: 198, iter: 3360/16000, loss: 0.2213, lr: 0.008089, batch_cost: 0.1991, reader_cost: 0.00050, ips: 40.1908 samples/sec | ETA 00:41:56
2023-03-06 19:57:50 [INFO]	[TRAIN] epoch: 199, iter: 3370/16000, loss: 0.3509, lr: 0.008083, batch_cost: 0.2767, reader_cost: 0.06499, ips: 28.9126 samples/sec | ETA 00:58:14
2023-03-06 19:57:52 [INFO]	[TRAIN] epoch: 199, iter: 3380/16000, loss: 0.2274, lr: 0.008077, batch_cost: 0.2069, reader_cost: 0.00029, ips: 38.6735 samples/sec | ETA 00:43:30
2023-03-06 19:57:55 [INFO]	[TRAIN] epoch: 200, iter: 3390/16000, loss: 0.2835, lr: 0.008072, batch_cost: 0.2620, reader_cost: 0.05777, ips: 30.5296 samples/sec | ETA 00:55:04
2023-03-06 19:57:57 [INFO]	[TRAIN] epoch: 200, iter: 3400/16000, loss: 0.4035, lr: 0.008066, batch_cost: 0.1968, reader_cost: 0.00026, ips: 40.6590 samples/sec | ETA 00:41:19
2023-03-06 19:58:00 [INFO]	[TRAIN] epoch: 201, iter: 3410/16000, loss: 0.3176, lr: 0.008060, batch_cost: 0.2967, reader_cost: 0.05590, ips: 26.9635 samples/sec | ETA 01:02:15
2023-03-06 19:58:04 [INFO]	[TRAIN] epoch: 202, iter: 3420/16000, loss: 0.2827, lr: 0.008054, batch_cost: 0.3876, reader_cost: 0.07489, ips: 20.6404 samples/sec | ETA 01:21:15
2023-03-06 19:58:06 [INFO]	[TRAIN] epoch: 202, iter: 3430/16000, loss: 0.2904, lr: 0.008049, batch_cost: 0.2797, reader_cost: 0.00032, ips: 28.6012 samples/sec | ETA 00:58:35
2023-03-06 19:58:10 [INFO]	[TRAIN] epoch: 203, iter: 3440/16000, loss: 0.2780, lr: 0.008043, batch_cost: 0.3730, reader_cost: 0.06200, ips: 21.4451 samples/sec | ETA 01:18:05
2023-03-06 19:58:13 [INFO]	[TRAIN] epoch: 203, iter: 3450/16000, loss: 0.2782, lr: 0.008037, batch_cost: 0.3401, reader_cost: 0.00167, ips: 23.5251 samples/sec | ETA 01:11:07
2023-03-06 19:58:17 [INFO]	[TRAIN] epoch: 204, iter: 3460/16000, loss: 0.2150, lr: 0.008031, batch_cost: 0.3623, reader_cost: 0.04838, ips: 22.0813 samples/sec | ETA 01:15:43
2023-03-06 19:58:20 [INFO]	[TRAIN] epoch: 205, iter: 3470/16000, loss: 0.2379, lr: 0.008026, batch_cost: 0.3114, reader_cost: 0.07679, ips: 25.6885 samples/sec | ETA 01:05:02
2023-03-06 19:58:24 [INFO]	[TRAIN] epoch: 205, iter: 3480/16000, loss: 0.3418, lr: 0.008020, batch_cost: 0.3424, reader_cost: 0.00031, ips: 23.3676 samples/sec | ETA 01:11:26
2023-03-06 19:58:27 [INFO]	[TRAIN] epoch: 206, iter: 3490/16000, loss: 0.3652, lr: 0.008014, batch_cost: 0.3586, reader_cost: 0.06409, ips: 22.3111 samples/sec | ETA 01:14:45
2023-03-06 19:58:29 [INFO]	[TRAIN] epoch: 206, iter: 3500/16000, loss: 0.2221, lr: 0.008008, batch_cost: 0.2122, reader_cost: 0.00030, ips: 37.7072 samples/sec | ETA 00:44:12
2023-03-06 19:58:33 [INFO]	[TRAIN] epoch: 207, iter: 3510/16000, loss: 0.2778, lr: 0.008003, batch_cost: 0.3531, reader_cost: 0.06134, ips: 22.6583 samples/sec | ETA 01:13:29
2023-03-06 19:58:36 [INFO]	[TRAIN] epoch: 208, iter: 3520/16000, loss: 0.3226, lr: 0.007997, batch_cost: 0.3511, reader_cost: 0.04705, ips: 22.7870 samples/sec | ETA 01:13:01
2023-03-06 19:58:40 [INFO]	[TRAIN] epoch: 208, iter: 3530/16000, loss: 0.3620, lr: 0.007991, batch_cost: 0.3579, reader_cost: 0.00155, ips: 22.3519 samples/sec | ETA 01:14:23
2023-03-06 19:58:44 [INFO]	[TRAIN] epoch: 209, iter: 3540/16000, loss: 0.2530, lr: 0.007985, batch_cost: 0.3892, reader_cost: 0.08204, ips: 20.5566 samples/sec | ETA 01:20:49
2023-03-06 19:58:46 [INFO]	[TRAIN] epoch: 209, iter: 3550/16000, loss: 0.2942, lr: 0.007980, batch_cost: 0.2091, reader_cost: 0.00030, ips: 38.2579 samples/sec | ETA 00:43:23
2023-03-06 19:58:49 [INFO]	[TRAIN] epoch: 210, iter: 3560/16000, loss: 0.2239, lr: 0.007974, batch_cost: 0.3132, reader_cost: 0.04987, ips: 25.5426 samples/sec | ETA 01:04:56
2023-03-06 19:58:52 [INFO]	[TRAIN] epoch: 210, iter: 3570/16000, loss: 0.3307, lr: 0.007968, batch_cost: 0.2878, reader_cost: 0.00030, ips: 27.7938 samples/sec | ETA 00:59:37
2023-03-06 19:58:55 [INFO]	[TRAIN] epoch: 211, iter: 3580/16000, loss: 0.2416, lr: 0.007962, batch_cost: 0.3489, reader_cost: 0.04516, ips: 22.9308 samples/sec | ETA 01:12:13
2023-03-06 19:58:59 [INFO]	[TRAIN] epoch: 212, iter: 3590/16000, loss: 0.3197, lr: 0.007956, batch_cost: 0.3212, reader_cost: 0.04457, ips: 24.9041 samples/sec | ETA 01:06:26
2023-03-06 19:59:02 [INFO]	[TRAIN] epoch: 212, iter: 3600/16000, loss: 0.2540, lr: 0.007951, batch_cost: 0.3012, reader_cost: 0.00038, ips: 26.5599 samples/sec | ETA 01:02:14
2023-03-06 19:59:06 [INFO]	[TRAIN] epoch: 213, iter: 3610/16000, loss: 0.2676, lr: 0.007945, batch_cost: 0.4019, reader_cost: 0.07143, ips: 19.9035 samples/sec | ETA 01:23:00
2023-03-06 19:59:08 [INFO]	[TRAIN] epoch: 213, iter: 3620/16000, loss: 0.2705, lr: 0.007939, batch_cost: 0.2262, reader_cost: 0.00031, ips: 35.3679 samples/sec | ETA 00:46:40
2023-03-06 19:59:12 [INFO]	[TRAIN] epoch: 214, iter: 3630/16000, loss: 0.3067, lr: 0.007933, batch_cost: 0.3668, reader_cost: 0.04994, ips: 21.8100 samples/sec | ETA 01:15:37
2023-03-06 19:59:15 [INFO]	[TRAIN] epoch: 215, iter: 3640/16000, loss: 0.2271, lr: 0.007928, batch_cost: 0.3415, reader_cost: 0.05994, ips: 23.4265 samples/sec | ETA 01:10:20
2023-03-06 19:59:18 [INFO]	[TRAIN] epoch: 215, iter: 3650/16000, loss: 0.2534, lr: 0.007922, batch_cost: 0.3296, reader_cost: 0.00036, ips: 24.2736 samples/sec | ETA 01:07:50
2023-03-06 19:59:21 [INFO]	[TRAIN] epoch: 216, iter: 3660/16000, loss: 0.2545, lr: 0.007916, batch_cost: 0.3123, reader_cost: 0.05713, ips: 25.6186 samples/sec | ETA 01:04:13
2023-03-06 19:59:24 [INFO]	[TRAIN] epoch: 216, iter: 3670/16000, loss: 0.2789, lr: 0.007910, batch_cost: 0.2182, reader_cost: 0.00038, ips: 36.6699 samples/sec | ETA 00:44:49
2023-03-06 19:59:27 [INFO]	[TRAIN] epoch: 217, iter: 3680/16000, loss: 0.2488, lr: 0.007904, batch_cost: 0.2934, reader_cost: 0.06952, ips: 27.2657 samples/sec | ETA 01:00:14
2023-03-06 19:59:30 [INFO]	[TRAIN] epoch: 218, iter: 3690/16000, loss: 0.2425, lr: 0.007899, batch_cost: 0.3144, reader_cost: 0.06064, ips: 25.4447 samples/sec | ETA 01:04:30
2023-03-06 19:59:32 [INFO]	[TRAIN] epoch: 218, iter: 3700/16000, loss: 0.2487, lr: 0.007893, batch_cost: 0.2387, reader_cost: 0.00035, ips: 33.5101 samples/sec | ETA 00:48:56
2023-03-06 19:59:35 [INFO]	[TRAIN] epoch: 219, iter: 3710/16000, loss: 0.2342, lr: 0.007887, batch_cost: 0.3107, reader_cost: 0.05583, ips: 25.7488 samples/sec | ETA 01:03:38
2023-03-06 19:59:37 [INFO]	[TRAIN] epoch: 219, iter: 3720/16000, loss: 0.2123, lr: 0.007881, batch_cost: 0.2102, reader_cost: 0.00033, ips: 38.0558 samples/sec | ETA 00:43:01
2023-03-06 19:59:40 [INFO]	[TRAIN] epoch: 220, iter: 3730/16000, loss: 0.1720, lr: 0.007876, batch_cost: 0.3021, reader_cost: 0.05640, ips: 26.4771 samples/sec | ETA 01:01:47
2023-03-06 19:59:43 [INFO]	[TRAIN] epoch: 220, iter: 3740/16000, loss: 0.2903, lr: 0.007870, batch_cost: 0.2755, reader_cost: 0.00067, ips: 29.0390 samples/sec | ETA 00:56:17
2023-03-06 19:59:46 [INFO]	[TRAIN] epoch: 221, iter: 3750/16000, loss: 0.3480, lr: 0.007864, batch_cost: 0.3382, reader_cost: 0.06186, ips: 23.6580 samples/sec | ETA 01:09:02
2023-03-06 19:59:50 [INFO]	[TRAIN] epoch: 222, iter: 3760/16000, loss: 0.3585, lr: 0.007858, batch_cost: 0.3980, reader_cost: 0.09632, ips: 20.0986 samples/sec | ETA 01:21:11
2023-03-06 19:59:53 [INFO]	[TRAIN] epoch: 222, iter: 3770/16000, loss: 0.3691, lr: 0.007852, batch_cost: 0.2183, reader_cost: 0.00036, ips: 36.6386 samples/sec | ETA 00:44:30
2023-03-06 19:59:56 [INFO]	[TRAIN] epoch: 223, iter: 3780/16000, loss: 0.3872, lr: 0.007847, batch_cost: 0.3546, reader_cost: 0.04849, ips: 22.5611 samples/sec | ETA 01:12:13
2023-03-06 19:59:58 [INFO]	[TRAIN] epoch: 223, iter: 3790/16000, loss: 0.2526, lr: 0.007841, batch_cost: 0.2054, reader_cost: 0.00025, ips: 38.9499 samples/sec | ETA 00:41:47
2023-03-06 20:00:01 [INFO]	[TRAIN] epoch: 224, iter: 3800/16000, loss: 0.3961, lr: 0.007835, batch_cost: 0.3010, reader_cost: 0.07429, ips: 26.5757 samples/sec | ETA 01:01:12
2023-03-06 20:00:04 [INFO]	[TRAIN] epoch: 225, iter: 3810/16000, loss: 0.2013, lr: 0.007829, batch_cost: 0.3142, reader_cost: 0.06554, ips: 25.4650 samples/sec | ETA 01:03:49
2023-03-06 20:00:07 [INFO]	[TRAIN] epoch: 225, iter: 3820/16000, loss: 0.3112, lr: 0.007824, batch_cost: 0.2367, reader_cost: 0.00035, ips: 33.7999 samples/sec | ETA 00:48:02
2023-03-06 20:00:10 [INFO]	[TRAIN] epoch: 226, iter: 3830/16000, loss: 0.2229, lr: 0.007818, batch_cost: 0.3097, reader_cost: 0.06943, ips: 25.8348 samples/sec | ETA 01:02:48
2023-03-06 20:00:12 [INFO]	[TRAIN] epoch: 226, iter: 3840/16000, loss: 0.2146, lr: 0.007812, batch_cost: 0.2551, reader_cost: 0.00035, ips: 31.3602 samples/sec | ETA 00:51:42
2023-03-06 20:00:16 [INFO]	[TRAIN] epoch: 227, iter: 3850/16000, loss: 0.3085, lr: 0.007806, batch_cost: 0.3604, reader_cost: 0.04629, ips: 22.1970 samples/sec | ETA 01:12:58
2023-03-06 20:00:19 [INFO]	[TRAIN] epoch: 228, iter: 3860/16000, loss: 0.2719, lr: 0.007800, batch_cost: 0.3164, reader_cost: 0.03953, ips: 25.2844 samples/sec | ETA 01:04:01
2023-03-06 20:00:21 [INFO]	[TRAIN] epoch: 228, iter: 3870/16000, loss: 0.2474, lr: 0.007795, batch_cost: 0.2132, reader_cost: 0.00032, ips: 37.5242 samples/sec | ETA 00:43:06
2023-03-06 20:00:24 [INFO]	[TRAIN] epoch: 229, iter: 3880/16000, loss: 0.2811, lr: 0.007789, batch_cost: 0.2740, reader_cost: 0.05743, ips: 29.1979 samples/sec | ETA 00:55:20
2023-03-06 20:00:26 [INFO]	[TRAIN] epoch: 229, iter: 3890/16000, loss: 0.1942, lr: 0.007783, batch_cost: 0.2082, reader_cost: 0.00031, ips: 38.4227 samples/sec | ETA 00:42:01
2023-03-06 20:00:29 [INFO]	[TRAIN] epoch: 230, iter: 3900/16000, loss: 0.2042, lr: 0.007777, batch_cost: 0.2823, reader_cost: 0.03737, ips: 28.3424 samples/sec | ETA 00:56:55
2023-03-06 20:00:31 [INFO]	[TRAIN] epoch: 230, iter: 3910/16000, loss: 0.2350, lr: 0.007772, batch_cost: 0.2310, reader_cost: 0.00028, ips: 34.6301 samples/sec | ETA 00:46:32
2023-03-06 20:00:34 [INFO]	[TRAIN] epoch: 231, iter: 3920/16000, loss: 0.3288, lr: 0.007766, batch_cost: 0.2720, reader_cost: 0.07088, ips: 29.4148 samples/sec | ETA 00:54:45
2023-03-06 20:00:37 [INFO]	[TRAIN] epoch: 232, iter: 3930/16000, loss: 0.4022, lr: 0.007760, batch_cost: 0.2531, reader_cost: 0.04676, ips: 31.6059 samples/sec | ETA 00:50:55
2023-03-06 20:00:39 [INFO]	[TRAIN] epoch: 232, iter: 3940/16000, loss: 0.2879, lr: 0.007754, batch_cost: 0.2224, reader_cost: 0.00034, ips: 35.9778 samples/sec | ETA 00:44:41
2023-03-06 20:00:42 [INFO]	[TRAIN] epoch: 233, iter: 3950/16000, loss: 0.2623, lr: 0.007748, batch_cost: 0.3013, reader_cost: 0.04993, ips: 26.5490 samples/sec | ETA 01:00:31
2023-03-06 20:00:44 [INFO]	[TRAIN] epoch: 233, iter: 3960/16000, loss: 0.3237, lr: 0.007743, batch_cost: 0.1989, reader_cost: 0.00027, ips: 40.2218 samples/sec | ETA 00:39:54
2023-03-06 20:00:46 [INFO]	[TRAIN] epoch: 234, iter: 3970/16000, loss: 0.3766, lr: 0.007737, batch_cost: 0.2706, reader_cost: 0.04374, ips: 29.5682 samples/sec | ETA 00:54:14
2023-03-06 20:00:50 [INFO]	[TRAIN] epoch: 235, iter: 3980/16000, loss: 0.2415, lr: 0.007731, batch_cost: 0.3103, reader_cost: 0.06192, ips: 25.7805 samples/sec | ETA 01:02:09
2023-03-06 20:00:52 [INFO]	[TRAIN] epoch: 235, iter: 3990/16000, loss: 0.2151, lr: 0.007725, batch_cost: 0.2057, reader_cost: 0.00031, ips: 38.8955 samples/sec | ETA 00:41:10
2023-03-06 20:00:55 [INFO]	[TRAIN] epoch: 236, iter: 4000/16000, loss: 0.2449, lr: 0.007719, batch_cost: 0.3367, reader_cost: 0.06319, ips: 23.7635 samples/sec | ETA 01:07:19
2023-03-06 20:00:55 [INFO]	Start evaluating (total_samples: 119, total_iters: 60)...
60/60 - 6s - batch_cost: 0.1050 - reader cost: 0.0024
2023-03-06 20:01:01 [INFO]	[EVAL] #Images: 119 mIoU: 0.7415 Acc: 0.9214 Kappa: 0.6809 Dice: 0.8404
2023-03-06 20:01:01 [INFO]	[EVAL] Class IoU: 
[0.9122 0.5708]
2023-03-06 20:01:01 [INFO]	[EVAL] Class Precision: 
[0.949  0.7507]
2023-03-06 20:01:01 [INFO]	[EVAL] Class Recall: 
[0.9592 0.7043]
2023-03-06 20:01:02 [INFO]	[EVAL] The model with the best validation mIoU (0.7632) was saved at iter 1000.
2023-03-06 20:01:06 [INFO]	[TRAIN] epoch: 236, iter: 4010/16000, loss: 0.2314, lr: 0.007714, batch_cost: 0.3543, reader_cost: 0.00035, ips: 22.5815 samples/sec | ETA 01:10:47
2023-03-06 20:01:09 [INFO]	[TRAIN] epoch: 237, iter: 4020/16000, loss: 0.2521, lr: 0.007708, batch_cost: 0.3235, reader_cost: 0.07238, ips: 24.7294 samples/sec | ETA 01:04:35
2023-03-06 20:01:12 [INFO]	[TRAIN] epoch: 238, iter: 4030/16000, loss: 0.3347, lr: 0.007702, batch_cost: 0.2601, reader_cost: 0.04323, ips: 30.7563 samples/sec | ETA 00:51:53
2023-03-06 20:01:15 [INFO]	[TRAIN] epoch: 238, iter: 4040/16000, loss: 0.2208, lr: 0.007696, batch_cost: 0.2724, reader_cost: 0.00049, ips: 29.3709 samples/sec | ETA 00:54:17
2023-03-06 20:01:17 [INFO]	[TRAIN] epoch: 239, iter: 4050/16000, loss: 0.2648, lr: 0.007691, batch_cost: 0.2657, reader_cost: 0.05411, ips: 30.1132 samples/sec | ETA 00:52:54
2023-03-06 20:01:19 [INFO]	[TRAIN] epoch: 239, iter: 4060/16000, loss: 0.2405, lr: 0.007685, batch_cost: 0.2061, reader_cost: 0.00029, ips: 38.8144 samples/sec | ETA 00:41:00
2023-03-06 20:01:22 [INFO]	[TRAIN] epoch: 240, iter: 4070/16000, loss: 0.2652, lr: 0.007679, batch_cost: 0.2725, reader_cost: 0.05086, ips: 29.3563 samples/sec | ETA 00:54:11
2023-03-06 20:01:24 [INFO]	[TRAIN] epoch: 240, iter: 4080/16000, loss: 0.3097, lr: 0.007673, batch_cost: 0.1974, reader_cost: 0.00025, ips: 40.5221 samples/sec | ETA 00:39:13
2023-03-06 20:01:27 [INFO]	[TRAIN] epoch: 241, iter: 4090/16000, loss: 0.3029, lr: 0.007667, batch_cost: 0.2648, reader_cost: 0.05178, ips: 30.2099 samples/sec | ETA 00:52:33
2023-03-06 20:01:30 [INFO]	[TRAIN] epoch: 242, iter: 4100/16000, loss: 0.2586, lr: 0.007662, batch_cost: 0.3776, reader_cost: 0.06661, ips: 21.1866 samples/sec | ETA 01:14:53
2023-03-06 20:01:33 [INFO]	[TRAIN] epoch: 242, iter: 4110/16000, loss: 0.1952, lr: 0.007656, batch_cost: 0.2569, reader_cost: 0.00036, ips: 31.1448 samples/sec | ETA 00:50:54
2023-03-06 20:01:36 [INFO]	[TRAIN] epoch: 243, iter: 4120/16000, loss: 0.2466, lr: 0.007650, batch_cost: 0.2684, reader_cost: 0.05623, ips: 29.8093 samples/sec | ETA 00:53:08
2023-03-06 20:01:38 [INFO]	[TRAIN] epoch: 243, iter: 4130/16000, loss: 0.2571, lr: 0.007644, batch_cost: 0.2016, reader_cost: 0.00027, ips: 39.6834 samples/sec | ETA 00:39:52
2023-03-06 20:01:41 [INFO]	[TRAIN] epoch: 244, iter: 4140/16000, loss: 0.3229, lr: 0.007638, batch_cost: 0.2851, reader_cost: 0.03643, ips: 28.0558 samples/sec | ETA 00:56:21
2023-03-06 20:01:43 [INFO]	[TRAIN] epoch: 245, iter: 4150/16000, loss: 0.2549, lr: 0.007633, batch_cost: 0.2927, reader_cost: 0.04222, ips: 27.3281 samples/sec | ETA 00:57:48
2023-03-06 20:01:45 [INFO]	[TRAIN] epoch: 245, iter: 4160/16000, loss: 0.2338, lr: 0.007627, batch_cost: 0.1925, reader_cost: 0.00030, ips: 41.5560 samples/sec | ETA 00:37:59
2023-03-06 20:01:48 [INFO]	[TRAIN] epoch: 246, iter: 4170/16000, loss: 0.2389, lr: 0.007621, batch_cost: 0.2496, reader_cost: 0.04663, ips: 32.0450 samples/sec | ETA 00:49:13
2023-03-06 20:01:50 [INFO]	[TRAIN] epoch: 246, iter: 4180/16000, loss: 0.3385, lr: 0.007615, batch_cost: 0.1933, reader_cost: 0.00029, ips: 41.3881 samples/sec | ETA 00:38:04
2023-03-06 20:01:52 [INFO]	[TRAIN] epoch: 247, iter: 4190/16000, loss: 0.2554, lr: 0.007609, batch_cost: 0.2497, reader_cost: 0.05098, ips: 32.0441 samples/sec | ETA 00:49:08
2023-03-06 20:01:55 [INFO]	[TRAIN] epoch: 248, iter: 4200/16000, loss: 0.2806, lr: 0.007604, batch_cost: 0.2424, reader_cost: 0.04171, ips: 32.9997 samples/sec | ETA 00:47:40
2023-03-06 20:01:57 [INFO]	[TRAIN] epoch: 248, iter: 4210/16000, loss: 0.4057, lr: 0.007598, batch_cost: 0.1934, reader_cost: 0.00029, ips: 41.3557 samples/sec | ETA 00:38:00
2023-03-06 20:01:59 [INFO]	[TRAIN] epoch: 249, iter: 4220/16000, loss: 0.2228, lr: 0.007592, batch_cost: 0.2516, reader_cost: 0.03615, ips: 31.7993 samples/sec | ETA 00:49:23
2023-03-06 20:02:01 [INFO]	[TRAIN] epoch: 249, iter: 4230/16000, loss: 0.2604, lr: 0.007586, batch_cost: 0.1931, reader_cost: 0.00027, ips: 41.4338 samples/sec | ETA 00:37:52
2023-03-06 20:02:04 [INFO]	[TRAIN] epoch: 250, iter: 4240/16000, loss: 0.3380, lr: 0.007580, batch_cost: 0.2878, reader_cost: 0.03432, ips: 27.7925 samples/sec | ETA 00:56:25
2023-03-06 20:02:06 [INFO]	[TRAIN] epoch: 250, iter: 4250/16000, loss: 0.2120, lr: 0.007575, batch_cost: 0.1929, reader_cost: 0.00023, ips: 41.4666 samples/sec | ETA 00:37:46
2023-03-06 20:02:09 [INFO]	[TRAIN] epoch: 251, iter: 4260/16000, loss: 0.2310, lr: 0.007569, batch_cost: 0.2922, reader_cost: 0.04590, ips: 27.3769 samples/sec | ETA 00:57:10
2023-03-06 20:02:12 [INFO]	[TRAIN] epoch: 252, iter: 4270/16000, loss: 0.2770, lr: 0.007563, batch_cost: 0.2782, reader_cost: 0.05940, ips: 28.7557 samples/sec | ETA 00:54:23
2023-03-06 20:02:14 [INFO]	[TRAIN] epoch: 252, iter: 4280/16000, loss: 0.2769, lr: 0.007557, batch_cost: 0.1854, reader_cost: 0.00032, ips: 43.1510 samples/sec | ETA 00:36:12
2023-03-06 20:02:16 [INFO]	[TRAIN] epoch: 253, iter: 4290/16000, loss: 0.2635, lr: 0.007551, batch_cost: 0.2593, reader_cost: 0.03931, ips: 30.8512 samples/sec | ETA 00:50:36
2023-03-06 20:02:19 [INFO]	[TRAIN] epoch: 253, iter: 4300/16000, loss: 0.3170, lr: 0.007546, batch_cost: 0.2451, reader_cost: 0.00025, ips: 32.6334 samples/sec | ETA 00:47:48
2023-03-06 20:02:22 [INFO]	[TRAIN] epoch: 254, iter: 4310/16000, loss: 0.2628, lr: 0.007540, batch_cost: 0.3325, reader_cost: 0.11718, ips: 24.0606 samples/sec | ETA 01:04:46
2023-03-06 20:02:24 [INFO]	[TRAIN] epoch: 255, iter: 4320/16000, loss: 0.2024, lr: 0.007534, batch_cost: 0.2461, reader_cost: 0.04031, ips: 32.5090 samples/sec | ETA 00:47:54
2023-03-06 20:02:26 [INFO]	[TRAIN] epoch: 255, iter: 4330/16000, loss: 0.2982, lr: 0.007528, batch_cost: 0.1863, reader_cost: 0.00036, ips: 42.9443 samples/sec | ETA 00:36:13
2023-03-06 20:02:29 [INFO]	[TRAIN] epoch: 256, iter: 4340/16000, loss: 0.2398, lr: 0.007522, batch_cost: 0.2670, reader_cost: 0.04229, ips: 29.9612 samples/sec | ETA 00:51:53
2023-03-06 20:02:31 [INFO]	[TRAIN] epoch: 256, iter: 4350/16000, loss: 0.2607, lr: 0.007517, batch_cost: 0.2321, reader_cost: 0.00032, ips: 34.4670 samples/sec | ETA 00:45:04
2023-03-06 20:02:34 [INFO]	[TRAIN] epoch: 257, iter: 4360/16000, loss: 0.2358, lr: 0.007511, batch_cost: 0.2537, reader_cost: 0.04670, ips: 31.5316 samples/sec | ETA 00:49:13
2023-03-06 20:02:36 [INFO]	[TRAIN] epoch: 258, iter: 4370/16000, loss: 0.2935, lr: 0.007505, batch_cost: 0.2503, reader_cost: 0.03417, ips: 31.9587 samples/sec | ETA 00:48:31
2023-03-06 20:02:38 [INFO]	[TRAIN] epoch: 258, iter: 4380/16000, loss: 0.2562, lr: 0.007499, batch_cost: 0.2042, reader_cost: 0.00033, ips: 39.1845 samples/sec | ETA 00:39:32
2023-03-06 20:02:41 [INFO]	[TRAIN] epoch: 259, iter: 4390/16000, loss: 0.2468, lr: 0.007493, batch_cost: 0.2473, reader_cost: 0.04784, ips: 32.3438 samples/sec | ETA 00:47:51
2023-03-06 20:02:43 [INFO]	[TRAIN] epoch: 259, iter: 4400/16000, loss: 0.2818, lr: 0.007488, batch_cost: 0.1899, reader_cost: 0.00029, ips: 42.1208 samples/sec | ETA 00:36:43
2023-03-06 20:02:45 [INFO]	[TRAIN] epoch: 260, iter: 4410/16000, loss: 0.3200, lr: 0.007482, batch_cost: 0.2461, reader_cost: 0.05230, ips: 32.5009 samples/sec | ETA 00:47:32
2023-03-06 20:02:47 [INFO]	[TRAIN] epoch: 260, iter: 4420/16000, loss: 0.2280, lr: 0.007476, batch_cost: 0.1875, reader_cost: 0.00023, ips: 42.6614 samples/sec | ETA 00:36:11
2023-03-06 20:02:50 [INFO]	[TRAIN] epoch: 261, iter: 4430/16000, loss: 0.2884, lr: 0.007470, batch_cost: 0.2899, reader_cost: 0.04306, ips: 27.5931 samples/sec | ETA 00:55:54
2023-03-06 20:02:53 [INFO]	[TRAIN] epoch: 262, iter: 4440/16000, loss: 0.3451, lr: 0.007464, batch_cost: 0.2855, reader_cost: 0.04791, ips: 28.0258 samples/sec | ETA 00:54:59
2023-03-06 20:02:55 [INFO]	[TRAIN] epoch: 262, iter: 4450/16000, loss: 0.2394, lr: 0.007458, batch_cost: 0.1882, reader_cost: 0.00030, ips: 42.5097 samples/sec | ETA 00:36:13
2023-03-06 20:02:57 [INFO]	[TRAIN] epoch: 263, iter: 4460/16000, loss: 0.2749, lr: 0.007453, batch_cost: 0.2665, reader_cost: 0.05352, ips: 30.0214 samples/sec | ETA 00:51:15
2023-03-06 20:02:59 [INFO]	[TRAIN] epoch: 263, iter: 4470/16000, loss: 0.3470, lr: 0.007447, batch_cost: 0.1914, reader_cost: 0.00023, ips: 41.7873 samples/sec | ETA 00:36:47
2023-03-06 20:03:02 [INFO]	[TRAIN] epoch: 264, iter: 4480/16000, loss: 0.2237, lr: 0.007441, batch_cost: 0.2733, reader_cost: 0.04806, ips: 29.2771 samples/sec | ETA 00:52:27
2023-03-06 20:03:04 [INFO]	[TRAIN] epoch: 265, iter: 4490/16000, loss: 0.2107, lr: 0.007435, batch_cost: 0.2480, reader_cost: 0.05257, ips: 32.2542 samples/sec | ETA 00:47:34
2023-03-06 20:03:06 [INFO]	[TRAIN] epoch: 265, iter: 4500/16000, loss: 0.3689, lr: 0.007429, batch_cost: 0.1847, reader_cost: 0.00028, ips: 43.3141 samples/sec | ETA 00:35:24
2023-03-06 20:03:09 [INFO]	[TRAIN] epoch: 266, iter: 4510/16000, loss: 0.2612, lr: 0.007424, batch_cost: 0.2476, reader_cost: 0.03587, ips: 32.3165 samples/sec | ETA 00:47:24
2023-03-06 20:03:11 [INFO]	[TRAIN] epoch: 266, iter: 4520/16000, loss: 0.2287, lr: 0.007418, batch_cost: 0.1926, reader_cost: 0.00030, ips: 41.5335 samples/sec | ETA 00:36:51
2023-03-06 20:03:13 [INFO]	[TRAIN] epoch: 267, iter: 4530/16000, loss: 0.3184, lr: 0.007412, batch_cost: 0.2422, reader_cost: 0.04723, ips: 33.0340 samples/sec | ETA 00:46:17
2023-03-06 20:03:15 [INFO]	[TRAIN] epoch: 268, iter: 4540/16000, loss: 0.2760, lr: 0.007406, batch_cost: 0.2397, reader_cost: 0.04407, ips: 33.3773 samples/sec | ETA 00:45:46
2023-03-06 20:03:17 [INFO]	[TRAIN] epoch: 268, iter: 4550/16000, loss: 0.2800, lr: 0.007400, batch_cost: 0.1920, reader_cost: 0.00035, ips: 41.6620 samples/sec | ETA 00:36:38
2023-03-06 20:03:20 [INFO]	[TRAIN] epoch: 269, iter: 4560/16000, loss: 0.2492, lr: 0.007395, batch_cost: 0.2489, reader_cost: 0.04392, ips: 32.1443 samples/sec | ETA 00:47:27
2023-03-06 20:03:22 [INFO]	[TRAIN] epoch: 269, iter: 4570/16000, loss: 0.2548, lr: 0.007389, batch_cost: 0.1929, reader_cost: 0.00026, ips: 41.4656 samples/sec | ETA 00:36:45
2023-03-06 20:03:24 [INFO]	[TRAIN] epoch: 270, iter: 4580/16000, loss: 0.2094, lr: 0.007383, batch_cost: 0.2472, reader_cost: 0.05058, ips: 32.3579 samples/sec | ETA 00:47:03
2023-03-06 20:03:26 [INFO]	[TRAIN] epoch: 270, iter: 4590/16000, loss: 0.1830, lr: 0.007377, batch_cost: 0.1849, reader_cost: 0.00020, ips: 43.2613 samples/sec | ETA 00:35:09
2023-03-06 20:03:29 [INFO]	[TRAIN] epoch: 271, iter: 4600/16000, loss: 0.2192, lr: 0.007371, batch_cost: 0.2639, reader_cost: 0.03341, ips: 30.3097 samples/sec | ETA 00:50:08
2023-03-06 20:03:31 [INFO]	[TRAIN] epoch: 272, iter: 4610/16000, loss: 0.2833, lr: 0.007365, batch_cost: 0.2472, reader_cost: 0.03279, ips: 32.3643 samples/sec | ETA 00:46:55
2023-03-06 20:03:33 [INFO]	[TRAIN] epoch: 272, iter: 4620/16000, loss: 0.2831, lr: 0.007360, batch_cost: 0.1902, reader_cost: 0.00031, ips: 42.0564 samples/sec | ETA 00:36:04
2023-03-06 20:03:36 [INFO]	[TRAIN] epoch: 273, iter: 4630/16000, loss: 0.2323, lr: 0.007354, batch_cost: 0.2488, reader_cost: 0.04391, ips: 32.1514 samples/sec | ETA 00:47:09
2023-03-06 20:03:38 [INFO]	[TRAIN] epoch: 273, iter: 4640/16000, loss: 0.1849, lr: 0.007348, batch_cost: 0.1874, reader_cost: 0.00027, ips: 42.6948 samples/sec | ETA 00:35:28
2023-03-06 20:03:40 [INFO]	[TRAIN] epoch: 274, iter: 4650/16000, loss: 0.2675, lr: 0.007342, batch_cost: 0.2871, reader_cost: 0.06652, ips: 27.8638 samples/sec | ETA 00:54:18
2023-03-06 20:03:43 [INFO]	[TRAIN] epoch: 275, iter: 4660/16000, loss: 0.2861, lr: 0.007336, batch_cost: 0.2534, reader_cost: 0.05100, ips: 31.5714 samples/sec | ETA 00:47:53
2023-03-06 20:03:45 [INFO]	[TRAIN] epoch: 275, iter: 4670/16000, loss: 0.2560, lr: 0.007330, batch_cost: 0.2056, reader_cost: 0.00031, ips: 38.9177 samples/sec | ETA 00:38:49
2023-03-06 20:03:48 [INFO]	[TRAIN] epoch: 276, iter: 4680/16000, loss: 0.2630, lr: 0.007325, batch_cost: 0.2534, reader_cost: 0.04066, ips: 31.5653 samples/sec | ETA 00:47:48
2023-03-06 20:03:49 [INFO]	[TRAIN] epoch: 276, iter: 4690/16000, loss: 0.3426, lr: 0.007319, batch_cost: 0.1844, reader_cost: 0.00024, ips: 43.3878 samples/sec | ETA 00:34:45
2023-03-06 20:03:52 [INFO]	[TRAIN] epoch: 277, iter: 4700/16000, loss: 0.2333, lr: 0.007313, batch_cost: 0.2585, reader_cost: 0.04832, ips: 30.9498 samples/sec | ETA 00:48:40
2023-03-06 20:03:55 [INFO]	[TRAIN] epoch: 278, iter: 4710/16000, loss: 0.2774, lr: 0.007307, batch_cost: 0.2530, reader_cost: 0.03326, ips: 31.6200 samples/sec | ETA 00:47:36
2023-03-06 20:03:56 [INFO]	[TRAIN] epoch: 278, iter: 4720/16000, loss: 0.2205, lr: 0.007301, batch_cost: 0.1951, reader_cost: 0.00032, ips: 41.0018 samples/sec | ETA 00:36:40
2023-03-06 20:03:59 [INFO]	[TRAIN] epoch: 279, iter: 4730/16000, loss: 0.2998, lr: 0.007296, batch_cost: 0.2466, reader_cost: 0.04659, ips: 32.4477 samples/sec | ETA 00:46:18
2023-03-06 20:04:01 [INFO]	[TRAIN] epoch: 279, iter: 4740/16000, loss: 0.2189, lr: 0.007290, batch_cost: 0.1878, reader_cost: 0.00029, ips: 42.5908 samples/sec | ETA 00:35:15
2023-03-06 20:04:03 [INFO]	[TRAIN] epoch: 280, iter: 4750/16000, loss: 0.2257, lr: 0.007284, batch_cost: 0.2464, reader_cost: 0.03970, ips: 32.4717 samples/sec | ETA 00:46:11
2023-03-06 20:04:05 [INFO]	[TRAIN] epoch: 280, iter: 4760/16000, loss: 0.2095, lr: 0.007278, batch_cost: 0.1866, reader_cost: 0.00027, ips: 42.8611 samples/sec | ETA 00:34:57
2023-03-06 20:04:08 [INFO]	[TRAIN] epoch: 281, iter: 4770/16000, loss: 0.2447, lr: 0.007272, batch_cost: 0.2527, reader_cost: 0.05016, ips: 31.6626 samples/sec | ETA 00:47:17
2023-03-06 20:04:10 [INFO]	[TRAIN] epoch: 282, iter: 4780/16000, loss: 0.2792, lr: 0.007266, batch_cost: 0.2568, reader_cost: 0.05171, ips: 31.1554 samples/sec | ETA 00:48:01
2023-03-06 20:04:12 [INFO]	[TRAIN] epoch: 282, iter: 4790/16000, loss: 0.2602, lr: 0.007261, batch_cost: 0.1964, reader_cost: 0.00025, ips: 40.7423 samples/sec | ETA 00:36:41
2023-03-06 20:04:15 [INFO]	[TRAIN] epoch: 283, iter: 4800/16000, loss: 0.2176, lr: 0.007255, batch_cost: 0.2601, reader_cost: 0.05559, ips: 30.7603 samples/sec | ETA 00:48:32
2023-03-06 20:04:17 [INFO]	[TRAIN] epoch: 283, iter: 4810/16000, loss: 0.2181, lr: 0.007249, batch_cost: 0.1905, reader_cost: 0.00027, ips: 42.0008 samples/sec | ETA 00:35:31
2023-03-06 20:04:20 [INFO]	[TRAIN] epoch: 284, iter: 4820/16000, loss: 0.2723, lr: 0.007243, batch_cost: 0.2851, reader_cost: 0.04642, ips: 28.0561 samples/sec | ETA 00:53:07
2023-03-06 20:04:22 [INFO]	[TRAIN] epoch: 285, iter: 4830/16000, loss: 0.2481, lr: 0.007237, batch_cost: 0.2564, reader_cost: 0.05417, ips: 31.2019 samples/sec | ETA 00:47:43
2023-03-06 20:04:24 [INFO]	[TRAIN] epoch: 285, iter: 4840/16000, loss: 0.2640, lr: 0.007231, batch_cost: 0.1860, reader_cost: 0.00038, ips: 43.0085 samples/sec | ETA 00:34:35
2023-03-06 20:04:26 [INFO]	[TRAIN] epoch: 286, iter: 4850/16000, loss: 0.2801, lr: 0.007226, batch_cost: 0.2452, reader_cost: 0.04919, ips: 32.6251 samples/sec | ETA 00:45:34
2023-03-06 20:04:28 [INFO]	[TRAIN] epoch: 286, iter: 4860/16000, loss: 0.2698, lr: 0.007220, batch_cost: 0.1916, reader_cost: 0.00023, ips: 41.7538 samples/sec | ETA 00:35:34
2023-03-06 20:04:31 [INFO]	[TRAIN] epoch: 287, iter: 4870/16000, loss: 0.1817, lr: 0.007214, batch_cost: 0.2457, reader_cost: 0.04781, ips: 32.5664 samples/sec | ETA 00:45:34
2023-03-06 20:04:33 [INFO]	[TRAIN] epoch: 288, iter: 4880/16000, loss: 0.1979, lr: 0.007208, batch_cost: 0.2404, reader_cost: 0.04555, ips: 33.2732 samples/sec | ETA 00:44:33
2023-03-06 20:04:35 [INFO]	[TRAIN] epoch: 288, iter: 4890/16000, loss: 0.1911, lr: 0.007202, batch_cost: 0.1883, reader_cost: 0.00028, ips: 42.4829 samples/sec | ETA 00:34:52
2023-03-06 20:04:38 [INFO]	[TRAIN] epoch: 289, iter: 4900/16000, loss: 0.2467, lr: 0.007196, batch_cost: 0.2497, reader_cost: 0.05703, ips: 32.0426 samples/sec | ETA 00:46:11
2023-03-06 20:04:39 [INFO]	[TRAIN] epoch: 289, iter: 4910/16000, loss: 0.2581, lr: 0.007191, batch_cost: 0.1872, reader_cost: 0.00029, ips: 42.7455 samples/sec | ETA 00:34:35
2023-03-06 20:04:42 [INFO]	[TRAIN] epoch: 290, iter: 4920/16000, loss: 0.2558, lr: 0.007185, batch_cost: 0.2774, reader_cost: 0.04491, ips: 28.8365 samples/sec | ETA 00:51:13
2023-03-06 20:04:44 [INFO]	[TRAIN] epoch: 290, iter: 4930/16000, loss: 0.2259, lr: 0.007179, batch_cost: 0.1946, reader_cost: 0.00029, ips: 41.1026 samples/sec | ETA 00:35:54
2023-03-06 20:04:47 [INFO]	[TRAIN] epoch: 291, iter: 4940/16000, loss: 0.2116, lr: 0.007173, batch_cost: 0.2654, reader_cost: 0.05464, ips: 30.1471 samples/sec | ETA 00:48:54
2023-03-06 20:04:49 [INFO]	[TRAIN] epoch: 292, iter: 4950/16000, loss: 0.2337, lr: 0.007167, batch_cost: 0.2440, reader_cost: 0.04442, ips: 32.7892 samples/sec | ETA 00:44:56
2023-03-06 20:04:51 [INFO]	[TRAIN] epoch: 292, iter: 4960/16000, loss: 0.3005, lr: 0.007161, batch_cost: 0.1951, reader_cost: 0.00031, ips: 41.0030 samples/sec | ETA 00:35:53
2023-03-06 20:04:54 [INFO]	[TRAIN] epoch: 293, iter: 4970/16000, loss: 0.2764, lr: 0.007156, batch_cost: 0.2529, reader_cost: 0.04873, ips: 31.6303 samples/sec | ETA 00:46:29
2023-03-06 20:04:56 [INFO]	[TRAIN] epoch: 293, iter: 4980/16000, loss: 0.2366, lr: 0.007150, batch_cost: 0.1947, reader_cost: 0.00035, ips: 41.0834 samples/sec | ETA 00:35:45
2023-03-06 20:04:58 [INFO]	[TRAIN] epoch: 294, iter: 4990/16000, loss: 0.2267, lr: 0.007144, batch_cost: 0.2571, reader_cost: 0.05252, ips: 31.1201 samples/sec | ETA 00:47:10
2023-03-06 20:05:01 [INFO]	[TRAIN] epoch: 295, iter: 5000/16000, loss: 0.2652, lr: 0.007138, batch_cost: 0.2681, reader_cost: 0.06596, ips: 29.8381 samples/sec | ETA 00:49:09
2023-03-06 20:05:01 [INFO]	Start evaluating (total_samples: 119, total_iters: 60)...
60/60 - 3s - batch_cost: 0.0539 - reader cost: 0.0021
2023-03-06 20:05:04 [INFO]	[EVAL] #Images: 119 mIoU: 0.7517 Acc: 0.9218 Kappa: 0.6973 Dice: 0.8486
2023-03-06 20:05:04 [INFO]	[EVAL] Class IoU: 
[0.9118 0.5916]
2023-03-06 20:05:04 [INFO]	[EVAL] Class Precision: 
[0.9582 0.7252]
2023-03-06 20:05:04 [INFO]	[EVAL] Class Recall: 
[0.9496 0.7625]
2023-03-06 20:05:05 [INFO]	[EVAL] The model with the best validation mIoU (0.7632) was saved at iter 1000.
2023-03-06 20:05:07 [INFO]	[TRAIN] epoch: 295, iter: 5010/16000, loss: 0.3093, lr: 0.007132, batch_cost: 0.1898, reader_cost: 0.00028, ips: 42.1430 samples/sec | ETA 00:34:46
2023-03-06 20:05:09 [INFO]	[TRAIN] epoch: 296, iter: 5020/16000, loss: 0.2237, lr: 0.007126, batch_cost: 0.2558, reader_cost: 0.04889, ips: 31.2735 samples/sec | ETA 00:46:48
2023-03-06 20:05:11 [INFO]	[TRAIN] epoch: 296, iter: 5030/16000, loss: 0.3687, lr: 0.007121, batch_cost: 0.1990, reader_cost: 0.00030, ips: 40.2053 samples/sec | ETA 00:36:22
2023-03-06 20:05:14 [INFO]	[TRAIN] epoch: 297, iter: 5040/16000, loss: 0.2547, lr: 0.007115, batch_cost: 0.2525, reader_cost: 0.04091, ips: 31.6791 samples/sec | ETA 00:46:07
2023-03-06 20:05:17 [INFO]	[TRAIN] epoch: 298, iter: 5050/16000, loss: 0.2355, lr: 0.007109, batch_cost: 0.2631, reader_cost: 0.06712, ips: 30.4019 samples/sec | ETA 00:48:01
2023-03-06 20:05:18 [INFO]	[TRAIN] epoch: 298, iter: 5060/16000, loss: 0.2308, lr: 0.007103, batch_cost: 0.1914, reader_cost: 0.00028, ips: 41.8026 samples/sec | ETA 00:34:53
2023-03-06 20:05:21 [INFO]	[TRAIN] epoch: 299, iter: 5070/16000, loss: 0.2464, lr: 0.007097, batch_cost: 0.2475, reader_cost: 0.04505, ips: 32.3210 samples/sec | ETA 00:45:05
2023-03-06 20:05:23 [INFO]	[TRAIN] epoch: 299, iter: 5080/16000, loss: 0.3996, lr: 0.007091, batch_cost: 0.1908, reader_cost: 0.00030, ips: 41.9351 samples/sec | ETA 00:34:43
2023-03-06 20:05:25 [INFO]	[TRAIN] epoch: 300, iter: 5090/16000, loss: 0.1949, lr: 0.007085, batch_cost: 0.2622, reader_cost: 0.03365, ips: 30.5156 samples/sec | ETA 00:47:40
2023-03-06 20:05:27 [INFO]	[TRAIN] epoch: 300, iter: 5100/16000, loss: 0.2465, lr: 0.007080, batch_cost: 0.1908, reader_cost: 0.00021, ips: 41.9396 samples/sec | ETA 00:34:39
2023-03-06 20:05:30 [INFO]	[TRAIN] epoch: 301, iter: 5110/16000, loss: 0.2455, lr: 0.007074, batch_cost: 0.2619, reader_cost: 0.03773, ips: 30.5445 samples/sec | ETA 00:47:32
2023-03-06 20:05:33 [INFO]	[TRAIN] epoch: 302, iter: 5120/16000, loss: 0.2691, lr: 0.007068, batch_cost: 0.2790, reader_cost: 0.05764, ips: 28.6718 samples/sec | ETA 00:50:35
2023-03-06 20:05:35 [INFO]	[TRAIN] epoch: 302, iter: 5130/16000, loss: 0.2538, lr: 0.007062, batch_cost: 0.1898, reader_cost: 0.00031, ips: 42.1414 samples/sec | ETA 00:34:23
2023-03-06 20:05:37 [INFO]	[TRAIN] epoch: 303, iter: 5140/16000, loss: 0.2254, lr: 0.007056, batch_cost: 0.2585, reader_cost: 0.04382, ips: 30.9454 samples/sec | ETA 00:46:47
2023-03-06 20:05:39 [INFO]	[TRAIN] epoch: 303, iter: 5150/16000, loss: 0.2045, lr: 0.007050, batch_cost: 0.1939, reader_cost: 0.00027, ips: 41.2490 samples/sec | ETA 00:35:04
2023-03-06 20:05:42 [INFO]	[TRAIN] epoch: 304, iter: 5160/16000, loss: 0.1688, lr: 0.007045, batch_cost: 0.2658, reader_cost: 0.05575, ips: 30.0933 samples/sec | ETA 00:48:01
2023-03-06 20:05:44 [INFO]	[TRAIN] epoch: 305, iter: 5170/16000, loss: 0.3931, lr: 0.007039, batch_cost: 0.2495, reader_cost: 0.03453, ips: 32.0611 samples/sec | ETA 00:45:02
2023-03-06 20:05:46 [INFO]	[TRAIN] epoch: 305, iter: 5180/16000, loss: 0.2767, lr: 0.007033, batch_cost: 0.1920, reader_cost: 0.00032, ips: 41.6649 samples/sec | ETA 00:34:37
2023-03-06 20:05:49 [INFO]	[TRAIN] epoch: 306, iter: 5190/16000, loss: 0.3326, lr: 0.007027, batch_cost: 0.2434, reader_cost: 0.03367, ips: 32.8712 samples/sec | ETA 00:43:50
2023-03-06 20:05:51 [INFO]	[TRAIN] epoch: 306, iter: 5200/16000, loss: 0.2638, lr: 0.007021, batch_cost: 0.1889, reader_cost: 0.00029, ips: 42.3507 samples/sec | ETA 00:34:00
2023-03-06 20:05:53 [INFO]	[TRAIN] epoch: 307, iter: 5210/16000, loss: 0.2272, lr: 0.007015, batch_cost: 0.2751, reader_cost: 0.03216, ips: 29.0830 samples/sec | ETA 00:49:28
2023-03-06 20:05:56 [INFO]	[TRAIN] epoch: 308, iter: 5220/16000, loss: 0.2641, lr: 0.007009, batch_cost: 0.2623, reader_cost: 0.06111, ips: 30.4966 samples/sec | ETA 00:47:07
2023-03-06 20:05:58 [INFO]	[TRAIN] epoch: 308, iter: 5230/16000, loss: 0.2906, lr: 0.007004, batch_cost: 0.1902, reader_cost: 0.00032, ips: 42.0546 samples/sec | ETA 00:34:08
2023-03-06 20:06:00 [INFO]	[TRAIN] epoch: 309, iter: 5240/16000, loss: 0.2897, lr: 0.006998, batch_cost: 0.2593, reader_cost: 0.05415, ips: 30.8476 samples/sec | ETA 00:46:30
2023-03-06 20:06:02 [INFO]	[TRAIN] epoch: 309, iter: 5250/16000, loss: 0.3097, lr: 0.006992, batch_cost: 0.2009, reader_cost: 0.00030, ips: 39.8176 samples/sec | ETA 00:35:59
2023-03-06 20:06:05 [INFO]	[TRAIN] epoch: 310, iter: 5260/16000, loss: 0.2804, lr: 0.006986, batch_cost: 0.2622, reader_cost: 0.03750, ips: 30.5155 samples/sec | ETA 00:46:55
2023-03-06 20:06:07 [INFO]	[TRAIN] epoch: 310, iter: 5270/16000, loss: 0.2909, lr: 0.006980, batch_cost: 0.1889, reader_cost: 0.00030, ips: 42.3553 samples/sec | ETA 00:33:46
2023-03-06 20:06:10 [INFO]	[TRAIN] epoch: 311, iter: 5280/16000, loss: 0.2375, lr: 0.006974, batch_cost: 0.2701, reader_cost: 0.04952, ips: 29.6144 samples/sec | ETA 00:48:15
2023-03-06 20:06:12 [INFO]	[TRAIN] epoch: 312, iter: 5290/16000, loss: 0.2812, lr: 0.006968, batch_cost: 0.2583, reader_cost: 0.04868, ips: 30.9761 samples/sec | ETA 00:46:06
2023-03-06 20:06:14 [INFO]	[TRAIN] epoch: 312, iter: 5300/16000, loss: 0.2081, lr: 0.006963, batch_cost: 0.2181, reader_cost: 0.00029, ips: 36.6746 samples/sec | ETA 00:38:54
2023-03-06 20:06:17 [INFO]	[TRAIN] epoch: 313, iter: 5310/16000, loss: 0.3194, lr: 0.006957, batch_cost: 0.2626, reader_cost: 0.03680, ips: 30.4601 samples/sec | ETA 00:46:47
2023-03-06 20:06:19 [INFO]	[TRAIN] epoch: 313, iter: 5320/16000, loss: 0.2486, lr: 0.006951, batch_cost: 0.1935, reader_cost: 0.00030, ips: 41.3456 samples/sec | ETA 00:34:26
2023-03-06 20:06:22 [INFO]	[TRAIN] epoch: 314, iter: 5330/16000, loss: 0.1938, lr: 0.006945, batch_cost: 0.2501, reader_cost: 0.04437, ips: 31.9882 samples/sec | ETA 00:44:28
2023-03-06 20:06:24 [INFO]	[TRAIN] epoch: 315, iter: 5340/16000, loss: 0.1789, lr: 0.006939, batch_cost: 0.2393, reader_cost: 0.04695, ips: 33.4317 samples/sec | ETA 00:42:30
2023-03-06 20:06:26 [INFO]	[TRAIN] epoch: 315, iter: 5350/16000, loss: 0.2822, lr: 0.006933, batch_cost: 0.1914, reader_cost: 0.00033, ips: 41.7915 samples/sec | ETA 00:33:58
2023-03-06 20:06:28 [INFO]	[TRAIN] epoch: 316, iter: 5360/16000, loss: 0.1980, lr: 0.006927, batch_cost: 0.2503, reader_cost: 0.04092, ips: 31.9657 samples/sec | ETA 00:44:22
2023-03-06 20:06:30 [INFO]	[TRAIN] epoch: 316, iter: 5370/16000, loss: 0.2343, lr: 0.006922, batch_cost: 0.1960, reader_cost: 0.00029, ips: 40.8179 samples/sec | ETA 00:34:43
2023-03-06 20:06:33 [INFO]	[TRAIN] epoch: 317, iter: 5380/16000, loss: 0.2094, lr: 0.006916, batch_cost: 0.2560, reader_cost: 0.05038, ips: 31.2440 samples/sec | ETA 00:45:19
2023-03-06 20:06:35 [INFO]	[TRAIN] epoch: 318, iter: 5390/16000, loss: 0.2216, lr: 0.006910, batch_cost: 0.2418, reader_cost: 0.04340, ips: 33.0790 samples/sec | ETA 00:42:45
2023-03-06 20:06:37 [INFO]	[TRAIN] epoch: 318, iter: 5400/16000, loss: 0.2757, lr: 0.006904, batch_cost: 0.1987, reader_cost: 0.00030, ips: 40.2688 samples/sec | ETA 00:35:05
2023-03-06 20:06:40 [INFO]	[TRAIN] epoch: 319, iter: 5410/16000, loss: 0.3523, lr: 0.006898, batch_cost: 0.2509, reader_cost: 0.04064, ips: 31.8814 samples/sec | ETA 00:44:17
2023-03-06 20:06:42 [INFO]	[TRAIN] epoch: 319, iter: 5420/16000, loss: 0.2767, lr: 0.006892, batch_cost: 0.1922, reader_cost: 0.00031, ips: 41.6144 samples/sec | ETA 00:33:53
2023-03-06 20:06:44 [INFO]	[TRAIN] epoch: 320, iter: 5430/16000, loss: 0.2288, lr: 0.006886, batch_cost: 0.2454, reader_cost: 0.04204, ips: 32.6018 samples/sec | ETA 00:43:13
2023-03-06 20:06:46 [INFO]	[TRAIN] epoch: 320, iter: 5440/16000, loss: 0.3562, lr: 0.006881, batch_cost: 0.1900, reader_cost: 0.00028, ips: 42.1141 samples/sec | ETA 00:33:25
2023-03-06 20:06:49 [INFO]	[TRAIN] epoch: 321, iter: 5450/16000, loss: 0.3142, lr: 0.006875, batch_cost: 0.2736, reader_cost: 0.07278, ips: 29.2448 samples/sec | ETA 00:48:05
2023-03-06 20:06:51 [INFO]	[TRAIN] epoch: 322, iter: 5460/16000, loss: 0.2069, lr: 0.006869, batch_cost: 0.2640, reader_cost: 0.04119, ips: 30.3036 samples/sec | ETA 00:46:22
2023-03-06 20:06:53 [INFO]	[TRAIN] epoch: 322, iter: 5470/16000, loss: 0.2439, lr: 0.006863, batch_cost: 0.1902, reader_cost: 0.00035, ips: 42.0650 samples/sec | ETA 00:33:22
2023-03-06 20:06:56 [INFO]	[TRAIN] epoch: 323, iter: 5480/16000, loss: 0.2657, lr: 0.006857, batch_cost: 0.2603, reader_cost: 0.06502, ips: 30.7379 samples/sec | ETA 00:45:37
2023-03-06 20:06:58 [INFO]	[TRAIN] epoch: 323, iter: 5490/16000, loss: 0.3287, lr: 0.006851, batch_cost: 0.1961, reader_cost: 0.00024, ips: 40.7973 samples/sec | ETA 00:34:20
2023-03-06 20:07:00 [INFO]	[TRAIN] epoch: 324, iter: 5500/16000, loss: 0.2139, lr: 0.006845, batch_cost: 0.2511, reader_cost: 0.04245, ips: 31.8654 samples/sec | ETA 00:43:56
2023-03-06 20:07:03 [INFO]	[TRAIN] epoch: 325, iter: 5510/16000, loss: 0.2702, lr: 0.006840, batch_cost: 0.2439, reader_cost: 0.04065, ips: 32.8001 samples/sec | ETA 00:42:38
2023-03-06 20:07:05 [INFO]	[TRAIN] epoch: 325, iter: 5520/16000, loss: 0.2067, lr: 0.006834, batch_cost: 0.1875, reader_cost: 0.00029, ips: 42.6585 samples/sec | ETA 00:32:45
2023-03-06 20:07:07 [INFO]	[TRAIN] epoch: 326, iter: 5530/16000, loss: 0.1838, lr: 0.006828, batch_cost: 0.2457, reader_cost: 0.04280, ips: 32.5561 samples/sec | ETA 00:42:52
2023-03-06 20:07:09 [INFO]	[TRAIN] epoch: 326, iter: 5540/16000, loss: 0.1993, lr: 0.006822, batch_cost: 0.1887, reader_cost: 0.00027, ips: 42.3902 samples/sec | ETA 00:32:54
2023-03-06 20:07:12 [INFO]	[TRAIN] epoch: 327, iter: 5550/16000, loss: 0.2735, lr: 0.006816, batch_cost: 0.3159, reader_cost: 0.05209, ips: 25.3216 samples/sec | ETA 00:55:01
2023-03-06 20:07:16 [INFO]	[TRAIN] epoch: 328, iter: 5560/16000, loss: 0.1792, lr: 0.006810, batch_cost: 0.3914, reader_cost: 0.07813, ips: 20.4385 samples/sec | ETA 01:08:06
2023-03-06 20:07:18 [INFO]	[TRAIN] epoch: 328, iter: 5570/16000, loss: 0.1893, lr: 0.006804, batch_cost: 0.2033, reader_cost: 0.00028, ips: 39.3440 samples/sec | ETA 00:35:20
2023-03-06 20:07:21 [INFO]	[TRAIN] epoch: 329, iter: 5580/16000, loss: 0.3234, lr: 0.006798, batch_cost: 0.2517, reader_cost: 0.03639, ips: 31.7879 samples/sec | ETA 00:43:42
2023-03-06 20:07:23 [INFO]	[TRAIN] epoch: 329, iter: 5590/16000, loss: 0.2459, lr: 0.006793, batch_cost: 0.1926, reader_cost: 0.00031, ips: 41.5283 samples/sec | ETA 00:33:25
2023-03-06 20:07:25 [INFO]	[TRAIN] epoch: 330, iter: 5600/16000, loss: 0.3041, lr: 0.006787, batch_cost: 0.2502, reader_cost: 0.04837, ips: 31.9746 samples/sec | ETA 00:43:22
2023-03-06 20:07:27 [INFO]	[TRAIN] epoch: 330, iter: 5610/16000, loss: 0.2162, lr: 0.006781, batch_cost: 0.1821, reader_cost: 0.00025, ips: 43.9258 samples/sec | ETA 00:31:32
2023-03-06 20:07:29 [INFO]	[TRAIN] epoch: 331, iter: 5620/16000, loss: 0.1862, lr: 0.006775, batch_cost: 0.2497, reader_cost: 0.05300, ips: 32.0445 samples/sec | ETA 00:43:11
2023-03-06 20:07:32 [INFO]	[TRAIN] epoch: 332, iter: 5630/16000, loss: 0.2445, lr: 0.006769, batch_cost: 0.2596, reader_cost: 0.06067, ips: 30.8132 samples/sec | ETA 00:44:52
2023-03-06 20:07:34 [INFO]	[TRAIN] epoch: 332, iter: 5640/16000, loss: 0.4053, lr: 0.006763, batch_cost: 0.1909, reader_cost: 0.00030, ips: 41.8988 samples/sec | ETA 00:32:58
2023-03-06 20:07:36 [INFO]	[TRAIN] epoch: 333, iter: 5650/16000, loss: 0.2407, lr: 0.006757, batch_cost: 0.2393, reader_cost: 0.04090, ips: 33.4256 samples/sec | ETA 00:41:17
2023-03-06 20:07:38 [INFO]	[TRAIN] epoch: 333, iter: 5660/16000, loss: 0.2589, lr: 0.006751, batch_cost: 0.1904, reader_cost: 0.00029, ips: 42.0269 samples/sec | ETA 00:32:48
2023-03-06 20:07:41 [INFO]	[TRAIN] epoch: 334, iter: 5670/16000, loss: 0.2482, lr: 0.006746, batch_cost: 0.2721, reader_cost: 0.04060, ips: 29.4044 samples/sec | ETA 00:46:50
2023-03-06 20:07:44 [INFO]	[TRAIN] epoch: 335, iter: 5680/16000, loss: 0.3165, lr: 0.006740, batch_cost: 0.2594, reader_cost: 0.05228, ips: 30.8448 samples/sec | ETA 00:44:36
2023-03-06 20:07:45 [INFO]	[TRAIN] epoch: 335, iter: 5690/16000, loss: 0.3091, lr: 0.006734, batch_cost: 0.1826, reader_cost: 0.00028, ips: 43.8024 samples/sec | ETA 00:31:23
2023-03-06 20:07:48 [INFO]	[TRAIN] epoch: 336, iter: 5700/16000, loss: 0.3038, lr: 0.006728, batch_cost: 0.2539, reader_cost: 0.05886, ips: 31.5070 samples/sec | ETA 00:43:35
2023-03-06 20:07:50 [INFO]	[TRAIN] epoch: 336, iter: 5710/16000, loss: 0.2622, lr: 0.006722, batch_cost: 0.1924, reader_cost: 0.00031, ips: 41.5839 samples/sec | ETA 00:32:59
2023-03-06 20:07:52 [INFO]	[TRAIN] epoch: 337, iter: 5720/16000, loss: 0.2801, lr: 0.006716, batch_cost: 0.2530, reader_cost: 0.04067, ips: 31.6183 samples/sec | ETA 00:43:21
2023-03-06 20:07:55 [INFO]	[TRAIN] epoch: 338, iter: 5730/16000, loss: 0.3403, lr: 0.006710, batch_cost: 0.2465, reader_cost: 0.04571, ips: 32.4582 samples/sec | ETA 00:42:11
2023-03-06 20:07:57 [INFO]	[TRAIN] epoch: 338, iter: 5740/16000, loss: 0.2112, lr: 0.006704, batch_cost: 0.2076, reader_cost: 0.00031, ips: 38.5344 samples/sec | ETA 00:35:30
2023-03-06 20:08:00 [INFO]	[TRAIN] epoch: 339, iter: 5750/16000, loss: 0.2489, lr: 0.006699, batch_cost: 0.2613, reader_cost: 0.06118, ips: 30.6164 samples/sec | ETA 00:44:38
2023-03-06 20:08:02 [INFO]	[TRAIN] epoch: 339, iter: 5760/16000, loss: 0.2689, lr: 0.006693, batch_cost: 0.1973, reader_cost: 0.00031, ips: 40.5420 samples/sec | ETA 00:33:40
2023-03-06 20:08:04 [INFO]	[TRAIN] epoch: 340, iter: 5770/16000, loss: 0.1957, lr: 0.006687, batch_cost: 0.2735, reader_cost: 0.04471, ips: 29.2537 samples/sec | ETA 00:46:37
2023-03-06 20:08:06 [INFO]	[TRAIN] epoch: 340, iter: 5780/16000, loss: 0.1812, lr: 0.006681, batch_cost: 0.1795, reader_cost: 0.00025, ips: 44.5643 samples/sec | ETA 00:30:34
2023-03-06 20:08:09 [INFO]	[TRAIN] epoch: 341, iter: 5790/16000, loss: 0.2785, lr: 0.006675, batch_cost: 0.2515, reader_cost: 0.05236, ips: 31.8079 samples/sec | ETA 00:42:47
2023-03-06 20:08:11 [INFO]	[TRAIN] epoch: 342, iter: 5800/16000, loss: 0.2108, lr: 0.006669, batch_cost: 0.2531, reader_cost: 0.05502, ips: 31.6066 samples/sec | ETA 00:43:01
2023-03-06 20:08:13 [INFO]	[TRAIN] epoch: 342, iter: 5810/16000, loss: 0.1912, lr: 0.006663, batch_cost: 0.1888, reader_cost: 0.00030, ips: 42.3726 samples/sec | ETA 00:32:03
2023-03-06 20:08:15 [INFO]	[TRAIN] epoch: 343, iter: 5820/16000, loss: 0.3420, lr: 0.006657, batch_cost: 0.2501, reader_cost: 0.04311, ips: 31.9871 samples/sec | ETA 00:42:26
2023-03-06 20:08:17 [INFO]	[TRAIN] epoch: 343, iter: 5830/16000, loss: 0.2371, lr: 0.006651, batch_cost: 0.1934, reader_cost: 0.00028, ips: 41.3707 samples/sec | ETA 00:32:46
2023-03-06 20:08:20 [INFO]	[TRAIN] epoch: 344, iter: 5840/16000, loss: 0.3154, lr: 0.006646, batch_cost: 0.2495, reader_cost: 0.04373, ips: 32.0626 samples/sec | ETA 00:42:15
2023-03-06 20:08:22 [INFO]	[TRAIN] epoch: 345, iter: 5850/16000, loss: 0.3232, lr: 0.006640, batch_cost: 0.2389, reader_cost: 0.04406, ips: 33.4844 samples/sec | ETA 00:40:25
2023-03-06 20:08:24 [INFO]	[TRAIN] epoch: 345, iter: 5860/16000, loss: 0.2846, lr: 0.006634, batch_cost: 0.1884, reader_cost: 0.00029, ips: 42.4614 samples/sec | ETA 00:31:50
2023-03-06 20:08:27 [INFO]	[TRAIN] epoch: 346, iter: 5870/16000, loss: 0.2583, lr: 0.006628, batch_cost: 0.2455, reader_cost: 0.03560, ips: 32.5850 samples/sec | ETA 00:41:27
2023-03-06 20:08:28 [INFO]	[TRAIN] epoch: 346, iter: 5880/16000, loss: 0.1970, lr: 0.006622, batch_cost: 0.1849, reader_cost: 0.00029, ips: 43.2568 samples/sec | ETA 00:31:11
2023-03-06 20:08:31 [INFO]	[TRAIN] epoch: 347, iter: 5890/16000, loss: 0.2781, lr: 0.006616, batch_cost: 0.2408, reader_cost: 0.04399, ips: 33.2197 samples/sec | ETA 00:40:34
2023-03-06 20:08:33 [INFO]	[TRAIN] epoch: 348, iter: 5900/16000, loss: 0.2184, lr: 0.006610, batch_cost: 0.2409, reader_cost: 0.04450, ips: 33.2032 samples/sec | ETA 00:40:33
2023-03-06 20:08:35 [INFO]	[TRAIN] epoch: 348, iter: 5910/16000, loss: 0.2701, lr: 0.006604, batch_cost: 0.1838, reader_cost: 0.00027, ips: 43.5373 samples/sec | ETA 00:30:54
2023-03-06 20:08:38 [INFO]	[TRAIN] epoch: 349, iter: 5920/16000, loss: 0.2244, lr: 0.006599, batch_cost: 0.2491, reader_cost: 0.05174, ips: 32.1207 samples/sec | ETA 00:41:50
2023-03-06 20:08:40 [INFO]	[TRAIN] epoch: 349, iter: 5930/16000, loss: 0.2250, lr: 0.006593, batch_cost: 0.1940, reader_cost: 0.00026, ips: 41.2351 samples/sec | ETA 00:32:33
2023-03-06 20:08:42 [INFO]	[TRAIN] epoch: 350, iter: 5940/16000, loss: 0.2403, lr: 0.006587, batch_cost: 0.2504, reader_cost: 0.05092, ips: 31.9499 samples/sec | ETA 00:41:58
2023-03-06 20:08:44 [INFO]	[TRAIN] epoch: 350, iter: 5950/16000, loss: 0.3024, lr: 0.006581, batch_cost: 0.1868, reader_cost: 0.00027, ips: 42.8202 samples/sec | ETA 00:31:17
2023-03-06 20:08:46 [INFO]	[TRAIN] epoch: 351, iter: 5960/16000, loss: 0.2151, lr: 0.006575, batch_cost: 0.2515, reader_cost: 0.05103, ips: 31.8109 samples/sec | ETA 00:42:04
2023-03-06 20:08:49 [INFO]	[TRAIN] epoch: 352, iter: 5970/16000, loss: 0.2960, lr: 0.006569, batch_cost: 0.2429, reader_cost: 0.03813, ips: 32.9383 samples/sec | ETA 00:40:36
2023-03-06 20:08:51 [INFO]	[TRAIN] epoch: 352, iter: 5980/16000, loss: 0.2251, lr: 0.006563, batch_cost: 0.1883, reader_cost: 0.00028, ips: 42.4835 samples/sec | ETA 00:31:26
2023-03-06 20:08:53 [INFO]	[TRAIN] epoch: 353, iter: 5990/16000, loss: 0.2686, lr: 0.006557, batch_cost: 0.2390, reader_cost: 0.04303, ips: 33.4795 samples/sec | ETA 00:39:51
2023-03-06 20:08:55 [INFO]	[TRAIN] epoch: 353, iter: 6000/16000, loss: 0.2638, lr: 0.006551, batch_cost: 0.1888, reader_cost: 0.00027, ips: 42.3755 samples/sec | ETA 00:31:27
2023-03-06 20:08:55 [INFO]	Start evaluating (total_samples: 119, total_iters: 60)...
60/60 - 3s - batch_cost: 0.0536 - reader cost: 0.0020
2023-03-06 20:08:58 [INFO]	[EVAL] #Images: 119 mIoU: 0.7677 Acc: 0.9290 Kappa: 0.7203 Dice: 0.8601
2023-03-06 20:08:58 [INFO]	[EVAL] Class IoU: 
[0.92   0.6155]
2023-03-06 20:08:58 [INFO]	[EVAL] Class Precision: 
[0.9589 0.7591]
2023-03-06 20:08:58 [INFO]	[EVAL] Class Recall: 
[0.9577 0.7648]
2023-03-06 20:08:59 [INFO]	[EVAL] The model with the best validation mIoU (0.7677) was saved at iter 6000.
2023-03-06 20:09:02 [INFO]	[TRAIN] epoch: 354, iter: 6010/16000, loss: 0.2058, lr: 0.006545, batch_cost: 0.2537, reader_cost: 0.05156, ips: 31.5298 samples/sec | ETA 00:42:14
2023-03-06 20:09:04 [INFO]	[TRAIN] epoch: 355, iter: 6020/16000, loss: 0.2766, lr: 0.006540, batch_cost: 0.2454, reader_cost: 0.04103, ips: 32.5996 samples/sec | ETA 00:40:49
2023-03-06 20:09:06 [INFO]	[TRAIN] epoch: 355, iter: 6030/16000, loss: 0.2738, lr: 0.006534, batch_cost: 0.2029, reader_cost: 0.00029, ips: 39.4294 samples/sec | ETA 00:33:42
2023-03-06 20:09:09 [INFO]	[TRAIN] epoch: 356, iter: 6040/16000, loss: 0.2721, lr: 0.006528, batch_cost: 0.2933, reader_cost: 0.03906, ips: 27.2794 samples/sec | ETA 00:48:40
2023-03-06 20:09:11 [INFO]	[TRAIN] epoch: 356, iter: 6050/16000, loss: 0.2138, lr: 0.006522, batch_cost: 0.2060, reader_cost: 0.00030, ips: 38.8311 samples/sec | ETA 00:34:09
2023-03-06 20:09:14 [INFO]	[TRAIN] epoch: 357, iter: 6060/16000, loss: 0.2277, lr: 0.006516, batch_cost: 0.2562, reader_cost: 0.04875, ips: 31.2303 samples/sec | ETA 00:42:26
2023-03-06 20:09:17 [INFO]	[TRAIN] epoch: 358, iter: 6070/16000, loss: 0.2428, lr: 0.006510, batch_cost: 0.2482, reader_cost: 0.04736, ips: 32.2314 samples/sec | ETA 00:41:04
2023-03-06 20:09:18 [INFO]	[TRAIN] epoch: 358, iter: 6080/16000, loss: 0.2293, lr: 0.006504, batch_cost: 0.1892, reader_cost: 0.00028, ips: 42.2841 samples/sec | ETA 00:31:16
2023-03-06 20:09:21 [INFO]	[TRAIN] epoch: 359, iter: 6090/16000, loss: 0.2681, lr: 0.006498, batch_cost: 0.2478, reader_cost: 0.04499, ips: 32.2821 samples/sec | ETA 00:40:55
2023-03-06 20:09:23 [INFO]	[TRAIN] epoch: 359, iter: 6100/16000, loss: 0.2432, lr: 0.006492, batch_cost: 0.1861, reader_cost: 0.00031, ips: 42.9875 samples/sec | ETA 00:30:42
2023-03-06 20:09:25 [INFO]	[TRAIN] epoch: 360, iter: 6110/16000, loss: 0.2659, lr: 0.006486, batch_cost: 0.2465, reader_cost: 0.04098, ips: 32.4493 samples/sec | ETA 00:40:38
2023-03-06 20:09:27 [INFO]	[TRAIN] epoch: 360, iter: 6120/16000, loss: 0.3013, lr: 0.006481, batch_cost: 0.1845, reader_cost: 0.00027, ips: 43.3634 samples/sec | ETA 00:30:22
2023-03-06 20:09:30 [INFO]	[TRAIN] epoch: 361, iter: 6130/16000, loss: 0.2427, lr: 0.006475, batch_cost: 0.2596, reader_cost: 0.05271, ips: 30.8162 samples/sec | ETA 00:42:42
2023-03-06 20:09:32 [INFO]	[TRAIN] epoch: 362, iter: 6140/16000, loss: 0.2683, lr: 0.006469, batch_cost: 0.2419, reader_cost: 0.04329, ips: 33.0655 samples/sec | ETA 00:39:45
2023-03-06 20:09:34 [INFO]	[TRAIN] epoch: 362, iter: 6150/16000, loss: 0.2545, lr: 0.006463, batch_cost: 0.1906, reader_cost: 0.00026, ips: 41.9739 samples/sec | ETA 00:31:17
2023-03-06 20:09:36 [INFO]	[TRAIN] epoch: 363, iter: 6160/16000, loss: 0.2406, lr: 0.006457, batch_cost: 0.2504, reader_cost: 0.04105, ips: 31.9491 samples/sec | ETA 00:41:03
2023-03-06 20:09:38 [INFO]	[TRAIN] epoch: 363, iter: 6170/16000, loss: 0.3428, lr: 0.006451, batch_cost: 0.1872, reader_cost: 0.00037, ips: 42.7276 samples/sec | ETA 00:30:40
2023-03-06 20:09:41 [INFO]	[TRAIN] epoch: 364, iter: 6180/16000, loss: 0.2181, lr: 0.006445, batch_cost: 0.2508, reader_cost: 0.04268, ips: 31.8949 samples/sec | ETA 00:41:03
2023-03-06 20:09:43 [INFO]	[TRAIN] epoch: 365, iter: 6190/16000, loss: 0.2259, lr: 0.006439, batch_cost: 0.2449, reader_cost: 0.03944, ips: 32.6599 samples/sec | ETA 00:40:02
2023-03-06 20:09:45 [INFO]	[TRAIN] epoch: 365, iter: 6200/16000, loss: 0.2181, lr: 0.006433, batch_cost: 0.1971, reader_cost: 0.00030, ips: 40.5862 samples/sec | ETA 00:32:11
2023-03-06 20:09:48 [INFO]	[TRAIN] epoch: 366, iter: 6210/16000, loss: 0.1877, lr: 0.006427, batch_cost: 0.2522, reader_cost: 0.04304, ips: 31.7181 samples/sec | ETA 00:41:09
2023-03-06 20:09:50 [INFO]	[TRAIN] epoch: 366, iter: 6220/16000, loss: 0.2365, lr: 0.006422, batch_cost: 0.1908, reader_cost: 0.00031, ips: 41.9199 samples/sec | ETA 00:31:06
2023-03-06 20:09:52 [INFO]	[TRAIN] epoch: 367, iter: 6230/16000, loss: 0.2124, lr: 0.006416, batch_cost: 0.2476, reader_cost: 0.05172, ips: 32.3098 samples/sec | ETA 00:40:19
2023-03-06 20:09:55 [INFO]	[TRAIN] epoch: 368, iter: 6240/16000, loss: 0.3470, lr: 0.006410, batch_cost: 0.2521, reader_cost: 0.05857, ips: 31.7376 samples/sec | ETA 00:41:00
2023-03-06 20:09:57 [INFO]	[TRAIN] epoch: 368, iter: 6250/16000, loss: 0.3207, lr: 0.006404, batch_cost: 0.1934, reader_cost: 0.00029, ips: 41.3631 samples/sec | ETA 00:31:25
2023-03-06 20:09:59 [INFO]	[TRAIN] epoch: 369, iter: 6260/16000, loss: 0.2653, lr: 0.006398, batch_cost: 0.2566, reader_cost: 0.05737, ips: 31.1716 samples/sec | ETA 00:41:39
2023-03-06 20:10:01 [INFO]	[TRAIN] epoch: 369, iter: 6270/16000, loss: 0.2502, lr: 0.006392, batch_cost: 0.1851, reader_cost: 0.00028, ips: 43.2134 samples/sec | ETA 00:30:01
2023-03-06 20:10:04 [INFO]	[TRAIN] epoch: 370, iter: 6280/16000, loss: 0.2105, lr: 0.006386, batch_cost: 0.2754, reader_cost: 0.07373, ips: 29.0467 samples/sec | ETA 00:44:37
2023-03-06 20:10:06 [INFO]	[TRAIN] epoch: 370, iter: 6290/16000, loss: 0.2336, lr: 0.006380, batch_cost: 0.1906, reader_cost: 0.00039, ips: 41.9791 samples/sec | ETA 00:30:50
2023-03-06 20:10:08 [INFO]	[TRAIN] epoch: 371, iter: 6300/16000, loss: 0.3331, lr: 0.006374, batch_cost: 0.2679, reader_cost: 0.04316, ips: 29.8586 samples/sec | ETA 00:43:18
2023-03-06 20:10:11 [INFO]	[TRAIN] epoch: 372, iter: 6310/16000, loss: 0.2999, lr: 0.006368, batch_cost: 0.2594, reader_cost: 0.05520, ips: 30.8445 samples/sec | ETA 00:41:53
2023-03-06 20:10:13 [INFO]	[TRAIN] epoch: 372, iter: 6320/16000, loss: 0.2803, lr: 0.006362, batch_cost: 0.1921, reader_cost: 0.00027, ips: 41.6540 samples/sec | ETA 00:30:59
2023-03-06 20:10:16 [INFO]	[TRAIN] epoch: 373, iter: 6330/16000, loss: 0.2108, lr: 0.006356, batch_cost: 0.2736, reader_cost: 0.04245, ips: 29.2448 samples/sec | ETA 00:44:05
2023-03-06 20:10:18 [INFO]	[TRAIN] epoch: 373, iter: 6340/16000, loss: 0.1960, lr: 0.006351, batch_cost: 0.2226, reader_cost: 0.00030, ips: 35.9350 samples/sec | ETA 00:35:50
2023-03-06 20:10:20 [INFO]	[TRAIN] epoch: 374, iter: 6350/16000, loss: 0.2402, lr: 0.006345, batch_cost: 0.2409, reader_cost: 0.03917, ips: 33.2136 samples/sec | ETA 00:38:44
2023-03-06 20:10:23 [INFO]	[TRAIN] epoch: 375, iter: 6360/16000, loss: 0.2667, lr: 0.006339, batch_cost: 0.2422, reader_cost: 0.04425, ips: 33.0352 samples/sec | ETA 00:38:54
2023-03-06 20:10:25 [INFO]	[TRAIN] epoch: 375, iter: 6370/16000, loss: 0.1970, lr: 0.006333, batch_cost: 0.1879, reader_cost: 0.00031, ips: 42.5801 samples/sec | ETA 00:30:09
2023-03-06 20:10:27 [INFO]	[TRAIN] epoch: 376, iter: 6380/16000, loss: 0.2196, lr: 0.006327, batch_cost: 0.2473, reader_cost: 0.03383, ips: 32.3435 samples/sec | ETA 00:39:39
2023-03-06 20:10:29 [INFO]	[TRAIN] epoch: 376, iter: 6390/16000, loss: 0.2289, lr: 0.006321, batch_cost: 0.2082, reader_cost: 0.00028, ips: 38.4242 samples/sec | ETA 00:33:20
2023-03-06 20:10:32 [INFO]	[TRAIN] epoch: 377, iter: 6400/16000, loss: 0.1841, lr: 0.006315, batch_cost: 0.2936, reader_cost: 0.05234, ips: 27.2457 samples/sec | ETA 00:46:58
2023-03-06 20:10:35 [INFO]	[TRAIN] epoch: 378, iter: 6410/16000, loss: 0.2287, lr: 0.006309, batch_cost: 0.2578, reader_cost: 0.05509, ips: 31.0309 samples/sec | ETA 00:41:12
2023-03-06 20:10:37 [INFO]	[TRAIN] epoch: 378, iter: 6420/16000, loss: 0.1850, lr: 0.006303, batch_cost: 0.1904, reader_cost: 0.00029, ips: 42.0222 samples/sec | ETA 00:30:23
2023-03-06 20:10:39 [INFO]	[TRAIN] epoch: 379, iter: 6430/16000, loss: 0.2024, lr: 0.006297, batch_cost: 0.2542, reader_cost: 0.04914, ips: 31.4673 samples/sec | ETA 00:40:33
2023-03-06 20:10:41 [INFO]	[TRAIN] epoch: 379, iter: 6440/16000, loss: 0.2821, lr: 0.006291, batch_cost: 0.1922, reader_cost: 0.00031, ips: 41.6180 samples/sec | ETA 00:30:37
2023-03-06 20:10:44 [INFO]	[TRAIN] epoch: 380, iter: 6450/16000, loss: 0.2073, lr: 0.006285, batch_cost: 0.2626, reader_cost: 0.04875, ips: 30.4666 samples/sec | ETA 00:41:47
2023-03-06 20:10:46 [INFO]	[TRAIN] epoch: 380, iter: 6460/16000, loss: 0.3953, lr: 0.006280, batch_cost: 0.1949, reader_cost: 0.00028, ips: 41.0391 samples/sec | ETA 00:30:59
2023-03-06 20:10:48 [INFO]	[TRAIN] epoch: 381, iter: 6470/16000, loss: 0.2330, lr: 0.006274, batch_cost: 0.2452, reader_cost: 0.03883, ips: 32.6305 samples/sec | ETA 00:38:56
2023-03-06 20:10:50 [INFO]	[TRAIN] epoch: 382, iter: 6480/16000, loss: 0.2131, lr: 0.006268, batch_cost: 0.2392, reader_cost: 0.04478, ips: 33.4387 samples/sec | ETA 00:37:57
2023-03-06 20:10:52 [INFO]	[TRAIN] epoch: 382, iter: 6490/16000, loss: 0.3013, lr: 0.006262, batch_cost: 0.1902, reader_cost: 0.00027, ips: 42.0520 samples/sec | ETA 00:30:09
2023-03-06 20:10:55 [INFO]	[TRAIN] epoch: 383, iter: 6500/16000, loss: 0.2790, lr: 0.006256, batch_cost: 0.2733, reader_cost: 0.04856, ips: 29.2672 samples/sec | ETA 00:43:16
2023-03-06 20:10:57 [INFO]	[TRAIN] epoch: 383, iter: 6510/16000, loss: 0.1865, lr: 0.006250, batch_cost: 0.1880, reader_cost: 0.00023, ips: 42.5562 samples/sec | ETA 00:29:43
2023-03-06 20:10:59 [INFO]	[TRAIN] epoch: 384, iter: 6520/16000, loss: 0.2286, lr: 0.006244, batch_cost: 0.2503, reader_cost: 0.05446, ips: 31.9591 samples/sec | ETA 00:39:33
2023-03-06 20:11:02 [INFO]	[TRAIN] epoch: 385, iter: 6530/16000, loss: 0.2441, lr: 0.006238, batch_cost: 0.2429, reader_cost: 0.05454, ips: 32.9364 samples/sec | ETA 00:38:20
2023-03-06 20:11:04 [INFO]	[TRAIN] epoch: 385, iter: 6540/16000, loss: 0.2732, lr: 0.006232, batch_cost: 0.1939, reader_cost: 0.00027, ips: 41.2484 samples/sec | ETA 00:30:34
2023-03-06 20:11:06 [INFO]	[TRAIN] epoch: 386, iter: 6550/16000, loss: 0.2617, lr: 0.006226, batch_cost: 0.2450, reader_cost: 0.04481, ips: 32.6523 samples/sec | ETA 00:38:35
2023-03-06 20:11:08 [INFO]	[TRAIN] epoch: 386, iter: 6560/16000, loss: 0.2266, lr: 0.006220, batch_cost: 0.1912, reader_cost: 0.00028, ips: 41.8325 samples/sec | ETA 00:30:05
2023-03-06 20:11:11 [INFO]	[TRAIN] epoch: 387, iter: 6570/16000, loss: 0.1716, lr: 0.006214, batch_cost: 0.2861, reader_cost: 0.06097, ips: 27.9639 samples/sec | ETA 00:44:57
2023-03-06 20:11:14 [INFO]	[TRAIN] epoch: 388, iter: 6580/16000, loss: 0.2321, lr: 0.006208, batch_cost: 0.2677, reader_cost: 0.05448, ips: 29.8867 samples/sec | ETA 00:42:01
2023-03-06 20:11:16 [INFO]	[TRAIN] epoch: 388, iter: 6590/16000, loss: 0.2203, lr: 0.006202, batch_cost: 0.1920, reader_cost: 0.00035, ips: 41.6661 samples/sec | ETA 00:30:06
2023-03-06 20:11:18 [INFO]	[TRAIN] epoch: 389, iter: 6600/16000, loss: 0.2684, lr: 0.006197, batch_cost: 0.2419, reader_cost: 0.04910, ips: 33.0689 samples/sec | ETA 00:37:54
2023-03-06 20:11:20 [INFO]	[TRAIN] epoch: 389, iter: 6610/16000, loss: 0.2839, lr: 0.006191, batch_cost: 0.1919, reader_cost: 0.00038, ips: 41.6916 samples/sec | ETA 00:30:01
2023-03-06 20:11:22 [INFO]	[TRAIN] epoch: 390, iter: 6620/16000, loss: 0.2826, lr: 0.006185, batch_cost: 0.2460, reader_cost: 0.04823, ips: 32.5261 samples/sec | ETA 00:38:27
2023-03-06 20:11:24 [INFO]	[TRAIN] epoch: 390, iter: 6630/16000, loss: 0.2038, lr: 0.006179, batch_cost: 0.1894, reader_cost: 0.00028, ips: 42.2351 samples/sec | ETA 00:29:34
2023-03-06 20:11:27 [INFO]	[TRAIN] epoch: 391, iter: 6640/16000, loss: 0.2672, lr: 0.006173, batch_cost: 0.2525, reader_cost: 0.05201, ips: 31.6811 samples/sec | ETA 00:39:23
2023-03-06 20:11:29 [INFO]	[TRAIN] epoch: 392, iter: 6650/16000, loss: 0.2261, lr: 0.006167, batch_cost: 0.2454, reader_cost: 0.03340, ips: 32.5980 samples/sec | ETA 00:38:14
2023-03-06 20:11:31 [INFO]	[TRAIN] epoch: 392, iter: 6660/16000, loss: 0.2922, lr: 0.006161, batch_cost: 0.1923, reader_cost: 0.00030, ips: 41.6074 samples/sec | ETA 00:29:55
2023-03-06 20:11:34 [INFO]	[TRAIN] epoch: 393, iter: 6670/16000, loss: 0.2280, lr: 0.006155, batch_cost: 0.2675, reader_cost: 0.06686, ips: 29.9108 samples/sec | ETA 00:41:35
2023-03-06 20:11:36 [INFO]	[TRAIN] epoch: 393, iter: 6680/16000, loss: 0.2331, lr: 0.006149, batch_cost: 0.1851, reader_cost: 0.00030, ips: 43.2178 samples/sec | ETA 00:28:45
2023-03-06 20:11:39 [INFO]	[TRAIN] epoch: 394, iter: 6690/16000, loss: 0.2411, lr: 0.006143, batch_cost: 0.2760, reader_cost: 0.05821, ips: 28.9831 samples/sec | ETA 00:42:49
2023-03-06 20:11:41 [INFO]	[TRAIN] epoch: 395, iter: 6700/16000, loss: 0.2273, lr: 0.006137, batch_cost: 0.2657, reader_cost: 0.04009, ips: 30.1087 samples/sec | ETA 00:41:11
2023-03-06 20:11:43 [INFO]	[TRAIN] epoch: 395, iter: 6710/16000, loss: 0.2398, lr: 0.006131, batch_cost: 0.1928, reader_cost: 0.00029, ips: 41.4937 samples/sec | ETA 00:29:51
2023-03-06 20:11:46 [INFO]	[TRAIN] epoch: 396, iter: 6720/16000, loss: 0.2589, lr: 0.006125, batch_cost: 0.2544, reader_cost: 0.03701, ips: 31.4499 samples/sec | ETA 00:39:20
2023-03-06 20:11:48 [INFO]	[TRAIN] epoch: 396, iter: 6730/16000, loss: 0.2463, lr: 0.006119, batch_cost: 0.1905, reader_cost: 0.00030, ips: 41.9991 samples/sec | ETA 00:29:25
2023-03-06 20:11:50 [INFO]	[TRAIN] epoch: 397, iter: 6740/16000, loss: 0.2428, lr: 0.006113, batch_cost: 0.2879, reader_cost: 0.05352, ips: 27.7857 samples/sec | ETA 00:44:26
2023-03-06 20:11:53 [INFO]	[TRAIN] epoch: 398, iter: 6750/16000, loss: 0.1985, lr: 0.006107, batch_cost: 0.2450, reader_cost: 0.04254, ips: 32.6545 samples/sec | ETA 00:37:46
2023-03-06 20:11:55 [INFO]	[TRAIN] epoch: 398, iter: 6760/16000, loss: 0.3895, lr: 0.006102, batch_cost: 0.1865, reader_cost: 0.00031, ips: 42.8959 samples/sec | ETA 00:28:43
2023-03-06 20:11:57 [INFO]	[TRAIN] epoch: 399, iter: 6770/16000, loss: 0.2467, lr: 0.006096, batch_cost: 0.2452, reader_cost: 0.05094, ips: 32.6244 samples/sec | ETA 00:37:43
2023-03-06 20:11:59 [INFO]	[TRAIN] epoch: 399, iter: 6780/16000, loss: 0.1979, lr: 0.006090, batch_cost: 0.1931, reader_cost: 0.00027, ips: 41.4218 samples/sec | ETA 00:29:40
2023-03-06 20:12:02 [INFO]	[TRAIN] epoch: 400, iter: 6790/16000, loss: 0.2778, lr: 0.006084, batch_cost: 0.2610, reader_cost: 0.05054, ips: 30.6506 samples/sec | ETA 00:40:03
2023-03-06 20:12:04 [INFO]	[TRAIN] epoch: 400, iter: 6800/16000, loss: 0.2904, lr: 0.006078, batch_cost: 0.1804, reader_cost: 0.00024, ips: 44.3532 samples/sec | ETA 00:27:39
2023-03-06 20:12:06 [INFO]	[TRAIN] epoch: 401, iter: 6810/16000, loss: 0.1874, lr: 0.006072, batch_cost: 0.2504, reader_cost: 0.04037, ips: 31.9523 samples/sec | ETA 00:38:20
2023-03-06 20:12:09 [INFO]	[TRAIN] epoch: 402, iter: 6820/16000, loss: 0.2192, lr: 0.006066, batch_cost: 0.2533, reader_cost: 0.04438, ips: 31.5785 samples/sec | ETA 00:38:45
2023-03-06 20:12:11 [INFO]	[TRAIN] epoch: 402, iter: 6830/16000, loss: 0.1870, lr: 0.006060, batch_cost: 0.1952, reader_cost: 0.00031, ips: 40.9817 samples/sec | ETA 00:29:50
2023-03-06 20:12:13 [INFO]	[TRAIN] epoch: 403, iter: 6840/16000, loss: 0.2388, lr: 0.006054, batch_cost: 0.2508, reader_cost: 0.04673, ips: 31.8956 samples/sec | ETA 00:38:17
2023-03-06 20:12:15 [INFO]	[TRAIN] epoch: 403, iter: 6850/16000, loss: 0.3028, lr: 0.006048, batch_cost: 0.1989, reader_cost: 0.00031, ips: 40.2142 samples/sec | ETA 00:30:20
2023-03-06 20:12:18 [INFO]	[TRAIN] epoch: 404, iter: 6860/16000, loss: 0.3389, lr: 0.006042, batch_cost: 0.2639, reader_cost: 0.04338, ips: 30.3158 samples/sec | ETA 00:40:11
2023-03-06 20:12:20 [INFO]	[TRAIN] epoch: 405, iter: 6870/16000, loss: 0.2405, lr: 0.006036, batch_cost: 0.2476, reader_cost: 0.05090, ips: 32.3100 samples/sec | ETA 00:37:40
2023-03-06 20:12:22 [INFO]	[TRAIN] epoch: 405, iter: 6880/16000, loss: 0.2382, lr: 0.006030, batch_cost: 0.2121, reader_cost: 0.00029, ips: 37.7131 samples/sec | ETA 00:32:14
2023-03-06 20:12:25 [INFO]	[TRAIN] epoch: 406, iter: 6890/16000, loss: 0.1897, lr: 0.006024, batch_cost: 0.2611, reader_cost: 0.03573, ips: 30.6441 samples/sec | ETA 00:39:38
2023-03-06 20:12:27 [INFO]	[TRAIN] epoch: 406, iter: 6900/16000, loss: 0.2043, lr: 0.006018, batch_cost: 0.1821, reader_cost: 0.00026, ips: 43.9330 samples/sec | ETA 00:27:37
2023-03-06 20:12:29 [INFO]	[TRAIN] epoch: 407, iter: 6910/16000, loss: 0.2082, lr: 0.006012, batch_cost: 0.2516, reader_cost: 0.05659, ips: 31.7918 samples/sec | ETA 00:38:07
2023-03-06 20:12:32 [INFO]	[TRAIN] epoch: 408, iter: 6920/16000, loss: 0.2399, lr: 0.006006, batch_cost: 0.2369, reader_cost: 0.04320, ips: 33.7692 samples/sec | ETA 00:35:51
2023-03-06 20:12:34 [INFO]	[TRAIN] epoch: 408, iter: 6930/16000, loss: 0.2028, lr: 0.006000, batch_cost: 0.1923, reader_cost: 0.00033, ips: 41.5980 samples/sec | ETA 00:29:04
2023-03-06 20:12:36 [INFO]	[TRAIN] epoch: 409, iter: 6940/16000, loss: 0.2328, lr: 0.005994, batch_cost: 0.2526, reader_cost: 0.04788, ips: 31.6667 samples/sec | ETA 00:38:08
2023-03-06 20:12:38 [INFO]	[TRAIN] epoch: 409, iter: 6950/16000, loss: 0.2574, lr: 0.005989, batch_cost: 0.1898, reader_cost: 0.00027, ips: 42.1573 samples/sec | ETA 00:28:37
2023-03-06 20:12:41 [INFO]	[TRAIN] epoch: 410, iter: 6960/16000, loss: 0.1961, lr: 0.005983, batch_cost: 0.2518, reader_cost: 0.03872, ips: 31.7665 samples/sec | ETA 00:37:56
2023-03-06 20:12:42 [INFO]	[TRAIN] epoch: 410, iter: 6970/16000, loss: 0.2766, lr: 0.005977, batch_cost: 0.1838, reader_cost: 0.00025, ips: 43.5271 samples/sec | ETA 00:27:39
2023-03-06 20:12:45 [INFO]	[TRAIN] epoch: 411, iter: 6980/16000, loss: 0.2223, lr: 0.005971, batch_cost: 0.2519, reader_cost: 0.04822, ips: 31.7627 samples/sec | ETA 00:37:51
2023-03-06 20:12:47 [INFO]	[TRAIN] epoch: 412, iter: 6990/16000, loss: 0.2747, lr: 0.005965, batch_cost: 0.2547, reader_cost: 0.05342, ips: 31.4142 samples/sec | ETA 00:38:14
2023-03-06 20:12:49 [INFO]	[TRAIN] epoch: 412, iter: 7000/16000, loss: 0.2136, lr: 0.005959, batch_cost: 0.1930, reader_cost: 0.00027, ips: 41.4560 samples/sec | ETA 00:28:56
2023-03-06 20:12:49 [INFO]	Start evaluating (total_samples: 119, total_iters: 60)...
60/60 - 3s - batch_cost: 0.0548 - reader cost: 0.0019
2023-03-06 20:12:53 [INFO]	[EVAL] #Images: 119 mIoU: 0.7711 Acc: 0.9260 Kappa: 0.7267 Dice: 0.8632
2023-03-06 20:12:53 [INFO]	[EVAL] Class IoU: 
[0.9155 0.6266]
2023-03-06 20:12:53 [INFO]	[EVAL] Class Precision: 
[0.9705 0.7145]
2023-03-06 20:12:53 [INFO]	[EVAL] Class Recall: 
[0.9417 0.836 ]
2023-03-06 20:12:54 [INFO]	[EVAL] The model with the best validation mIoU (0.7711) was saved at iter 7000.
2023-03-06 20:12:56 [INFO]	[TRAIN] epoch: 413, iter: 7010/16000, loss: 0.2801, lr: 0.005953, batch_cost: 0.2463, reader_cost: 0.05590, ips: 32.4786 samples/sec | ETA 00:36:54
2023-03-06 20:12:58 [INFO]	[TRAIN] epoch: 413, iter: 7020/16000, loss: 0.3204, lr: 0.005947, batch_cost: 0.1891, reader_cost: 0.00027, ips: 42.3131 samples/sec | ETA 00:28:17
2023-03-06 20:13:01 [INFO]	[TRAIN] epoch: 414, iter: 7030/16000, loss: 0.2550, lr: 0.005941, batch_cost: 0.2495, reader_cost: 0.03458, ips: 32.0612 samples/sec | ETA 00:37:18
2023-03-06 20:13:03 [INFO]	[TRAIN] epoch: 415, iter: 7040/16000, loss: 0.2374, lr: 0.005935, batch_cost: 0.2422, reader_cost: 0.04442, ips: 33.0287 samples/sec | ETA 00:36:10
2023-03-06 20:13:05 [INFO]	[TRAIN] epoch: 415, iter: 7050/16000, loss: 0.2594, lr: 0.005929, batch_cost: 0.1863, reader_cost: 0.00026, ips: 42.9419 samples/sec | ETA 00:27:47
2023-03-06 20:13:08 [INFO]	[TRAIN] epoch: 416, iter: 7060/16000, loss: 0.1632, lr: 0.005923, batch_cost: 0.2462, reader_cost: 0.04298, ips: 32.4899 samples/sec | ETA 00:36:41
2023-03-06 20:13:10 [INFO]	[TRAIN] epoch: 416, iter: 7070/16000, loss: 0.2810, lr: 0.005917, batch_cost: 0.1986, reader_cost: 0.00026, ips: 40.2817 samples/sec | ETA 00:29:33
2023-03-06 20:13:12 [INFO]	[TRAIN] epoch: 417, iter: 7080/16000, loss: 0.2327, lr: 0.005911, batch_cost: 0.2532, reader_cost: 0.04205, ips: 31.5979 samples/sec | ETA 00:37:38
2023-03-06 20:13:15 [INFO]	[TRAIN] epoch: 418, iter: 7090/16000, loss: 0.1609, lr: 0.005905, batch_cost: 0.2458, reader_cost: 0.04870, ips: 32.5449 samples/sec | ETA 00:36:30
2023-03-06 20:13:17 [INFO]	[TRAIN] epoch: 418, iter: 7100/16000, loss: 0.2609, lr: 0.005899, batch_cost: 0.2040, reader_cost: 0.00034, ips: 39.2241 samples/sec | ETA 00:30:15
2023-03-06 20:13:19 [INFO]	[TRAIN] epoch: 419, iter: 7110/16000, loss: 0.2609, lr: 0.005893, batch_cost: 0.2541, reader_cost: 0.05517, ips: 31.4777 samples/sec | ETA 00:37:39
2023-03-06 20:13:21 [INFO]	[TRAIN] epoch: 419, iter: 7120/16000, loss: 0.2369, lr: 0.005887, batch_cost: 0.1894, reader_cost: 0.00026, ips: 42.2416 samples/sec | ETA 00:28:01
2023-03-06 20:13:24 [INFO]	[TRAIN] epoch: 420, iter: 7130/16000, loss: 0.2814, lr: 0.005881, batch_cost: 0.2586, reader_cost: 0.04329, ips: 30.9339 samples/sec | ETA 00:38:13
2023-03-06 20:13:26 [INFO]	[TRAIN] epoch: 420, iter: 7140/16000, loss: 0.2658, lr: 0.005875, batch_cost: 0.2270, reader_cost: 0.00023, ips: 35.2385 samples/sec | ETA 00:33:31
2023-03-06 20:13:29 [INFO]	[TRAIN] epoch: 421, iter: 7150/16000, loss: 0.2378, lr: 0.005869, batch_cost: 0.2623, reader_cost: 0.04211, ips: 30.5018 samples/sec | ETA 00:38:41
2023-03-06 20:13:31 [INFO]	[TRAIN] epoch: 422, iter: 7160/16000, loss: 0.3090, lr: 0.005863, batch_cost: 0.2529, reader_cost: 0.03423, ips: 31.6302 samples/sec | ETA 00:37:15
2023-03-06 20:13:33 [INFO]	[TRAIN] epoch: 422, iter: 7170/16000, loss: 0.2993, lr: 0.005857, batch_cost: 0.2091, reader_cost: 0.00026, ips: 38.2658 samples/sec | ETA 00:30:46
2023-03-06 20:13:36 [INFO]	[TRAIN] epoch: 423, iter: 7180/16000, loss: 0.1975, lr: 0.005851, batch_cost: 0.2534, reader_cost: 0.04806, ips: 31.5657 samples/sec | ETA 00:37:15
2023-03-06 20:13:38 [INFO]	[TRAIN] epoch: 423, iter: 7190/16000, loss: 0.3096, lr: 0.005845, batch_cost: 0.1849, reader_cost: 0.00027, ips: 43.2686 samples/sec | ETA 00:27:08
2023-03-06 20:13:40 [INFO]	[TRAIN] epoch: 424, iter: 7200/16000, loss: 0.3187, lr: 0.005839, batch_cost: 0.2561, reader_cost: 0.05568, ips: 31.2319 samples/sec | ETA 00:37:34
2023-03-06 20:13:43 [INFO]	[TRAIN] epoch: 425, iter: 7210/16000, loss: 0.2694, lr: 0.005833, batch_cost: 0.2421, reader_cost: 0.03633, ips: 33.0470 samples/sec | ETA 00:35:27
2023-03-06 20:13:44 [INFO]	[TRAIN] epoch: 425, iter: 7220/16000, loss: 0.1842, lr: 0.005827, batch_cost: 0.1934, reader_cost: 0.00027, ips: 41.3621 samples/sec | ETA 00:28:18
2023-03-06 20:13:47 [INFO]	[TRAIN] epoch: 426, iter: 7230/16000, loss: 0.2856, lr: 0.005822, batch_cost: 0.2455, reader_cost: 0.04258, ips: 32.5809 samples/sec | ETA 00:35:53
2023-03-06 20:13:49 [INFO]	[TRAIN] epoch: 426, iter: 7240/16000, loss: 0.2745, lr: 0.005816, batch_cost: 0.1934, reader_cost: 0.00030, ips: 41.3679 samples/sec | ETA 00:28:14
2023-03-06 20:13:51 [INFO]	[TRAIN] epoch: 427, iter: 7250/16000, loss: 0.2464, lr: 0.005810, batch_cost: 0.2591, reader_cost: 0.04646, ips: 30.8721 samples/sec | ETA 00:37:47
2023-03-06 20:13:54 [INFO]	[TRAIN] epoch: 428, iter: 7260/16000, loss: 0.2006, lr: 0.005804, batch_cost: 0.2555, reader_cost: 0.04767, ips: 31.3156 samples/sec | ETA 00:37:12
2023-03-06 20:13:56 [INFO]	[TRAIN] epoch: 428, iter: 7270/16000, loss: 0.2088, lr: 0.005798, batch_cost: 0.1913, reader_cost: 0.00546, ips: 41.8126 samples/sec | ETA 00:27:50
2023-03-06 20:13:58 [INFO]	[TRAIN] epoch: 429, iter: 7280/16000, loss: 0.3015, lr: 0.005792, batch_cost: 0.2494, reader_cost: 0.03788, ips: 32.0762 samples/sec | ETA 00:36:14
2023-03-06 20:14:00 [INFO]	[TRAIN] epoch: 429, iter: 7290/16000, loss: 0.2487, lr: 0.005786, batch_cost: 0.1976, reader_cost: 0.00028, ips: 40.4779 samples/sec | ETA 00:28:41
2023-03-06 20:14:03 [INFO]	[TRAIN] epoch: 430, iter: 7300/16000, loss: 0.3213, lr: 0.005780, batch_cost: 0.2588, reader_cost: 0.04438, ips: 30.9174 samples/sec | ETA 00:37:31
2023-03-06 20:14:05 [INFO]	[TRAIN] epoch: 430, iter: 7310/16000, loss: 0.1848, lr: 0.005774, batch_cost: 0.1912, reader_cost: 0.00027, ips: 41.8510 samples/sec | ETA 00:27:41
2023-03-06 20:14:07 [INFO]	[TRAIN] epoch: 431, iter: 7320/16000, loss: 0.2159, lr: 0.005768, batch_cost: 0.2478, reader_cost: 0.04776, ips: 32.2889 samples/sec | ETA 00:35:50
2023-03-06 20:14:10 [INFO]	[TRAIN] epoch: 432, iter: 7330/16000, loss: 0.3024, lr: 0.005762, batch_cost: 0.2637, reader_cost: 0.06486, ips: 30.3326 samples/sec | ETA 00:38:06
2023-03-06 20:14:12 [INFO]	[TRAIN] epoch: 432, iter: 7340/16000, loss: 0.2194, lr: 0.005756, batch_cost: 0.2002, reader_cost: 0.00031, ips: 39.9564 samples/sec | ETA 00:28:53
2023-03-06 20:14:15 [INFO]	[TRAIN] epoch: 433, iter: 7350/16000, loss: 0.2976, lr: 0.005750, batch_cost: 0.2557, reader_cost: 0.05484, ips: 31.2879 samples/sec | ETA 00:36:51
2023-03-06 20:14:16 [INFO]	[TRAIN] epoch: 433, iter: 7360/16000, loss: 0.2878, lr: 0.005744, batch_cost: 0.1844, reader_cost: 0.00026, ips: 43.3948 samples/sec | ETA 00:26:32
2023-03-06 20:14:20 [INFO]	[TRAIN] epoch: 434, iter: 7370/16000, loss: 0.2109, lr: 0.005738, batch_cost: 0.3614, reader_cost: 0.16205, ips: 22.1340 samples/sec | ETA 00:51:59
2023-03-06 20:14:23 [INFO]	[TRAIN] epoch: 435, iter: 7380/16000, loss: 0.2569, lr: 0.005732, batch_cost: 0.2664, reader_cost: 0.04765, ips: 30.0317 samples/sec | ETA 00:38:16
2023-03-06 20:14:25 [INFO]	[TRAIN] epoch: 435, iter: 7390/16000, loss: 0.2122, lr: 0.005726, batch_cost: 0.2217, reader_cost: 0.00028, ips: 36.0779 samples/sec | ETA 00:31:49
2023-03-06 20:14:28 [INFO]	[TRAIN] epoch: 436, iter: 7400/16000, loss: 0.2266, lr: 0.005720, batch_cost: 0.2605, reader_cost: 0.05148, ips: 30.7061 samples/sec | ETA 00:37:20
2023-03-06 20:14:29 [INFO]	[TRAIN] epoch: 436, iter: 7410/16000, loss: 0.2234, lr: 0.005714, batch_cost: 0.1925, reader_cost: 0.00029, ips: 41.5552 samples/sec | ETA 00:27:33
2023-03-06 20:14:32 [INFO]	[TRAIN] epoch: 437, iter: 7420/16000, loss: 0.3491, lr: 0.005708, batch_cost: 0.2539, reader_cost: 0.04938, ips: 31.5147 samples/sec | ETA 00:36:18
2023-03-06 20:14:35 [INFO]	[TRAIN] epoch: 438, iter: 7430/16000, loss: 0.2830, lr: 0.005702, batch_cost: 0.2646, reader_cost: 0.05855, ips: 30.2287 samples/sec | ETA 00:37:48
2023-03-06 20:14:37 [INFO]	[TRAIN] epoch: 438, iter: 7440/16000, loss: 0.2965, lr: 0.005696, batch_cost: 0.1972, reader_cost: 0.00033, ips: 40.5766 samples/sec | ETA 00:28:07
2023-03-06 20:14:39 [INFO]	[TRAIN] epoch: 439, iter: 7450/16000, loss: 0.2261, lr: 0.005690, batch_cost: 0.2512, reader_cost: 0.04647, ips: 31.8507 samples/sec | ETA 00:35:47
2023-03-06 20:14:41 [INFO]	[TRAIN] epoch: 439, iter: 7460/16000, loss: 0.2231, lr: 0.005684, batch_cost: 0.2056, reader_cost: 0.01313, ips: 38.9105 samples/sec | ETA 00:29:15
2023-03-06 20:14:44 [INFO]	[TRAIN] epoch: 440, iter: 7470/16000, loss: 0.1876, lr: 0.005678, batch_cost: 0.2600, reader_cost: 0.05618, ips: 30.7751 samples/sec | ETA 00:36:57
2023-03-06 20:14:46 [INFO]	[TRAIN] epoch: 440, iter: 7480/16000, loss: 0.2276, lr: 0.005672, batch_cost: 0.1895, reader_cost: 0.00029, ips: 42.2087 samples/sec | ETA 00:26:54
2023-03-06 20:14:48 [INFO]	[TRAIN] epoch: 441, iter: 7490/16000, loss: 0.1547, lr: 0.005666, batch_cost: 0.2601, reader_cost: 0.05178, ips: 30.7560 samples/sec | ETA 00:36:53
2023-03-06 20:14:51 [INFO]	[TRAIN] epoch: 442, iter: 7500/16000, loss: 0.1957, lr: 0.005660, batch_cost: 0.2537, reader_cost: 0.03908, ips: 31.5331 samples/sec | ETA 00:35:56
2023-03-06 20:14:53 [INFO]	[TRAIN] epoch: 442, iter: 7510/16000, loss: 0.1970, lr: 0.005654, batch_cost: 0.2018, reader_cost: 0.00032, ips: 39.6510 samples/sec | ETA 00:28:32
2023-03-06 20:14:55 [INFO]	[TRAIN] epoch: 443, iter: 7520/16000, loss: 0.1877, lr: 0.005648, batch_cost: 0.2633, reader_cost: 0.04981, ips: 30.3885 samples/sec | ETA 00:37:12
2023-03-06 20:14:57 [INFO]	[TRAIN] epoch: 443, iter: 7530/16000, loss: 0.1715, lr: 0.005642, batch_cost: 0.1909, reader_cost: 0.00028, ips: 41.9031 samples/sec | ETA 00:26:57
2023-03-06 20:15:00 [INFO]	[TRAIN] epoch: 444, iter: 7540/16000, loss: 0.1886, lr: 0.005636, batch_cost: 0.2644, reader_cost: 0.04206, ips: 30.2543 samples/sec | ETA 00:37:17
2023-03-06 20:15:03 [INFO]	[TRAIN] epoch: 445, iter: 7550/16000, loss: 0.1802, lr: 0.005630, batch_cost: 0.2547, reader_cost: 0.05406, ips: 31.4140 samples/sec | ETA 00:35:51
2023-03-06 20:15:05 [INFO]	[TRAIN] epoch: 445, iter: 7560/16000, loss: 0.2263, lr: 0.005624, batch_cost: 0.1990, reader_cost: 0.00031, ips: 40.2079 samples/sec | ETA 00:27:59
2023-03-06 20:15:07 [INFO]	[TRAIN] epoch: 446, iter: 7570/16000, loss: 0.1919, lr: 0.005618, batch_cost: 0.2516, reader_cost: 0.05085, ips: 31.7923 samples/sec | ETA 00:35:21
2023-03-06 20:15:09 [INFO]	[TRAIN] epoch: 446, iter: 7580/16000, loss: 0.2245, lr: 0.005612, batch_cost: 0.1907, reader_cost: 0.00029, ips: 41.9456 samples/sec | ETA 00:26:45
2023-03-06 20:15:12 [INFO]	[TRAIN] epoch: 447, iter: 7590/16000, loss: 0.2033, lr: 0.005606, batch_cost: 0.2589, reader_cost: 0.04591, ips: 30.9034 samples/sec | ETA 00:36:17
2023-03-06 20:15:14 [INFO]	[TRAIN] epoch: 448, iter: 7600/16000, loss: 0.2562, lr: 0.005600, batch_cost: 0.2485, reader_cost: 0.03535, ips: 32.1956 samples/sec | ETA 00:34:47
2023-03-06 20:15:16 [INFO]	[TRAIN] epoch: 448, iter: 7610/16000, loss: 0.2790, lr: 0.005594, batch_cost: 0.1949, reader_cost: 0.00034, ips: 41.0397 samples/sec | ETA 00:27:15
2023-03-06 20:15:19 [INFO]	[TRAIN] epoch: 449, iter: 7620/16000, loss: 0.2675, lr: 0.005588, batch_cost: 0.2563, reader_cost: 0.05709, ips: 31.2102 samples/sec | ETA 00:35:48
2023-03-06 20:15:21 [INFO]	[TRAIN] epoch: 449, iter: 7630/16000, loss: 0.2175, lr: 0.005582, batch_cost: 0.1922, reader_cost: 0.00031, ips: 41.6180 samples/sec | ETA 00:26:48
2023-03-06 20:15:23 [INFO]	[TRAIN] epoch: 450, iter: 7640/16000, loss: 0.2337, lr: 0.005576, batch_cost: 0.2483, reader_cost: 0.04566, ips: 32.2150 samples/sec | ETA 00:34:36
2023-03-06 20:15:25 [INFO]	[TRAIN] epoch: 450, iter: 7650/16000, loss: 0.2500, lr: 0.005570, batch_cost: 0.1781, reader_cost: 0.00025, ips: 44.9197 samples/sec | ETA 00:24:47
2023-03-06 20:15:27 [INFO]	[TRAIN] epoch: 451, iter: 7660/16000, loss: 0.2740, lr: 0.005564, batch_cost: 0.2629, reader_cost: 0.04472, ips: 30.4252 samples/sec | ETA 00:36:32
2023-03-06 20:15:30 [INFO]	[TRAIN] epoch: 452, iter: 7670/16000, loss: 0.2824, lr: 0.005558, batch_cost: 0.2509, reader_cost: 0.04538, ips: 31.8856 samples/sec | ETA 00:34:49
2023-03-06 20:15:32 [INFO]	[TRAIN] epoch: 452, iter: 7680/16000, loss: 0.2297, lr: 0.005552, batch_cost: 0.1867, reader_cost: 0.00030, ips: 42.8451 samples/sec | ETA 00:25:53
2023-03-06 20:15:34 [INFO]	[TRAIN] epoch: 453, iter: 7690/16000, loss: 0.2138, lr: 0.005546, batch_cost: 0.2410, reader_cost: 0.03510, ips: 33.1957 samples/sec | ETA 00:33:22
2023-03-06 20:15:36 [INFO]	[TRAIN] epoch: 453, iter: 7700/16000, loss: 0.2445, lr: 0.005540, batch_cost: 0.1918, reader_cost: 0.00029, ips: 41.7033 samples/sec | ETA 00:26:32
2023-03-06 20:15:39 [INFO]	[TRAIN] epoch: 454, iter: 7710/16000, loss: 0.2318, lr: 0.005534, batch_cost: 0.2643, reader_cost: 0.06460, ips: 30.2636 samples/sec | ETA 00:36:31
2023-03-06 20:15:41 [INFO]	[TRAIN] epoch: 455, iter: 7720/16000, loss: 0.1777, lr: 0.005528, batch_cost: 0.2518, reader_cost: 0.04669, ips: 31.7705 samples/sec | ETA 00:34:44
2023-03-06 20:15:43 [INFO]	[TRAIN] epoch: 455, iter: 7730/16000, loss: 0.3629, lr: 0.005522, batch_cost: 0.1908, reader_cost: 0.00034, ips: 41.9360 samples/sec | ETA 00:26:17
2023-03-06 20:15:46 [INFO]	[TRAIN] epoch: 456, iter: 7740/16000, loss: 0.2855, lr: 0.005516, batch_cost: 0.2579, reader_cost: 0.05096, ips: 31.0212 samples/sec | ETA 00:35:30
2023-03-06 20:15:48 [INFO]	[TRAIN] epoch: 456, iter: 7750/16000, loss: 0.2179, lr: 0.005510, batch_cost: 0.1857, reader_cost: 0.00027, ips: 43.0717 samples/sec | ETA 00:25:32
2023-03-06 20:15:50 [INFO]	[TRAIN] epoch: 457, iter: 7760/16000, loss: 0.2151, lr: 0.005504, batch_cost: 0.2525, reader_cost: 0.05506, ips: 31.6843 samples/sec | ETA 00:34:40
2023-03-06 20:15:53 [INFO]	[TRAIN] epoch: 458, iter: 7770/16000, loss: 0.2013, lr: 0.005498, batch_cost: 0.2503, reader_cost: 0.04596, ips: 31.9617 samples/sec | ETA 00:34:19
2023-03-06 20:15:55 [INFO]	[TRAIN] epoch: 458, iter: 7780/16000, loss: 0.1761, lr: 0.005492, batch_cost: 0.2123, reader_cost: 0.00031, ips: 37.6739 samples/sec | ETA 00:29:05
2023-03-06 20:15:57 [INFO]	[TRAIN] epoch: 459, iter: 7790/16000, loss: 0.2652, lr: 0.005486, batch_cost: 0.2571, reader_cost: 0.04246, ips: 31.1206 samples/sec | ETA 00:35:10
2023-03-06 20:15:59 [INFO]	[TRAIN] epoch: 459, iter: 7800/16000, loss: 0.2333, lr: 0.005480, batch_cost: 0.1887, reader_cost: 0.00028, ips: 42.3864 samples/sec | ETA 00:25:47
2023-03-06 20:16:02 [INFO]	[TRAIN] epoch: 460, iter: 7810/16000, loss: 0.2315, lr: 0.005474, batch_cost: 0.2568, reader_cost: 0.05458, ips: 31.1499 samples/sec | ETA 00:35:03
2023-03-06 20:16:04 [INFO]	[TRAIN] epoch: 460, iter: 7820/16000, loss: 0.1817, lr: 0.005468, batch_cost: 0.1828, reader_cost: 0.00025, ips: 43.7598 samples/sec | ETA 00:24:55
2023-03-06 20:16:06 [INFO]	[TRAIN] epoch: 461, iter: 7830/16000, loss: 0.2487, lr: 0.005462, batch_cost: 0.2538, reader_cost: 0.05113, ips: 31.5179 samples/sec | ETA 00:34:33
2023-03-06 20:16:09 [INFO]	[TRAIN] epoch: 462, iter: 7840/16000, loss: 0.2325, lr: 0.005456, batch_cost: 0.2525, reader_cost: 0.03726, ips: 31.6831 samples/sec | ETA 00:34:20
2023-03-06 20:16:11 [INFO]	[TRAIN] epoch: 462, iter: 7850/16000, loss: 0.2907, lr: 0.005450, batch_cost: 0.1856, reader_cost: 0.00026, ips: 43.0997 samples/sec | ETA 00:25:12
2023-03-06 20:16:13 [INFO]	[TRAIN] epoch: 463, iter: 7860/16000, loss: 0.2989, lr: 0.005444, batch_cost: 0.2410, reader_cost: 0.04731, ips: 33.1991 samples/sec | ETA 00:32:41
2023-03-06 20:16:15 [INFO]	[TRAIN] epoch: 463, iter: 7870/16000, loss: 0.2193, lr: 0.005438, batch_cost: 0.1821, reader_cost: 0.00029, ips: 43.9316 samples/sec | ETA 00:24:40
2023-03-06 20:16:17 [INFO]	[TRAIN] epoch: 464, iter: 7880/16000, loss: 0.2357, lr: 0.005432, batch_cost: 0.2326, reader_cost: 0.03624, ips: 34.4009 samples/sec | ETA 00:31:28
2023-03-06 20:16:20 [INFO]	[TRAIN] epoch: 465, iter: 7890/16000, loss: 0.1660, lr: 0.005426, batch_cost: 0.2479, reader_cost: 0.05781, ips: 32.2714 samples/sec | ETA 00:33:30
2023-03-06 20:16:22 [INFO]	[TRAIN] epoch: 465, iter: 7900/16000, loss: 0.2910, lr: 0.005420, batch_cost: 0.1917, reader_cost: 0.00031, ips: 41.7278 samples/sec | ETA 00:25:52
2023-03-06 20:16:24 [INFO]	[TRAIN] epoch: 466, iter: 7910/16000, loss: 0.1785, lr: 0.005414, batch_cost: 0.2567, reader_cost: 0.03910, ips: 31.1682 samples/sec | ETA 00:34:36
2023-03-06 20:16:26 [INFO]	[TRAIN] epoch: 466, iter: 7920/16000, loss: 0.2262, lr: 0.005408, batch_cost: 0.2042, reader_cost: 0.00029, ips: 39.1840 samples/sec | ETA 00:27:29
2023-03-06 20:16:29 [INFO]	[TRAIN] epoch: 467, iter: 7930/16000, loss: 0.2677, lr: 0.005402, batch_cost: 0.2591, reader_cost: 0.04523, ips: 30.8767 samples/sec | ETA 00:34:50
2023-03-06 20:16:31 [INFO]	[TRAIN] epoch: 468, iter: 7940/16000, loss: 0.3251, lr: 0.005396, batch_cost: 0.2437, reader_cost: 0.03978, ips: 32.8281 samples/sec | ETA 00:32:44
2023-03-06 20:16:33 [INFO]	[TRAIN] epoch: 468, iter: 7950/16000, loss: 0.3593, lr: 0.005390, batch_cost: 0.1942, reader_cost: 0.00030, ips: 41.1926 samples/sec | ETA 00:26:03
2023-03-06 20:16:36 [INFO]	[TRAIN] epoch: 469, iter: 7960/16000, loss: 0.2107, lr: 0.005384, batch_cost: 0.2526, reader_cost: 0.04844, ips: 31.6759 samples/sec | ETA 00:33:50
2023-03-06 20:16:37 [INFO]	[TRAIN] epoch: 469, iter: 7970/16000, loss: 0.2249, lr: 0.005378, batch_cost: 0.1800, reader_cost: 0.00026, ips: 44.4476 samples/sec | ETA 00:24:05
2023-03-06 20:16:40 [INFO]	[TRAIN] epoch: 470, iter: 7980/16000, loss: 0.2897, lr: 0.005372, batch_cost: 0.2390, reader_cost: 0.03975, ips: 33.4757 samples/sec | ETA 00:31:56
2023-03-06 20:16:42 [INFO]	[TRAIN] epoch: 470, iter: 7990/16000, loss: 0.2596, lr: 0.005365, batch_cost: 0.1918, reader_cost: 0.00029, ips: 41.7028 samples/sec | ETA 00:25:36
2023-03-06 20:16:44 [INFO]	[TRAIN] epoch: 471, iter: 8000/16000, loss: 0.2937, lr: 0.005359, batch_cost: 0.2448, reader_cost: 0.04452, ips: 32.6841 samples/sec | ETA 00:32:38
2023-03-06 20:16:44 [INFO]	Start evaluating (total_samples: 119, total_iters: 60)...
60/60 - 3s - batch_cost: 0.0549 - reader cost: 0.0019
2023-03-06 20:16:48 [INFO]	[EVAL] #Images: 119 mIoU: 0.7758 Acc: 0.9331 Kappa: 0.7316 Dice: 0.8658
2023-03-06 20:16:48 [INFO]	[EVAL] Class IoU: 
[0.9246 0.627 ]
2023-03-06 20:16:48 [INFO]	[EVAL] Class Precision: 
[0.958  0.7842]
2023-03-06 20:16:48 [INFO]	[EVAL] Class Recall: 
[0.9636 0.7578]
2023-03-06 20:16:49 [INFO]	[EVAL] The model with the best validation mIoU (0.7758) was saved at iter 8000.
2023-03-06 20:16:51 [INFO]	[TRAIN] epoch: 472, iter: 8010/16000, loss: 0.2030, lr: 0.005353, batch_cost: 0.2416, reader_cost: 0.04230, ips: 33.1085 samples/sec | ETA 00:32:10
2023-03-06 20:16:53 [INFO]	[TRAIN] epoch: 472, iter: 8020/16000, loss: 0.2515, lr: 0.005347, batch_cost: 0.1895, reader_cost: 0.00031, ips: 42.2189 samples/sec | ETA 00:25:12
2023-03-06 20:16:55 [INFO]	[TRAIN] epoch: 473, iter: 8030/16000, loss: 0.2929, lr: 0.005341, batch_cost: 0.2379, reader_cost: 0.04297, ips: 33.6268 samples/sec | ETA 00:31:36
2023-03-06 20:16:57 [INFO]	[TRAIN] epoch: 473, iter: 8040/16000, loss: 0.1735, lr: 0.005335, batch_cost: 0.1853, reader_cost: 0.00025, ips: 43.1745 samples/sec | ETA 00:24:34
2023-03-06 20:17:00 [INFO]	[TRAIN] epoch: 474, iter: 8050/16000, loss: 0.2782, lr: 0.005329, batch_cost: 0.2786, reader_cost: 0.06443, ips: 28.7181 samples/sec | ETA 00:36:54
2023-03-06 20:17:03 [INFO]	[TRAIN] epoch: 475, iter: 8060/16000, loss: 0.2355, lr: 0.005323, batch_cost: 0.2532, reader_cost: 0.05637, ips: 31.5928 samples/sec | ETA 00:33:30
2023-03-06 20:17:04 [INFO]	[TRAIN] epoch: 475, iter: 8070/16000, loss: 0.2337, lr: 0.005317, batch_cost: 0.1872, reader_cost: 0.00029, ips: 42.7240 samples/sec | ETA 00:24:44
2023-03-06 20:17:07 [INFO]	[TRAIN] epoch: 476, iter: 8080/16000, loss: 0.1887, lr: 0.005311, batch_cost: 0.2646, reader_cost: 0.06631, ips: 30.2330 samples/sec | ETA 00:34:55
2023-03-06 20:17:09 [INFO]	[TRAIN] epoch: 476, iter: 8090/16000, loss: 0.1877, lr: 0.005305, batch_cost: 0.1933, reader_cost: 0.00028, ips: 41.3836 samples/sec | ETA 00:25:29
2023-03-06 20:17:11 [INFO]	[TRAIN] epoch: 477, iter: 8100/16000, loss: 0.2589, lr: 0.005299, batch_cost: 0.2419, reader_cost: 0.04001, ips: 33.0661 samples/sec | ETA 00:31:51
2023-03-06 20:17:14 [INFO]	[TRAIN] epoch: 478, iter: 8110/16000, loss: 0.2125, lr: 0.005293, batch_cost: 0.2586, reader_cost: 0.04101, ips: 30.9365 samples/sec | ETA 00:34:00
2023-03-06 20:17:16 [INFO]	[TRAIN] epoch: 478, iter: 8120/16000, loss: 0.3876, lr: 0.005287, batch_cost: 0.1924, reader_cost: 0.00031, ips: 41.5850 samples/sec | ETA 00:25:15
2023-03-06 20:17:18 [INFO]	[TRAIN] epoch: 479, iter: 8130/16000, loss: 0.2252, lr: 0.005281, batch_cost: 0.2452, reader_cost: 0.04279, ips: 32.6252 samples/sec | ETA 00:32:09
2023-03-06 20:17:20 [INFO]	[TRAIN] epoch: 479, iter: 8140/16000, loss: 0.2349, lr: 0.005275, batch_cost: 0.1860, reader_cost: 0.00028, ips: 43.0131 samples/sec | ETA 00:24:21
2023-03-06 20:17:23 [INFO]	[TRAIN] epoch: 480, iter: 8150/16000, loss: 0.1864, lr: 0.005269, batch_cost: 0.2541, reader_cost: 0.05060, ips: 31.4843 samples/sec | ETA 00:33:14
2023-03-06 20:17:25 [INFO]	[TRAIN] epoch: 480, iter: 8160/16000, loss: 0.1926, lr: 0.005263, batch_cost: 0.1918, reader_cost: 0.00027, ips: 41.7146 samples/sec | ETA 00:25:03
2023-03-06 20:17:27 [INFO]	[TRAIN] epoch: 481, iter: 8170/16000, loss: 0.3165, lr: 0.005257, batch_cost: 0.2440, reader_cost: 0.04062, ips: 32.7887 samples/sec | ETA 00:31:50
2023-03-06 20:17:30 [INFO]	[TRAIN] epoch: 482, iter: 8180/16000, loss: 0.2496, lr: 0.005251, batch_cost: 0.2605, reader_cost: 0.05551, ips: 30.7056 samples/sec | ETA 00:33:57
2023-03-06 20:17:32 [INFO]	[TRAIN] epoch: 482, iter: 8190/16000, loss: 0.1899, lr: 0.005245, batch_cost: 0.1947, reader_cost: 0.00033, ips: 41.0846 samples/sec | ETA 00:25:20
2023-03-06 20:17:34 [INFO]	[TRAIN] epoch: 483, iter: 8200/16000, loss: 0.1875, lr: 0.005239, batch_cost: 0.2481, reader_cost: 0.04042, ips: 32.2506 samples/sec | ETA 00:32:14
2023-03-06 20:17:36 [INFO]	[TRAIN] epoch: 483, iter: 8210/16000, loss: 0.1817, lr: 0.005233, batch_cost: 0.1885, reader_cost: 0.00040, ips: 42.4473 samples/sec | ETA 00:24:28
2023-03-06 20:17:39 [INFO]	[TRAIN] epoch: 484, iter: 8220/16000, loss: 0.3012, lr: 0.005227, batch_cost: 0.2535, reader_cost: 0.04533, ips: 31.5521 samples/sec | ETA 00:32:52
2023-03-06 20:17:41 [INFO]	[TRAIN] epoch: 485, iter: 8230/16000, loss: 0.1826, lr: 0.005221, batch_cost: 0.2552, reader_cost: 0.04214, ips: 31.3459 samples/sec | ETA 00:33:03
2023-03-06 20:17:43 [INFO]	[TRAIN] epoch: 485, iter: 8240/16000, loss: 0.2698, lr: 0.005215, batch_cost: 0.1917, reader_cost: 0.00030, ips: 41.7236 samples/sec | ETA 00:24:47
2023-03-06 20:17:46 [INFO]	[TRAIN] epoch: 486, iter: 8250/16000, loss: 0.3703, lr: 0.005209, batch_cost: 0.2413, reader_cost: 0.04449, ips: 33.1603 samples/sec | ETA 00:31:09
2023-03-06 20:17:47 [INFO]	[TRAIN] epoch: 486, iter: 8260/16000, loss: 0.1875, lr: 0.005202, batch_cost: 0.1873, reader_cost: 0.00030, ips: 42.7209 samples/sec | ETA 00:24:09
2023-03-06 20:17:50 [INFO]	[TRAIN] epoch: 487, iter: 8270/16000, loss: 0.2086, lr: 0.005196, batch_cost: 0.2485, reader_cost: 0.03318, ips: 32.1934 samples/sec | ETA 00:32:00
2023-03-06 20:17:53 [INFO]	[TRAIN] epoch: 488, iter: 8280/16000, loss: 0.2871, lr: 0.005190, batch_cost: 0.2619, reader_cost: 0.05873, ips: 30.5458 samples/sec | ETA 00:33:41
2023-03-06 20:17:54 [INFO]	[TRAIN] epoch: 488, iter: 8290/16000, loss: 0.2142, lr: 0.005184, batch_cost: 0.1944, reader_cost: 0.00030, ips: 41.1536 samples/sec | ETA 00:24:58
2023-03-06 20:17:57 [INFO]	[TRAIN] epoch: 489, iter: 8300/16000, loss: 0.2221, lr: 0.005178, batch_cost: 0.2831, reader_cost: 0.04202, ips: 28.2547 samples/sec | ETA 00:36:20
2023-03-06 20:17:59 [INFO]	[TRAIN] epoch: 489, iter: 8310/16000, loss: 0.2224, lr: 0.005172, batch_cost: 0.1901, reader_cost: 0.00032, ips: 42.0858 samples/sec | ETA 00:24:21
2023-03-06 20:18:02 [INFO]	[TRAIN] epoch: 490, iter: 8320/16000, loss: 0.2556, lr: 0.005166, batch_cost: 0.2405, reader_cost: 0.04085, ips: 33.2648 samples/sec | ETA 00:30:46
2023-03-06 20:18:04 [INFO]	[TRAIN] epoch: 490, iter: 8330/16000, loss: 0.2300, lr: 0.005160, batch_cost: 0.1922, reader_cost: 0.00030, ips: 41.6174 samples/sec | ETA 00:24:34
2023-03-06 20:18:06 [INFO]	[TRAIN] epoch: 491, iter: 8340/16000, loss: 0.1572, lr: 0.005154, batch_cost: 0.2497, reader_cost: 0.03612, ips: 32.0399 samples/sec | ETA 00:31:52
2023-03-06 20:18:09 [INFO]	[TRAIN] epoch: 492, iter: 8350/16000, loss: 0.3453, lr: 0.005148, batch_cost: 0.2655, reader_cost: 0.04936, ips: 30.1365 samples/sec | ETA 00:33:50
2023-03-06 20:18:11 [INFO]	[TRAIN] epoch: 492, iter: 8360/16000, loss: 0.1968, lr: 0.005142, batch_cost: 0.1893, reader_cost: 0.00027, ips: 42.2630 samples/sec | ETA 00:24:06
2023-03-06 20:18:13 [INFO]	[TRAIN] epoch: 493, iter: 8370/16000, loss: 0.1904, lr: 0.005136, batch_cost: 0.2582, reader_cost: 0.03816, ips: 30.9805 samples/sec | ETA 00:32:50
2023-03-06 20:18:15 [INFO]	[TRAIN] epoch: 493, iter: 8380/16000, loss: 0.2402, lr: 0.005130, batch_cost: 0.2296, reader_cost: 0.00024, ips: 34.8358 samples/sec | ETA 00:29:09
2023-03-06 20:18:18 [INFO]	[TRAIN] epoch: 494, iter: 8390/16000, loss: 0.2644, lr: 0.005124, batch_cost: 0.2559, reader_cost: 0.04216, ips: 31.2595 samples/sec | ETA 00:32:27
2023-03-06 20:18:20 [INFO]	[TRAIN] epoch: 495, iter: 8400/16000, loss: 0.1829, lr: 0.005118, batch_cost: 0.2427, reader_cost: 0.03566, ips: 32.9665 samples/sec | ETA 00:30:44
2023-03-06 20:18:22 [INFO]	[TRAIN] epoch: 495, iter: 8410/16000, loss: 0.2169, lr: 0.005112, batch_cost: 0.1991, reader_cost: 0.00029, ips: 40.1761 samples/sec | ETA 00:25:11
2023-03-06 20:18:25 [INFO]	[TRAIN] epoch: 496, iter: 8420/16000, loss: 0.3035, lr: 0.005106, batch_cost: 0.2597, reader_cost: 0.05764, ips: 30.8093 samples/sec | ETA 00:32:48
2023-03-06 20:18:27 [INFO]	[TRAIN] epoch: 496, iter: 8430/16000, loss: 0.2785, lr: 0.005100, batch_cost: 0.1927, reader_cost: 0.00026, ips: 41.5205 samples/sec | ETA 00:24:18
2023-03-06 20:18:29 [INFO]	[TRAIN] epoch: 497, iter: 8440/16000, loss: 0.3471, lr: 0.005093, batch_cost: 0.2528, reader_cost: 0.03968, ips: 31.6461 samples/sec | ETA 00:31:51
2023-03-06 20:18:32 [INFO]	[TRAIN] epoch: 498, iter: 8450/16000, loss: 0.1990, lr: 0.005087, batch_cost: 0.2351, reader_cost: 0.03833, ips: 34.0336 samples/sec | ETA 00:29:34
2023-03-06 20:18:34 [INFO]	[TRAIN] epoch: 498, iter: 8460/16000, loss: 0.2873, lr: 0.005081, batch_cost: 0.2006, reader_cost: 0.00031, ips: 39.8792 samples/sec | ETA 00:25:12
2023-03-06 20:18:36 [INFO]	[TRAIN] epoch: 499, iter: 8470/16000, loss: 0.1991, lr: 0.005075, batch_cost: 0.2538, reader_cost: 0.05620, ips: 31.5218 samples/sec | ETA 00:31:51
2023-03-06 20:18:38 [INFO]	[TRAIN] epoch: 499, iter: 8480/16000, loss: 0.1996, lr: 0.005069, batch_cost: 0.1991, reader_cost: 0.00029, ips: 40.1711 samples/sec | ETA 00:24:57
2023-03-06 20:18:41 [INFO]	[TRAIN] epoch: 500, iter: 8490/16000, loss: 0.1985, lr: 0.005063, batch_cost: 0.2682, reader_cost: 0.04481, ips: 29.8292 samples/sec | ETA 00:33:34
2023-03-06 20:18:43 [INFO]	[TRAIN] epoch: 500, iter: 8500/16000, loss: 0.1958, lr: 0.005057, batch_cost: 0.1916, reader_cost: 0.00028, ips: 41.7433 samples/sec | ETA 00:23:57
2023-03-06 20:18:46 [INFO]	[TRAIN] epoch: 501, iter: 8510/16000, loss: 0.1850, lr: 0.005051, batch_cost: 0.2664, reader_cost: 0.05247, ips: 30.0338 samples/sec | ETA 00:33:15
2023-03-06 20:18:48 [INFO]	[TRAIN] epoch: 502, iter: 8520/16000, loss: 0.2447, lr: 0.005045, batch_cost: 0.2758, reader_cost: 0.07418, ips: 29.0046 samples/sec | ETA 00:34:23
2023-03-06 20:18:50 [INFO]	[TRAIN] epoch: 502, iter: 8530/16000, loss: 0.2808, lr: 0.005039, batch_cost: 0.1944, reader_cost: 0.00026, ips: 41.1515 samples/sec | ETA 00:24:12
2023-03-06 20:18:53 [INFO]	[TRAIN] epoch: 503, iter: 8540/16000, loss: 0.2702, lr: 0.005033, batch_cost: 0.2590, reader_cost: 0.05018, ips: 30.8907 samples/sec | ETA 00:32:11
2023-03-06 20:18:55 [INFO]	[TRAIN] epoch: 503, iter: 8550/16000, loss: 0.2672, lr: 0.005027, batch_cost: 0.1877, reader_cost: 0.00028, ips: 42.6268 samples/sec | ETA 00:23:18
2023-03-06 20:18:57 [INFO]	[TRAIN] epoch: 504, iter: 8560/16000, loss: 0.2619, lr: 0.005021, batch_cost: 0.2509, reader_cost: 0.04479, ips: 31.8880 samples/sec | ETA 00:31:06
2023-03-06 20:19:00 [INFO]	[TRAIN] epoch: 505, iter: 8570/16000, loss: 0.2705, lr: 0.005015, batch_cost: 0.2677, reader_cost: 0.06414, ips: 29.8857 samples/sec | ETA 00:33:08
2023-03-06 20:19:02 [INFO]	[TRAIN] epoch: 505, iter: 8580/16000, loss: 0.2521, lr: 0.005009, batch_cost: 0.1923, reader_cost: 0.00030, ips: 41.5917 samples/sec | ETA 00:23:47
2023-03-06 20:19:04 [INFO]	[TRAIN] epoch: 506, iter: 8590/16000, loss: 0.2644, lr: 0.005002, batch_cost: 0.2497, reader_cost: 0.05278, ips: 32.0378 samples/sec | ETA 00:30:50
2023-03-06 20:19:06 [INFO]	[TRAIN] epoch: 506, iter: 8600/16000, loss: 0.2075, lr: 0.004996, batch_cost: 0.1977, reader_cost: 0.00025, ips: 40.4718 samples/sec | ETA 00:24:22
2023-03-06 20:19:09 [INFO]	[TRAIN] epoch: 507, iter: 8610/16000, loss: 0.2589, lr: 0.004990, batch_cost: 0.2590, reader_cost: 0.03987, ips: 30.8837 samples/sec | ETA 00:31:54
2023-03-06 20:19:11 [INFO]	[TRAIN] epoch: 508, iter: 8620/16000, loss: 0.2850, lr: 0.004984, batch_cost: 0.2407, reader_cost: 0.04875, ips: 33.2363 samples/sec | ETA 00:29:36
2023-03-06 20:19:13 [INFO]	[TRAIN] epoch: 508, iter: 8630/16000, loss: 0.2709, lr: 0.004978, batch_cost: 0.1919, reader_cost: 0.00028, ips: 41.6877 samples/sec | ETA 00:23:34
2023-03-06 20:19:16 [INFO]	[TRAIN] epoch: 509, iter: 8640/16000, loss: 0.2030, lr: 0.004972, batch_cost: 0.2524, reader_cost: 0.04467, ips: 31.6918 samples/sec | ETA 00:30:57
2023-03-06 20:19:18 [INFO]	[TRAIN] epoch: 509, iter: 8650/16000, loss: 0.2329, lr: 0.004966, batch_cost: 0.1890, reader_cost: 0.00026, ips: 42.3267 samples/sec | ETA 00:23:09
2023-03-06 20:19:21 [INFO]	[TRAIN] epoch: 510, iter: 8660/16000, loss: 0.3281, lr: 0.004960, batch_cost: 0.2793, reader_cost: 0.05387, ips: 28.6420 samples/sec | ETA 00:34:10
2023-03-06 20:19:23 [INFO]	[TRAIN] epoch: 510, iter: 8670/16000, loss: 0.2018, lr: 0.004954, batch_cost: 0.2162, reader_cost: 0.00035, ips: 37.0004 samples/sec | ETA 00:26:24
2023-03-06 20:19:25 [INFO]	[TRAIN] epoch: 511, iter: 8680/16000, loss: 0.2364, lr: 0.004948, batch_cost: 0.2588, reader_cost: 0.04686, ips: 30.9104 samples/sec | ETA 00:31:34
2023-03-06 20:19:28 [INFO]	[TRAIN] epoch: 512, iter: 8690/16000, loss: 0.2034, lr: 0.004942, batch_cost: 0.2632, reader_cost: 0.03764, ips: 30.3933 samples/sec | ETA 00:32:04
2023-03-06 20:19:30 [INFO]	[TRAIN] epoch: 512, iter: 8700/16000, loss: 0.2521, lr: 0.004936, batch_cost: 0.1949, reader_cost: 0.00035, ips: 41.0457 samples/sec | ETA 00:23:42
2023-03-06 20:19:32 [INFO]	[TRAIN] epoch: 513, iter: 8710/16000, loss: 0.3009, lr: 0.004929, batch_cost: 0.2516, reader_cost: 0.03407, ips: 31.7997 samples/sec | ETA 00:30:33
2023-03-06 20:19:34 [INFO]	[TRAIN] epoch: 513, iter: 8720/16000, loss: 0.2233, lr: 0.004923, batch_cost: 0.1893, reader_cost: 0.00028, ips: 42.2695 samples/sec | ETA 00:22:57
2023-03-06 20:19:37 [INFO]	[TRAIN] epoch: 514, iter: 8730/16000, loss: 0.2644, lr: 0.004917, batch_cost: 0.2616, reader_cost: 0.06228, ips: 30.5756 samples/sec | ETA 00:31:42
2023-03-06 20:19:39 [INFO]	[TRAIN] epoch: 515, iter: 8740/16000, loss: 0.2508, lr: 0.004911, batch_cost: 0.2520, reader_cost: 0.04757, ips: 31.7450 samples/sec | ETA 00:30:29
2023-03-06 20:19:41 [INFO]	[TRAIN] epoch: 515, iter: 8750/16000, loss: 0.2687, lr: 0.004905, batch_cost: 0.1908, reader_cost: 0.00033, ips: 41.9396 samples/sec | ETA 00:23:02
2023-03-06 20:19:44 [INFO]	[TRAIN] epoch: 516, iter: 8760/16000, loss: 0.2060, lr: 0.004899, batch_cost: 0.2569, reader_cost: 0.04834, ips: 31.1425 samples/sec | ETA 00:30:59
2023-03-06 20:19:46 [INFO]	[TRAIN] epoch: 516, iter: 8770/16000, loss: 0.1975, lr: 0.004893, batch_cost: 0.1993, reader_cost: 0.00032, ips: 40.1464 samples/sec | ETA 00:24:00
2023-03-06 20:19:49 [INFO]	[TRAIN] epoch: 517, iter: 8780/16000, loss: 0.2132, lr: 0.004887, batch_cost: 0.2679, reader_cost: 0.04832, ips: 29.8565 samples/sec | ETA 00:32:14
2023-03-06 20:19:51 [INFO]	[TRAIN] epoch: 518, iter: 8790/16000, loss: 0.2590, lr: 0.004881, batch_cost: 0.2519, reader_cost: 0.04313, ips: 31.7622 samples/sec | ETA 00:30:15
2023-03-06 20:19:53 [INFO]	[TRAIN] epoch: 518, iter: 8800/16000, loss: 0.2765, lr: 0.004875, batch_cost: 0.1949, reader_cost: 0.00032, ips: 41.0442 samples/sec | ETA 00:23:23
2023-03-06 20:19:56 [INFO]	[TRAIN] epoch: 519, iter: 8810/16000, loss: 0.2457, lr: 0.004869, batch_cost: 0.2494, reader_cost: 0.03764, ips: 32.0746 samples/sec | ETA 00:29:53
2023-03-06 20:19:57 [INFO]	[TRAIN] epoch: 519, iter: 8820/16000, loss: 0.2331, lr: 0.004862, batch_cost: 0.1911, reader_cost: 0.00029, ips: 41.8609 samples/sec | ETA 00:22:52
2023-03-06 20:20:00 [INFO]	[TRAIN] epoch: 520, iter: 8830/16000, loss: 0.2309, lr: 0.004856, batch_cost: 0.2542, reader_cost: 0.04810, ips: 31.4653 samples/sec | ETA 00:30:22
2023-03-06 20:20:02 [INFO]	[TRAIN] epoch: 520, iter: 8840/16000, loss: 0.2354, lr: 0.004850, batch_cost: 0.2386, reader_cost: 0.00028, ips: 33.5356 samples/sec | ETA 00:28:28
2023-03-06 20:20:05 [INFO]	[TRAIN] epoch: 521, iter: 8850/16000, loss: 0.2180, lr: 0.004844, batch_cost: 0.2428, reader_cost: 0.04289, ips: 32.9465 samples/sec | ETA 00:28:56
2023-03-06 20:20:07 [INFO]	[TRAIN] epoch: 522, iter: 8860/16000, loss: 0.2363, lr: 0.004838, batch_cost: 0.2591, reader_cost: 0.04513, ips: 30.8816 samples/sec | ETA 00:30:49
2023-03-06 20:20:09 [INFO]	[TRAIN] epoch: 522, iter: 8870/16000, loss: 0.2702, lr: 0.004832, batch_cost: 0.2055, reader_cost: 0.00031, ips: 38.9343 samples/sec | ETA 00:24:25
2023-03-06 20:20:12 [INFO]	[TRAIN] epoch: 523, iter: 8880/16000, loss: 0.3076, lr: 0.004826, batch_cost: 0.2556, reader_cost: 0.03930, ips: 31.2999 samples/sec | ETA 00:30:19
2023-03-06 20:20:14 [INFO]	[TRAIN] epoch: 523, iter: 8890/16000, loss: 0.2102, lr: 0.004820, batch_cost: 0.1855, reader_cost: 0.00025, ips: 43.1301 samples/sec | ETA 00:21:58
2023-03-06 20:20:16 [INFO]	[TRAIN] epoch: 524, iter: 8900/16000, loss: 0.2270, lr: 0.004814, batch_cost: 0.2414, reader_cost: 0.04051, ips: 33.1460 samples/sec | ETA 00:28:33
2023-03-06 20:20:19 [INFO]	[TRAIN] epoch: 525, iter: 8910/16000, loss: 0.2281, lr: 0.004808, batch_cost: 0.2596, reader_cost: 0.06225, ips: 30.8131 samples/sec | ETA 00:30:40
2023-03-06 20:20:21 [INFO]	[TRAIN] epoch: 525, iter: 8920/16000, loss: 0.3273, lr: 0.004802, batch_cost: 0.1905, reader_cost: 0.00035, ips: 42.0027 samples/sec | ETA 00:22:28
2023-03-06 20:20:23 [INFO]	[TRAIN] epoch: 526, iter: 8930/16000, loss: 0.2455, lr: 0.004795, batch_cost: 0.2571, reader_cost: 0.05988, ips: 31.1202 samples/sec | ETA 00:30:17
2023-03-06 20:20:25 [INFO]	[TRAIN] epoch: 526, iter: 8940/16000, loss: 0.3358, lr: 0.004789, batch_cost: 0.2065, reader_cost: 0.00026, ips: 38.7502 samples/sec | ETA 00:24:17
2023-03-06 20:20:28 [INFO]	[TRAIN] epoch: 527, iter: 8950/16000, loss: 0.2410, lr: 0.004783, batch_cost: 0.3028, reader_cost: 0.03797, ips: 26.4200 samples/sec | ETA 00:35:34
2023-03-06 20:20:31 [INFO]	[TRAIN] epoch: 528, iter: 8960/16000, loss: 0.2050, lr: 0.004777, batch_cost: 0.2737, reader_cost: 0.05313, ips: 29.2246 samples/sec | ETA 00:32:07
2023-03-06 20:20:33 [INFO]	[TRAIN] epoch: 528, iter: 8970/16000, loss: 0.2929, lr: 0.004771, batch_cost: 0.1990, reader_cost: 0.00034, ips: 40.1963 samples/sec | ETA 00:23:19
2023-03-06 20:20:36 [INFO]	[TRAIN] epoch: 529, iter: 8980/16000, loss: 0.2227, lr: 0.004765, batch_cost: 0.2459, reader_cost: 0.04524, ips: 32.5292 samples/sec | ETA 00:28:46
2023-03-06 20:20:37 [INFO]	[TRAIN] epoch: 529, iter: 8990/16000, loss: 0.1857, lr: 0.004759, batch_cost: 0.1846, reader_cost: 0.00026, ips: 43.3444 samples/sec | ETA 00:21:33
2023-03-06 20:20:40 [INFO]	[TRAIN] epoch: 530, iter: 9000/16000, loss: 0.2431, lr: 0.004753, batch_cost: 0.2601, reader_cost: 0.04132, ips: 30.7632 samples/sec | ETA 00:30:20
2023-03-06 20:20:40 [INFO]	Start evaluating (total_samples: 119, total_iters: 60)...
60/60 - 4s - batch_cost: 0.0604 - reader cost: 0.0020
2023-03-06 20:20:44 [INFO]	[EVAL] #Images: 119 mIoU: 0.7624 Acc: 0.9279 Kappa: 0.7124 Dice: 0.8562
2023-03-06 20:20:44 [INFO]	[EVAL] Class IoU: 
[0.9189 0.606 ]
2023-03-06 20:20:44 [INFO]	[EVAL] Class Precision: 
[0.956  0.7627]
2023-03-06 20:20:44 [INFO]	[EVAL] Class Recall: 
[0.9595 0.7467]
2023-03-06 20:20:44 [INFO]	[EVAL] The model with the best validation mIoU (0.7758) was saved at iter 8000.
2023-03-06 20:20:47 [INFO]	[TRAIN] epoch: 530, iter: 9010/16000, loss: 0.2071, lr: 0.004747, batch_cost: 0.2110, reader_cost: 0.00026, ips: 37.9141 samples/sec | ETA 00:24:34
2023-03-06 20:20:49 [INFO]	[TRAIN] epoch: 531, iter: 9020/16000, loss: 0.2263, lr: 0.004740, batch_cost: 0.2521, reader_cost: 0.04896, ips: 31.7296 samples/sec | ETA 00:29:19
2023-03-06 20:20:52 [INFO]	[TRAIN] epoch: 532, iter: 9030/16000, loss: 0.3417, lr: 0.004734, batch_cost: 0.2469, reader_cost: 0.04746, ips: 32.4047 samples/sec | ETA 00:28:40
2023-03-06 20:20:53 [INFO]	[TRAIN] epoch: 532, iter: 9040/16000, loss: 0.2540, lr: 0.004728, batch_cost: 0.1822, reader_cost: 0.00028, ips: 43.8985 samples/sec | ETA 00:21:08
2023-03-06 20:20:56 [INFO]	[TRAIN] epoch: 533, iter: 9050/16000, loss: 0.2000, lr: 0.004722, batch_cost: 0.2695, reader_cost: 0.05157, ips: 29.6814 samples/sec | ETA 00:31:13
2023-03-06 20:20:58 [INFO]	[TRAIN] epoch: 533, iter: 9060/16000, loss: 0.1907, lr: 0.004716, batch_cost: 0.2261, reader_cost: 0.00028, ips: 35.3879 samples/sec | ETA 00:26:08
2023-03-06 20:21:01 [INFO]	[TRAIN] epoch: 534, iter: 9070/16000, loss: 0.2634, lr: 0.004710, batch_cost: 0.2410, reader_cost: 0.03916, ips: 33.1892 samples/sec | ETA 00:27:50
2023-03-06 20:21:03 [INFO]	[TRAIN] epoch: 535, iter: 9080/16000, loss: 0.2472, lr: 0.004704, batch_cost: 0.2500, reader_cost: 0.05072, ips: 31.9972 samples/sec | ETA 00:28:50
2023-03-06 20:21:05 [INFO]	[TRAIN] epoch: 535, iter: 9090/16000, loss: 0.1574, lr: 0.004698, batch_cost: 0.1904, reader_cost: 0.00028, ips: 42.0179 samples/sec | ETA 00:21:55
2023-03-06 20:21:07 [INFO]	[TRAIN] epoch: 536, iter: 9100/16000, loss: 0.1743, lr: 0.004692, batch_cost: 0.2349, reader_cost: 0.04769, ips: 34.0536 samples/sec | ETA 00:27:00
2023-03-06 20:21:09 [INFO]	[TRAIN] epoch: 536, iter: 9110/16000, loss: 0.2856, lr: 0.004685, batch_cost: 0.1868, reader_cost: 0.00027, ips: 42.8328 samples/sec | ETA 00:21:26
2023-03-06 20:21:12 [INFO]	[TRAIN] epoch: 537, iter: 9120/16000, loss: 0.2737, lr: 0.004679, batch_cost: 0.2965, reader_cost: 0.06650, ips: 26.9810 samples/sec | ETA 00:33:59
2023-03-06 20:21:15 [INFO]	[TRAIN] epoch: 538, iter: 9130/16000, loss: 0.1903, lr: 0.004673, batch_cost: 0.2550, reader_cost: 0.04603, ips: 31.3681 samples/sec | ETA 00:29:12
2023-03-06 20:21:17 [INFO]	[TRAIN] epoch: 538, iter: 9140/16000, loss: 0.2559, lr: 0.004667, batch_cost: 0.1898, reader_cost: 0.00030, ips: 42.1401 samples/sec | ETA 00:21:42
2023-03-06 20:21:19 [INFO]	[TRAIN] epoch: 539, iter: 9150/16000, loss: 0.2067, lr: 0.004661, batch_cost: 0.2468, reader_cost: 0.04918, ips: 32.4133 samples/sec | ETA 00:28:10
2023-03-06 20:21:21 [INFO]	[TRAIN] epoch: 539, iter: 9160/16000, loss: 0.1681, lr: 0.004655, batch_cost: 0.1908, reader_cost: 0.00030, ips: 41.9354 samples/sec | ETA 00:21:44
2023-03-06 20:21:24 [INFO]	[TRAIN] epoch: 540, iter: 9170/16000, loss: 0.1894, lr: 0.004649, batch_cost: 0.2733, reader_cost: 0.04611, ips: 29.2686 samples/sec | ETA 00:31:06
2023-03-06 20:21:26 [INFO]	[TRAIN] epoch: 540, iter: 9180/16000, loss: 0.2530, lr: 0.004643, batch_cost: 0.1881, reader_cost: 0.00027, ips: 42.5238 samples/sec | ETA 00:21:23
2023-03-06 20:21:28 [INFO]	[TRAIN] epoch: 541, iter: 9190/16000, loss: 0.2351, lr: 0.004636, batch_cost: 0.2440, reader_cost: 0.04858, ips: 32.7878 samples/sec | ETA 00:27:41
2023-03-06 20:21:31 [INFO]	[TRAIN] epoch: 542, iter: 9200/16000, loss: 0.1579, lr: 0.004630, batch_cost: 0.2354, reader_cost: 0.04396, ips: 33.9869 samples/sec | ETA 00:26:40
2023-03-06 20:21:32 [INFO]	[TRAIN] epoch: 542, iter: 9210/16000, loss: 0.2769, lr: 0.004624, batch_cost: 0.1856, reader_cost: 0.00028, ips: 43.1053 samples/sec | ETA 00:21:00
2023-03-06 20:21:35 [INFO]	[TRAIN] epoch: 543, iter: 9220/16000, loss: 0.2129, lr: 0.004618, batch_cost: 0.2428, reader_cost: 0.05324, ips: 32.9541 samples/sec | ETA 00:27:25
2023-03-06 20:21:37 [INFO]	[TRAIN] epoch: 543, iter: 9230/16000, loss: 0.3020, lr: 0.004612, batch_cost: 0.1808, reader_cost: 0.00024, ips: 44.2535 samples/sec | ETA 00:20:23
2023-03-06 20:21:39 [INFO]	[TRAIN] epoch: 544, iter: 9240/16000, loss: 0.2428, lr: 0.004606, batch_cost: 0.2521, reader_cost: 0.03473, ips: 31.7354 samples/sec | ETA 00:28:24
2023-03-06 20:21:42 [INFO]	[TRAIN] epoch: 545, iter: 9250/16000, loss: 0.4687, lr: 0.004600, batch_cost: 0.2593, reader_cost: 0.04151, ips: 30.8532 samples/sec | ETA 00:29:10
2023-03-06 20:21:44 [INFO]	[TRAIN] epoch: 545, iter: 9260/16000, loss: 0.1914, lr: 0.004594, batch_cost: 0.1855, reader_cost: 0.00027, ips: 43.1222 samples/sec | ETA 00:20:50
2023-03-06 20:21:46 [INFO]	[TRAIN] epoch: 546, iter: 9270/16000, loss: 0.2508, lr: 0.004587, batch_cost: 0.2552, reader_cost: 0.03607, ips: 31.3446 samples/sec | ETA 00:28:37
2023-03-06 20:21:48 [INFO]	[TRAIN] epoch: 546, iter: 9280/16000, loss: 0.1697, lr: 0.004581, batch_cost: 0.1883, reader_cost: 0.00026, ips: 42.4782 samples/sec | ETA 00:21:05
2023-03-06 20:21:50 [INFO]	[TRAIN] epoch: 547, iter: 9290/16000, loss: 0.3108, lr: 0.004575, batch_cost: 0.2409, reader_cost: 0.04402, ips: 33.2035 samples/sec | ETA 00:26:56
2023-03-06 20:21:53 [INFO]	[TRAIN] epoch: 548, iter: 9300/16000, loss: 0.1801, lr: 0.004569, batch_cost: 0.2413, reader_cost: 0.04904, ips: 33.1481 samples/sec | ETA 00:26:56
2023-03-06 20:21:55 [INFO]	[TRAIN] epoch: 548, iter: 9310/16000, loss: 0.1786, lr: 0.004563, batch_cost: 0.1862, reader_cost: 0.00034, ips: 42.9739 samples/sec | ETA 00:20:45
2023-03-06 20:21:57 [INFO]	[TRAIN] epoch: 549, iter: 9320/16000, loss: 0.2277, lr: 0.004557, batch_cost: 0.2590, reader_cost: 0.05271, ips: 30.8920 samples/sec | ETA 00:28:49
2023-03-06 20:21:59 [INFO]	[TRAIN] epoch: 549, iter: 9330/16000, loss: 0.2390, lr: 0.004551, batch_cost: 0.1882, reader_cost: 0.00025, ips: 42.4970 samples/sec | ETA 00:20:55
2023-03-06 20:22:02 [INFO]	[TRAIN] epoch: 550, iter: 9340/16000, loss: 0.2073, lr: 0.004544, batch_cost: 0.2569, reader_cost: 0.05911, ips: 31.1367 samples/sec | ETA 00:28:31
2023-03-06 20:22:04 [INFO]	[TRAIN] epoch: 550, iter: 9350/16000, loss: 0.2173, lr: 0.004538, batch_cost: 0.2070, reader_cost: 0.00023, ips: 38.6496 samples/sec | ETA 00:22:56
2023-03-06 20:22:06 [INFO]	[TRAIN] epoch: 551, iter: 9360/16000, loss: 0.2435, lr: 0.004532, batch_cost: 0.2366, reader_cost: 0.04149, ips: 33.8094 samples/sec | ETA 00:26:11
2023-03-06 20:22:09 [INFO]	[TRAIN] epoch: 552, iter: 9370/16000, loss: 0.2549, lr: 0.004526, batch_cost: 0.2423, reader_cost: 0.04388, ips: 33.0228 samples/sec | ETA 00:26:46
2023-03-06 20:22:11 [INFO]	[TRAIN] epoch: 552, iter: 9380/16000, loss: 0.2043, lr: 0.004520, batch_cost: 0.1934, reader_cost: 0.00030, ips: 41.3752 samples/sec | ETA 00:21:19
2023-03-06 20:22:13 [INFO]	[TRAIN] epoch: 553, iter: 9390/16000, loss: 0.1833, lr: 0.004514, batch_cost: 0.2612, reader_cost: 0.05042, ips: 30.6236 samples/sec | ETA 00:28:46
2023-03-06 20:22:15 [INFO]	[TRAIN] epoch: 553, iter: 9400/16000, loss: 0.1922, lr: 0.004508, batch_cost: 0.1872, reader_cost: 0.00042, ips: 42.7464 samples/sec | ETA 00:20:35
2023-03-06 20:22:18 [INFO]	[TRAIN] epoch: 554, iter: 9410/16000, loss: 0.2173, lr: 0.004501, batch_cost: 0.2542, reader_cost: 0.05511, ips: 31.4672 samples/sec | ETA 00:27:55
2023-03-06 20:22:20 [INFO]	[TRAIN] epoch: 555, iter: 9420/16000, loss: 0.1775, lr: 0.004495, batch_cost: 0.2576, reader_cost: 0.04587, ips: 31.0514 samples/sec | ETA 00:28:15
2023-03-06 20:22:22 [INFO]	[TRAIN] epoch: 555, iter: 9430/16000, loss: 0.2615, lr: 0.004489, batch_cost: 0.1894, reader_cost: 0.00032, ips: 42.2294 samples/sec | ETA 00:20:44
2023-03-06 20:22:25 [INFO]	[TRAIN] epoch: 556, iter: 9440/16000, loss: 0.1268, lr: 0.004483, batch_cost: 0.2470, reader_cost: 0.04804, ips: 32.3887 samples/sec | ETA 00:27:00
2023-03-06 20:22:26 [INFO]	[TRAIN] epoch: 556, iter: 9450/16000, loss: 0.1996, lr: 0.004477, batch_cost: 0.1834, reader_cost: 0.00026, ips: 43.6275 samples/sec | ETA 00:20:01
2023-03-06 20:22:29 [INFO]	[TRAIN] epoch: 557, iter: 9460/16000, loss: 0.1629, lr: 0.004471, batch_cost: 0.2430, reader_cost: 0.04765, ips: 32.9267 samples/sec | ETA 00:26:28
2023-03-06 20:22:31 [INFO]	[TRAIN] epoch: 558, iter: 9470/16000, loss: 0.1873, lr: 0.004465, batch_cost: 0.2492, reader_cost: 0.05358, ips: 32.1045 samples/sec | ETA 00:27:07
2023-03-06 20:22:33 [INFO]	[TRAIN] epoch: 558, iter: 9480/16000, loss: 0.2847, lr: 0.004458, batch_cost: 0.1822, reader_cost: 0.00028, ips: 43.9163 samples/sec | ETA 00:19:47
2023-03-06 20:22:36 [INFO]	[TRAIN] epoch: 559, iter: 9490/16000, loss: 0.1919, lr: 0.004452, batch_cost: 0.2482, reader_cost: 0.03845, ips: 32.2260 samples/sec | ETA 00:26:56
2023-03-06 20:22:37 [INFO]	[TRAIN] epoch: 559, iter: 9500/16000, loss: 0.2215, lr: 0.004446, batch_cost: 0.1891, reader_cost: 0.00031, ips: 42.3077 samples/sec | ETA 00:20:29
2023-03-06 20:22:40 [INFO]	[TRAIN] epoch: 560, iter: 9510/16000, loss: 0.1929, lr: 0.004440, batch_cost: 0.2650, reader_cost: 0.04259, ips: 30.1911 samples/sec | ETA 00:28:39
2023-03-06 20:22:42 [INFO]	[TRAIN] epoch: 560, iter: 9520/16000, loss: 0.3292, lr: 0.004434, batch_cost: 0.2256, reader_cost: 0.00025, ips: 35.4559 samples/sec | ETA 00:24:22
2023-03-06 20:22:45 [INFO]	[TRAIN] epoch: 561, iter: 9530/16000, loss: 0.1893, lr: 0.004428, batch_cost: 0.2726, reader_cost: 0.04018, ips: 29.3463 samples/sec | ETA 00:29:23
2023-03-06 20:22:48 [INFO]	[TRAIN] epoch: 562, iter: 9540/16000, loss: 0.2363, lr: 0.004421, batch_cost: 0.2531, reader_cost: 0.05111, ips: 31.6049 samples/sec | ETA 00:27:15
2023-03-06 20:22:50 [INFO]	[TRAIN] epoch: 562, iter: 9550/16000, loss: 0.2898, lr: 0.004415, batch_cost: 0.1870, reader_cost: 0.00031, ips: 42.7693 samples/sec | ETA 00:20:06
2023-03-06 20:22:52 [INFO]	[TRAIN] epoch: 563, iter: 9560/16000, loss: 0.2384, lr: 0.004409, batch_cost: 0.2463, reader_cost: 0.03749, ips: 32.4811 samples/sec | ETA 00:26:26
2023-03-06 20:22:54 [INFO]	[TRAIN] epoch: 563, iter: 9570/16000, loss: 0.2018, lr: 0.004403, batch_cost: 0.2176, reader_cost: 0.00030, ips: 36.7676 samples/sec | ETA 00:23:19
2023-03-06 20:22:57 [INFO]	[TRAIN] epoch: 564, iter: 9580/16000, loss: 0.2646, lr: 0.004397, batch_cost: 0.2460, reader_cost: 0.04169, ips: 32.5194 samples/sec | ETA 00:26:19
2023-03-06 20:23:00 [INFO]	[TRAIN] epoch: 565, iter: 9590/16000, loss: 0.3287, lr: 0.004391, batch_cost: 0.2952, reader_cost: 0.09648, ips: 27.0980 samples/sec | ETA 00:31:32
2023-03-06 20:23:02 [INFO]	[TRAIN] epoch: 565, iter: 9600/16000, loss: 0.2378, lr: 0.004384, batch_cost: 0.1920, reader_cost: 0.00030, ips: 41.6638 samples/sec | ETA 00:20:28
2023-03-06 20:23:04 [INFO]	[TRAIN] epoch: 566, iter: 9610/16000, loss: 0.2237, lr: 0.004378, batch_cost: 0.2538, reader_cost: 0.04284, ips: 31.5262 samples/sec | ETA 00:27:01
2023-03-06 20:23:06 [INFO]	[TRAIN] epoch: 566, iter: 9620/16000, loss: 0.2737, lr: 0.004372, batch_cost: 0.1936, reader_cost: 0.00045, ips: 41.3249 samples/sec | ETA 00:20:35
2023-03-06 20:23:09 [INFO]	[TRAIN] epoch: 567, iter: 9630/16000, loss: 0.2034, lr: 0.004366, batch_cost: 0.2649, reader_cost: 0.06139, ips: 30.2002 samples/sec | ETA 00:28:07
2023-03-06 20:23:11 [INFO]	[TRAIN] epoch: 568, iter: 9640/16000, loss: 0.2035, lr: 0.004360, batch_cost: 0.2571, reader_cost: 0.06032, ips: 31.1186 samples/sec | ETA 00:27:15
2023-03-06 20:23:13 [INFO]	[TRAIN] epoch: 568, iter: 9650/16000, loss: 0.1862, lr: 0.004354, batch_cost: 0.1911, reader_cost: 0.00033, ips: 41.8632 samples/sec | ETA 00:20:13
2023-03-06 20:23:16 [INFO]	[TRAIN] epoch: 569, iter: 9660/16000, loss: 0.2366, lr: 0.004347, batch_cost: 0.2555, reader_cost: 0.05806, ips: 31.3102 samples/sec | ETA 00:26:59
2023-03-06 20:23:18 [INFO]	[TRAIN] epoch: 569, iter: 9670/16000, loss: 0.2583, lr: 0.004341, batch_cost: 0.1998, reader_cost: 0.00030, ips: 40.0492 samples/sec | ETA 00:21:04
2023-03-06 20:23:20 [INFO]	[TRAIN] epoch: 570, iter: 9680/16000, loss: 0.2039, lr: 0.004335, batch_cost: 0.2657, reader_cost: 0.05560, ips: 30.1125 samples/sec | ETA 00:27:59
2023-03-06 20:23:23 [INFO]	[TRAIN] epoch: 570, iter: 9690/16000, loss: 0.2382, lr: 0.004329, batch_cost: 0.2210, reader_cost: 0.00027, ips: 36.1990 samples/sec | ETA 00:23:14
2023-03-06 20:23:25 [INFO]	[TRAIN] epoch: 571, iter: 9700/16000, loss: 0.2538, lr: 0.004323, batch_cost: 0.2649, reader_cost: 0.05339, ips: 30.2013 samples/sec | ETA 00:27:48
2023-03-06 20:23:28 [INFO]	[TRAIN] epoch: 572, iter: 9710/16000, loss: 0.2414, lr: 0.004317, batch_cost: 0.2534, reader_cost: 0.04901, ips: 31.5740 samples/sec | ETA 00:26:33
2023-03-06 20:23:30 [INFO]	[TRAIN] epoch: 572, iter: 9720/16000, loss: 0.2146, lr: 0.004310, batch_cost: 0.1871, reader_cost: 0.00030, ips: 42.7572 samples/sec | ETA 00:19:35
2023-03-06 20:23:32 [INFO]	[TRAIN] epoch: 573, iter: 9730/16000, loss: 0.2246, lr: 0.004304, batch_cost: 0.2491, reader_cost: 0.04705, ips: 32.1136 samples/sec | ETA 00:26:01
2023-03-06 20:23:34 [INFO]	[TRAIN] epoch: 573, iter: 9740/16000, loss: 0.2545, lr: 0.004298, batch_cost: 0.1902, reader_cost: 0.00026, ips: 42.0713 samples/sec | ETA 00:19:50
2023-03-06 20:23:37 [INFO]	[TRAIN] epoch: 574, iter: 9750/16000, loss: 0.2088, lr: 0.004292, batch_cost: 0.2764, reader_cost: 0.05955, ips: 28.9482 samples/sec | ETA 00:28:47
2023-03-06 20:23:39 [INFO]	[TRAIN] epoch: 575, iter: 9760/16000, loss: 0.2288, lr: 0.004286, batch_cost: 0.2482, reader_cost: 0.04401, ips: 32.2366 samples/sec | ETA 00:25:48
2023-03-06 20:23:41 [INFO]	[TRAIN] epoch: 575, iter: 9770/16000, loss: 0.1913, lr: 0.004280, batch_cost: 0.1927, reader_cost: 0.00026, ips: 41.5129 samples/sec | ETA 00:20:00
2023-03-06 20:23:44 [INFO]	[TRAIN] epoch: 576, iter: 9780/16000, loss: 0.2504, lr: 0.004273, batch_cost: 0.2496, reader_cost: 0.03804, ips: 32.0449 samples/sec | ETA 00:25:52
2023-03-06 20:23:46 [INFO]	[TRAIN] epoch: 576, iter: 9790/16000, loss: 0.2621, lr: 0.004267, batch_cost: 0.1966, reader_cost: 0.00024, ips: 40.6854 samples/sec | ETA 00:20:21
2023-03-06 20:23:48 [INFO]	[TRAIN] epoch: 577, iter: 9800/16000, loss: 0.2308, lr: 0.004261, batch_cost: 0.2574, reader_cost: 0.05835, ips: 31.0808 samples/sec | ETA 00:26:35
2023-03-06 20:23:51 [INFO]	[TRAIN] epoch: 578, iter: 9810/16000, loss: 0.2652, lr: 0.004255, batch_cost: 0.2499, reader_cost: 0.03378, ips: 32.0166 samples/sec | ETA 00:25:46
2023-03-06 20:23:53 [INFO]	[TRAIN] epoch: 578, iter: 9820/16000, loss: 0.2263, lr: 0.004249, batch_cost: 0.2021, reader_cost: 0.00044, ips: 39.5866 samples/sec | ETA 00:20:48
2023-03-06 20:23:55 [INFO]	[TRAIN] epoch: 579, iter: 9830/16000, loss: 0.2059, lr: 0.004242, batch_cost: 0.2710, reader_cost: 0.06140, ips: 29.5238 samples/sec | ETA 00:27:51
2023-03-06 20:23:57 [INFO]	[TRAIN] epoch: 579, iter: 9840/16000, loss: 0.3341, lr: 0.004236, batch_cost: 0.1852, reader_cost: 0.00026, ips: 43.1995 samples/sec | ETA 00:19:00
2023-03-06 20:24:00 [INFO]	[TRAIN] epoch: 580, iter: 9850/16000, loss: 0.2506, lr: 0.004230, batch_cost: 0.2543, reader_cost: 0.05156, ips: 31.4607 samples/sec | ETA 00:26:03
2023-03-06 20:24:02 [INFO]	[TRAIN] epoch: 580, iter: 9860/16000, loss: 0.2194, lr: 0.004224, batch_cost: 0.1934, reader_cost: 0.00030, ips: 41.3745 samples/sec | ETA 00:19:47
2023-03-06 20:24:05 [INFO]	[TRAIN] epoch: 581, iter: 9870/16000, loss: 0.2057, lr: 0.004218, batch_cost: 0.2815, reader_cost: 0.04646, ips: 28.4143 samples/sec | ETA 00:28:45
2023-03-06 20:24:07 [INFO]	[TRAIN] epoch: 582, iter: 9880/16000, loss: 0.2303, lr: 0.004211, batch_cost: 0.2739, reader_cost: 0.04056, ips: 29.2099 samples/sec | ETA 00:27:56
2023-03-06 20:24:10 [INFO]	[TRAIN] epoch: 582, iter: 9890/16000, loss: 0.1984, lr: 0.004205, batch_cost: 0.2314, reader_cost: 0.00036, ips: 34.5777 samples/sec | ETA 00:23:33
2023-03-06 20:24:12 [INFO]	[TRAIN] epoch: 583, iter: 9900/16000, loss: 0.2374, lr: 0.004199, batch_cost: 0.2576, reader_cost: 0.03996, ips: 31.0550 samples/sec | ETA 00:26:11
2023-03-06 20:24:14 [INFO]	[TRAIN] epoch: 583, iter: 9910/16000, loss: 0.2214, lr: 0.004193, batch_cost: 0.1915, reader_cost: 0.00045, ips: 41.7767 samples/sec | ETA 00:19:26
2023-03-06 20:24:17 [INFO]	[TRAIN] epoch: 584, iter: 9920/16000, loss: 0.2492, lr: 0.004187, batch_cost: 0.2467, reader_cost: 0.04035, ips: 32.4341 samples/sec | ETA 00:24:59
2023-03-06 20:24:19 [INFO]	[TRAIN] epoch: 585, iter: 9930/16000, loss: 0.2388, lr: 0.004180, batch_cost: 0.2422, reader_cost: 0.03880, ips: 33.0371 samples/sec | ETA 00:24:29
2023-03-06 20:24:21 [INFO]	[TRAIN] epoch: 585, iter: 9940/16000, loss: 0.2071, lr: 0.004174, batch_cost: 0.2180, reader_cost: 0.00032, ips: 36.7042 samples/sec | ETA 00:22:00
2023-03-06 20:24:24 [INFO]	[TRAIN] epoch: 586, iter: 9950/16000, loss: 0.1881, lr: 0.004168, batch_cost: 0.2592, reader_cost: 0.03703, ips: 30.8618 samples/sec | ETA 00:26:08
2023-03-06 20:24:26 [INFO]	[TRAIN] epoch: 586, iter: 9960/16000, loss: 0.2371, lr: 0.004162, batch_cost: 0.2307, reader_cost: 0.00030, ips: 34.6764 samples/sec | ETA 00:23:13
2023-03-06 20:24:29 [INFO]	[TRAIN] epoch: 587, iter: 9970/16000, loss: 0.1870, lr: 0.004156, batch_cost: 0.2570, reader_cost: 0.03348, ips: 31.1245 samples/sec | ETA 00:25:49
2023-03-06 20:24:31 [INFO]	[TRAIN] epoch: 588, iter: 9980/16000, loss: 0.2757, lr: 0.004149, batch_cost: 0.2566, reader_cost: 0.04762, ips: 31.1729 samples/sec | ETA 00:25:44
2023-03-06 20:24:33 [INFO]	[TRAIN] epoch: 588, iter: 9990/16000, loss: 0.2675, lr: 0.004143, batch_cost: 0.1944, reader_cost: 0.00045, ips: 41.1614 samples/sec | ETA 00:19:28
2023-03-06 20:24:36 [INFO]	[TRAIN] epoch: 589, iter: 10000/16000, loss: 0.2427, lr: 0.004137, batch_cost: 0.2491, reader_cost: 0.04229, ips: 32.1116 samples/sec | ETA 00:24:54
2023-03-06 20:24:36 [INFO]	Start evaluating (total_samples: 119, total_iters: 60)...
60/60 - 3s - batch_cost: 0.0542 - reader cost: 0.0020
2023-03-06 20:24:39 [INFO]	[EVAL] #Images: 119 mIoU: 0.7846 Acc: 0.9353 Kappa: 0.7443 Dice: 0.8722
2023-03-06 20:24:39 [INFO]	[EVAL] Class IoU: 
[0.9268 0.6425]
2023-03-06 20:24:39 [INFO]	[EVAL] Class Precision: 
[0.9622 0.7814]
2023-03-06 20:24:39 [INFO]	[EVAL] Class Recall: 
[0.9618 0.7833]
2023-03-06 20:24:40 [INFO]	[EVAL] The model with the best validation mIoU (0.7846) was saved at iter 10000.
2023-03-06 20:24:42 [INFO]	[TRAIN] epoch: 589, iter: 10010/16000, loss: 0.1976, lr: 0.004131, batch_cost: 0.1910, reader_cost: 0.00028, ips: 41.8856 samples/sec | ETA 00:19:04
2023-03-06 20:24:45 [INFO]	[TRAIN] epoch: 590, iter: 10020/16000, loss: 0.2621, lr: 0.004125, batch_cost: 0.2483, reader_cost: 0.04122, ips: 32.2223 samples/sec | ETA 00:24:44
2023-03-06 20:24:47 [INFO]	[TRAIN] epoch: 590, iter: 10030/16000, loss: 0.2180, lr: 0.004118, batch_cost: 0.1886, reader_cost: 0.00031, ips: 42.4126 samples/sec | ETA 00:18:46
2023-03-06 20:24:49 [INFO]	[TRAIN] epoch: 591, iter: 10040/16000, loss: 0.2512, lr: 0.004112, batch_cost: 0.2605, reader_cost: 0.03785, ips: 30.7064 samples/sec | ETA 00:25:52
2023-03-06 20:24:52 [INFO]	[TRAIN] epoch: 592, iter: 10050/16000, loss: 0.2595, lr: 0.004106, batch_cost: 0.2508, reader_cost: 0.05453, ips: 31.8979 samples/sec | ETA 00:24:52
2023-03-06 20:24:54 [INFO]	[TRAIN] epoch: 592, iter: 10060/16000, loss: 0.1876, lr: 0.004100, batch_cost: 0.1890, reader_cost: 0.00031, ips: 42.3381 samples/sec | ETA 00:18:42
2023-03-06 20:24:56 [INFO]	[TRAIN] epoch: 593, iter: 10070/16000, loss: 0.2327, lr: 0.004094, batch_cost: 0.2448, reader_cost: 0.03940, ips: 32.6802 samples/sec | ETA 00:24:11
2023-03-06 20:24:58 [INFO]	[TRAIN] epoch: 593, iter: 10080/16000, loss: 0.1945, lr: 0.004087, batch_cost: 0.1881, reader_cost: 0.00028, ips: 42.5258 samples/sec | ETA 00:18:33
2023-03-06 20:25:00 [INFO]	[TRAIN] epoch: 594, iter: 10090/16000, loss: 0.2187, lr: 0.004081, batch_cost: 0.2517, reader_cost: 0.05085, ips: 31.7887 samples/sec | ETA 00:24:47
2023-03-06 20:25:03 [INFO]	[TRAIN] epoch: 595, iter: 10100/16000, loss: 0.2419, lr: 0.004075, batch_cost: 0.2417, reader_cost: 0.04051, ips: 33.0928 samples/sec | ETA 00:23:46
2023-03-06 20:25:05 [INFO]	[TRAIN] epoch: 595, iter: 10110/16000, loss: 0.1963, lr: 0.004069, batch_cost: 0.1936, reader_cost: 0.00029, ips: 41.3191 samples/sec | ETA 00:19:00
2023-03-06 20:25:07 [INFO]	[TRAIN] epoch: 596, iter: 10120/16000, loss: 0.2046, lr: 0.004063, batch_cost: 0.2483, reader_cost: 0.03954, ips: 32.2217 samples/sec | ETA 00:24:19
2023-03-06 20:25:09 [INFO]	[TRAIN] epoch: 596, iter: 10130/16000, loss: 0.1882, lr: 0.004056, batch_cost: 0.1969, reader_cost: 0.00043, ips: 40.6216 samples/sec | ETA 00:19:16
2023-03-06 20:25:12 [INFO]	[TRAIN] epoch: 597, iter: 10140/16000, loss: 0.1797, lr: 0.004050, batch_cost: 0.2805, reader_cost: 0.08194, ips: 28.5229 samples/sec | ETA 00:27:23
2023-03-06 20:25:15 [INFO]	[TRAIN] epoch: 598, iter: 10150/16000, loss: 0.2466, lr: 0.004044, batch_cost: 0.2492, reader_cost: 0.04528, ips: 32.1008 samples/sec | ETA 00:24:17
2023-03-06 20:25:16 [INFO]	[TRAIN] epoch: 598, iter: 10160/16000, loss: 0.2241, lr: 0.004038, batch_cost: 0.1936, reader_cost: 0.00031, ips: 41.3260 samples/sec | ETA 00:18:50
2023-03-06 20:25:19 [INFO]	[TRAIN] epoch: 599, iter: 10170/16000, loss: 0.2045, lr: 0.004031, batch_cost: 0.2643, reader_cost: 0.04177, ips: 30.2710 samples/sec | ETA 00:25:40
2023-03-06 20:25:21 [INFO]	[TRAIN] epoch: 599, iter: 10180/16000, loss: 0.2800, lr: 0.004025, batch_cost: 0.1915, reader_cost: 0.00030, ips: 41.7747 samples/sec | ETA 00:18:34
2023-03-06 20:25:24 [INFO]	[TRAIN] epoch: 600, iter: 10190/16000, loss: 0.1523, lr: 0.004019, batch_cost: 0.2618, reader_cost: 0.04974, ips: 30.5563 samples/sec | ETA 00:25:21
2023-03-06 20:25:26 [INFO]	[TRAIN] epoch: 600, iter: 10200/16000, loss: 0.3189, lr: 0.004013, batch_cost: 0.1905, reader_cost: 0.00027, ips: 41.9860 samples/sec | ETA 00:18:25
2023-03-06 20:25:28 [INFO]	[TRAIN] epoch: 601, iter: 10210/16000, loss: 0.2167, lr: 0.004007, batch_cost: 0.2563, reader_cost: 0.04313, ips: 31.2078 samples/sec | ETA 00:24:44
2023-03-06 20:25:31 [INFO]	[TRAIN] epoch: 602, iter: 10220/16000, loss: 0.1807, lr: 0.004000, batch_cost: 0.2470, reader_cost: 0.03934, ips: 32.3951 samples/sec | ETA 00:23:47
2023-03-06 20:25:32 [INFO]	[TRAIN] epoch: 602, iter: 10230/16000, loss: 0.2291, lr: 0.003994, batch_cost: 0.1862, reader_cost: 0.00028, ips: 42.9627 samples/sec | ETA 00:17:54
2023-03-06 20:25:35 [INFO]	[TRAIN] epoch: 603, iter: 10240/16000, loss: 0.3451, lr: 0.003988, batch_cost: 0.2709, reader_cost: 0.06905, ips: 29.5295 samples/sec | ETA 00:26:00
2023-03-06 20:25:37 [INFO]	[TRAIN] epoch: 603, iter: 10250/16000, loss: 0.2116, lr: 0.003982, batch_cost: 0.1903, reader_cost: 0.00025, ips: 42.0417 samples/sec | ETA 00:18:14
2023-03-06 20:25:40 [INFO]	[TRAIN] epoch: 604, iter: 10260/16000, loss: 0.1551, lr: 0.003975, batch_cost: 0.2631, reader_cost: 0.04949, ips: 30.4120 samples/sec | ETA 00:25:09
2023-03-06 20:25:42 [INFO]	[TRAIN] epoch: 605, iter: 10270/16000, loss: 0.1851, lr: 0.003969, batch_cost: 0.2546, reader_cost: 0.03953, ips: 31.4246 samples/sec | ETA 00:24:18
2023-03-06 20:25:44 [INFO]	[TRAIN] epoch: 605, iter: 10280/16000, loss: 0.2409, lr: 0.003963, batch_cost: 0.1968, reader_cost: 0.00033, ips: 40.6513 samples/sec | ETA 00:18:45
2023-03-06 20:25:47 [INFO]	[TRAIN] epoch: 606, iter: 10290/16000, loss: 0.2097, lr: 0.003957, batch_cost: 0.2498, reader_cost: 0.04528, ips: 32.0238 samples/sec | ETA 00:23:46
2023-03-06 20:25:49 [INFO]	[TRAIN] epoch: 606, iter: 10300/16000, loss: 0.2829, lr: 0.003950, batch_cost: 0.1858, reader_cost: 0.00028, ips: 43.0686 samples/sec | ETA 00:17:38
2023-03-06 20:25:51 [INFO]	[TRAIN] epoch: 607, iter: 10310/16000, loss: 0.2661, lr: 0.003944, batch_cost: 0.2470, reader_cost: 0.04635, ips: 32.3906 samples/sec | ETA 00:23:25
2023-03-06 20:25:53 [INFO]	[TRAIN] epoch: 608, iter: 10320/16000, loss: 0.3141, lr: 0.003938, batch_cost: 0.2398, reader_cost: 0.03833, ips: 33.3653 samples/sec | ETA 00:22:41
2023-03-06 20:25:55 [INFO]	[TRAIN] epoch: 608, iter: 10330/16000, loss: 0.2628, lr: 0.003932, batch_cost: 0.1923, reader_cost: 0.00027, ips: 41.5913 samples/sec | ETA 00:18:10
2023-03-06 20:25:58 [INFO]	[TRAIN] epoch: 609, iter: 10340/16000, loss: 0.1962, lr: 0.003926, batch_cost: 0.2628, reader_cost: 0.03774, ips: 30.4360 samples/sec | ETA 00:24:47
2023-03-06 20:26:00 [INFO]	[TRAIN] epoch: 609, iter: 10350/16000, loss: 0.1995, lr: 0.003919, batch_cost: 0.2209, reader_cost: 0.00032, ips: 36.2178 samples/sec | ETA 00:20:48
2023-03-06 20:26:03 [INFO]	[TRAIN] epoch: 610, iter: 10360/16000, loss: 0.4017, lr: 0.003913, batch_cost: 0.2565, reader_cost: 0.03872, ips: 31.1835 samples/sec | ETA 00:24:06
2023-03-06 20:26:05 [INFO]	[TRAIN] epoch: 610, iter: 10370/16000, loss: 0.2988, lr: 0.003907, batch_cost: 0.1885, reader_cost: 0.00028, ips: 42.4342 samples/sec | ETA 00:17:41
2023-03-06 20:26:07 [INFO]	[TRAIN] epoch: 611, iter: 10380/16000, loss: 0.2162, lr: 0.003901, batch_cost: 0.2723, reader_cost: 0.04519, ips: 29.3765 samples/sec | ETA 00:25:30
2023-03-06 20:26:10 [INFO]	[TRAIN] epoch: 612, iter: 10390/16000, loss: 0.2517, lr: 0.003894, batch_cost: 0.2554, reader_cost: 0.04435, ips: 31.3265 samples/sec | ETA 00:23:52
2023-03-06 20:26:12 [INFO]	[TRAIN] epoch: 612, iter: 10400/16000, loss: 0.1948, lr: 0.003888, batch_cost: 0.1889, reader_cost: 0.00030, ips: 42.3515 samples/sec | ETA 00:17:37
2023-03-06 20:26:14 [INFO]	[TRAIN] epoch: 613, iter: 10410/16000, loss: 0.1916, lr: 0.003882, batch_cost: 0.2442, reader_cost: 0.03919, ips: 32.7600 samples/sec | ETA 00:22:45
2023-03-06 20:26:16 [INFO]	[TRAIN] epoch: 613, iter: 10420/16000, loss: 0.1877, lr: 0.003876, batch_cost: 0.1921, reader_cost: 0.00029, ips: 41.6399 samples/sec | ETA 00:17:52
2023-03-06 20:26:19 [INFO]	[TRAIN] epoch: 614, iter: 10430/16000, loss: 0.2691, lr: 0.003869, batch_cost: 0.2638, reader_cost: 0.06210, ips: 30.3267 samples/sec | ETA 00:24:29
2023-03-06 20:26:21 [INFO]	[TRAIN] epoch: 615, iter: 10440/16000, loss: 0.2197, lr: 0.003863, batch_cost: 0.2497, reader_cost: 0.04644, ips: 32.0434 samples/sec | ETA 00:23:08
2023-03-06 20:26:23 [INFO]	[TRAIN] epoch: 615, iter: 10450/16000, loss: 0.2479, lr: 0.003857, batch_cost: 0.2053, reader_cost: 0.00032, ips: 38.9650 samples/sec | ETA 00:18:59
2023-03-06 20:26:27 [INFO]	[TRAIN] epoch: 616, iter: 10460/16000, loss: 0.2135, lr: 0.003851, batch_cost: 0.3267, reader_cost: 0.05828, ips: 24.4901 samples/sec | ETA 00:30:09
2023-03-06 20:26:30 [INFO]	[TRAIN] epoch: 616, iter: 10470/16000, loss: 0.1882, lr: 0.003844, batch_cost: 0.3185, reader_cost: 0.00038, ips: 25.1178 samples/sec | ETA 00:29:21
2023-03-06 20:26:33 [INFO]	[TRAIN] epoch: 617, iter: 10480/16000, loss: 0.2210, lr: 0.003838, batch_cost: 0.2902, reader_cost: 0.06643, ips: 27.5717 samples/sec | ETA 00:26:41
2023-03-06 20:26:35 [INFO]	[TRAIN] epoch: 618, iter: 10490/16000, loss: 0.2963, lr: 0.003832, batch_cost: 0.2458, reader_cost: 0.05401, ips: 32.5506 samples/sec | ETA 00:22:34
2023-03-06 20:26:37 [INFO]	[TRAIN] epoch: 618, iter: 10500/16000, loss: 0.2483, lr: 0.003826, batch_cost: 0.1936, reader_cost: 0.00027, ips: 41.3194 samples/sec | ETA 00:17:44
2023-03-06 20:26:40 [INFO]	[TRAIN] epoch: 619, iter: 10510/16000, loss: 0.2617, lr: 0.003819, batch_cost: 0.2532, reader_cost: 0.05523, ips: 31.5990 samples/sec | ETA 00:23:09
2023-03-06 20:26:42 [INFO]	[TRAIN] epoch: 619, iter: 10520/16000, loss: 0.2357, lr: 0.003813, batch_cost: 0.1901, reader_cost: 0.00030, ips: 42.0871 samples/sec | ETA 00:17:21
2023-03-06 20:26:44 [INFO]	[TRAIN] epoch: 620, iter: 10530/16000, loss: 0.2154, lr: 0.003807, batch_cost: 0.2472, reader_cost: 0.03669, ips: 32.3666 samples/sec | ETA 00:22:32
2023-03-06 20:26:46 [INFO]	[TRAIN] epoch: 620, iter: 10540/16000, loss: 0.2071, lr: 0.003800, batch_cost: 0.1894, reader_cost: 0.00030, ips: 42.2342 samples/sec | ETA 00:17:14
2023-03-06 20:26:49 [INFO]	[TRAIN] epoch: 621, iter: 10550/16000, loss: 0.1660, lr: 0.003794, batch_cost: 0.2865, reader_cost: 0.04660, ips: 27.9206 samples/sec | ETA 00:26:01
2023-03-06 20:26:51 [INFO]	[TRAIN] epoch: 622, iter: 10560/16000, loss: 0.1836, lr: 0.003788, batch_cost: 0.2504, reader_cost: 0.03913, ips: 31.9441 samples/sec | ETA 00:22:42
2023-03-06 20:26:53 [INFO]	[TRAIN] epoch: 622, iter: 10570/16000, loss: 0.2235, lr: 0.003782, batch_cost: 0.1948, reader_cost: 0.00031, ips: 41.0685 samples/sec | ETA 00:17:37
2023-03-06 20:26:56 [INFO]	[TRAIN] epoch: 623, iter: 10580/16000, loss: 0.2121, lr: 0.003775, batch_cost: 0.2620, reader_cost: 0.04166, ips: 30.5304 samples/sec | ETA 00:23:40
2023-03-06 20:26:58 [INFO]	[TRAIN] epoch: 623, iter: 10590/16000, loss: 0.2041, lr: 0.003769, batch_cost: 0.1908, reader_cost: 0.00036, ips: 41.9264 samples/sec | ETA 00:17:12
2023-03-06 20:27:00 [INFO]	[TRAIN] epoch: 624, iter: 10600/16000, loss: 0.2649, lr: 0.003763, batch_cost: 0.2478, reader_cost: 0.03913, ips: 32.2899 samples/sec | ETA 00:22:17
2023-03-06 20:27:03 [INFO]	[TRAIN] epoch: 625, iter: 10610/16000, loss: 0.1554, lr: 0.003757, batch_cost: 0.2671, reader_cost: 0.03725, ips: 29.9482 samples/sec | ETA 00:23:59
2023-03-06 20:27:05 [INFO]	[TRAIN] epoch: 625, iter: 10620/16000, loss: 0.2180, lr: 0.003750, batch_cost: 0.2048, reader_cost: 0.00032, ips: 39.0588 samples/sec | ETA 00:18:21
2023-03-06 20:27:08 [INFO]	[TRAIN] epoch: 626, iter: 10630/16000, loss: 0.1792, lr: 0.003744, batch_cost: 0.2811, reader_cost: 0.08457, ips: 28.4621 samples/sec | ETA 00:25:09
2023-03-06 20:27:10 [INFO]	[TRAIN] epoch: 626, iter: 10640/16000, loss: 0.2391, lr: 0.003738, batch_cost: 0.1969, reader_cost: 0.00030, ips: 40.6340 samples/sec | ETA 00:17:35
2023-03-06 20:27:12 [INFO]	[TRAIN] epoch: 627, iter: 10650/16000, loss: 0.2458, lr: 0.003732, batch_cost: 0.2597, reader_cost: 0.05207, ips: 30.8096 samples/sec | ETA 00:23:09
2023-03-06 20:27:15 [INFO]	[TRAIN] epoch: 628, iter: 10660/16000, loss: 0.1491, lr: 0.003725, batch_cost: 0.2544, reader_cost: 0.05118, ips: 31.4410 samples/sec | ETA 00:22:38
2023-03-06 20:27:17 [INFO]	[TRAIN] epoch: 628, iter: 10670/16000, loss: 0.1696, lr: 0.003719, batch_cost: 0.1911, reader_cost: 0.00027, ips: 41.8669 samples/sec | ETA 00:16:58
2023-03-06 20:27:19 [INFO]	[TRAIN] epoch: 629, iter: 10680/16000, loss: 0.2388, lr: 0.003713, batch_cost: 0.2478, reader_cost: 0.03971, ips: 32.2861 samples/sec | ETA 00:21:58
2023-03-06 20:27:22 [INFO]	[TRAIN] epoch: 629, iter: 10690/16000, loss: 0.2060, lr: 0.003706, batch_cost: 0.2281, reader_cost: 0.00026, ips: 35.0649 samples/sec | ETA 00:20:11
2023-03-06 20:27:25 [INFO]	[TRAIN] epoch: 630, iter: 10700/16000, loss: 0.2058, lr: 0.003700, batch_cost: 0.2916, reader_cost: 0.05005, ips: 27.4307 samples/sec | ETA 00:25:45
2023-03-06 20:27:27 [INFO]	[TRAIN] epoch: 630, iter: 10710/16000, loss: 0.2186, lr: 0.003694, batch_cost: 0.2331, reader_cost: 0.00021, ips: 34.3207 samples/sec | ETA 00:20:33
2023-03-06 20:27:30 [INFO]	[TRAIN] epoch: 631, iter: 10720/16000, loss: 0.1643, lr: 0.003688, batch_cost: 0.2836, reader_cost: 0.05701, ips: 28.2072 samples/sec | ETA 00:24:57
2023-03-06 20:27:32 [INFO]	[TRAIN] epoch: 632, iter: 10730/16000, loss: 0.1857, lr: 0.003681, batch_cost: 0.2764, reader_cost: 0.04080, ips: 28.9405 samples/sec | ETA 00:24:16
2023-03-06 20:27:34 [INFO]	[TRAIN] epoch: 632, iter: 10740/16000, loss: 0.1882, lr: 0.003675, batch_cost: 0.1930, reader_cost: 0.00030, ips: 41.4445 samples/sec | ETA 00:16:55
2023-03-06 20:27:37 [INFO]	[TRAIN] epoch: 633, iter: 10750/16000, loss: 0.2748, lr: 0.003669, batch_cost: 0.2532, reader_cost: 0.04806, ips: 31.5946 samples/sec | ETA 00:22:09
2023-03-06 20:27:39 [INFO]	[TRAIN] epoch: 633, iter: 10760/16000, loss: 0.2137, lr: 0.003662, batch_cost: 0.1982, reader_cost: 0.00030, ips: 40.3648 samples/sec | ETA 00:17:18
2023-03-06 20:27:43 [INFO]	[TRAIN] epoch: 634, iter: 10770/16000, loss: 0.2690, lr: 0.003656, batch_cost: 0.3905, reader_cost: 0.16580, ips: 20.4869 samples/sec | ETA 00:34:02
2023-03-06 20:27:45 [INFO]	[TRAIN] epoch: 635, iter: 10780/16000, loss: 0.2130, lr: 0.003650, batch_cost: 0.2573, reader_cost: 0.05496, ips: 31.0945 samples/sec | ETA 00:22:23
2023-03-06 20:27:48 [INFO]	[TRAIN] epoch: 635, iter: 10790/16000, loss: 0.1825, lr: 0.003644, batch_cost: 0.2322, reader_cost: 0.00035, ips: 34.4533 samples/sec | ETA 00:20:09
2023-03-06 20:27:50 [INFO]	[TRAIN] epoch: 636, iter: 10800/16000, loss: 0.2042, lr: 0.003637, batch_cost: 0.2754, reader_cost: 0.04784, ips: 29.0534 samples/sec | ETA 00:23:51
2023-03-06 20:27:52 [INFO]	[TRAIN] epoch: 636, iter: 10810/16000, loss: 0.1910, lr: 0.003631, batch_cost: 0.1999, reader_cost: 0.00028, ips: 40.0211 samples/sec | ETA 00:17:17
2023-03-06 20:27:55 [INFO]	[TRAIN] epoch: 637, iter: 10820/16000, loss: 0.2866, lr: 0.003625, batch_cost: 0.2446, reader_cost: 0.03647, ips: 32.7067 samples/sec | ETA 00:21:07
2023-03-06 20:27:57 [INFO]	[TRAIN] epoch: 638, iter: 10830/16000, loss: 0.1893, lr: 0.003618, batch_cost: 0.2372, reader_cost: 0.03811, ips: 33.7218 samples/sec | ETA 00:20:26
2023-03-06 20:27:59 [INFO]	[TRAIN] epoch: 638, iter: 10840/16000, loss: 0.2082, lr: 0.003612, batch_cost: 0.1840, reader_cost: 0.00032, ips: 43.4720 samples/sec | ETA 00:15:49
2023-03-06 20:28:02 [INFO]	[TRAIN] epoch: 639, iter: 10850/16000, loss: 0.2642, lr: 0.003606, batch_cost: 0.2455, reader_cost: 0.04999, ips: 32.5890 samples/sec | ETA 00:21:04
2023-03-06 20:28:03 [INFO]	[TRAIN] epoch: 639, iter: 10860/16000, loss: 0.1899, lr: 0.003599, batch_cost: 0.1862, reader_cost: 0.00029, ips: 42.9692 samples/sec | ETA 00:15:56
2023-03-06 20:28:06 [INFO]	[TRAIN] epoch: 640, iter: 10870/16000, loss: 0.3124, lr: 0.003593, batch_cost: 0.2609, reader_cost: 0.05052, ips: 30.6576 samples/sec | ETA 00:22:18
2023-03-06 20:28:08 [INFO]	[TRAIN] epoch: 640, iter: 10880/16000, loss: 0.2325, lr: 0.003587, batch_cost: 0.1842, reader_cost: 0.00021, ips: 43.4232 samples/sec | ETA 00:15:43
2023-03-06 20:28:11 [INFO]	[TRAIN] epoch: 641, iter: 10890/16000, loss: 0.2626, lr: 0.003581, batch_cost: 0.2633, reader_cost: 0.04758, ips: 30.3835 samples/sec | ETA 00:22:25
2023-03-06 20:28:13 [INFO]	[TRAIN] epoch: 642, iter: 10900/16000, loss: 0.2046, lr: 0.003574, batch_cost: 0.2623, reader_cost: 0.05775, ips: 30.4977 samples/sec | ETA 00:22:17
2023-03-06 20:28:15 [INFO]	[TRAIN] epoch: 642, iter: 10910/16000, loss: 0.2454, lr: 0.003568, batch_cost: 0.1956, reader_cost: 0.00030, ips: 40.9013 samples/sec | ETA 00:16:35
2023-03-06 20:28:18 [INFO]	[TRAIN] epoch: 643, iter: 10920/16000, loss: 0.2368, lr: 0.003562, batch_cost: 0.2445, reader_cost: 0.04051, ips: 32.7231 samples/sec | ETA 00:20:41
2023-03-06 20:28:19 [INFO]	[TRAIN] epoch: 643, iter: 10930/16000, loss: 0.2541, lr: 0.003555, batch_cost: 0.1885, reader_cost: 0.00029, ips: 42.4485 samples/sec | ETA 00:15:55
2023-03-06 20:28:22 [INFO]	[TRAIN] epoch: 644, iter: 10940/16000, loss: 0.1979, lr: 0.003549, batch_cost: 0.2430, reader_cost: 0.04333, ips: 32.9188 samples/sec | ETA 00:20:29
2023-03-06 20:28:25 [INFO]	[TRAIN] epoch: 645, iter: 10950/16000, loss: 0.2460, lr: 0.003543, batch_cost: 0.2645, reader_cost: 0.07050, ips: 30.2410 samples/sec | ETA 00:22:15
2023-03-06 20:28:27 [INFO]	[TRAIN] epoch: 645, iter: 10960/16000, loss: 0.2639, lr: 0.003536, batch_cost: 0.2007, reader_cost: 0.00026, ips: 39.8544 samples/sec | ETA 00:16:51
2023-03-06 20:28:29 [INFO]	[TRAIN] epoch: 646, iter: 10970/16000, loss: 0.1912, lr: 0.003530, batch_cost: 0.2534, reader_cost: 0.05853, ips: 31.5651 samples/sec | ETA 00:21:14
2023-03-06 20:28:31 [INFO]	[TRAIN] epoch: 646, iter: 10980/16000, loss: 0.3059, lr: 0.003524, batch_cost: 0.1929, reader_cost: 0.00028, ips: 41.4740 samples/sec | ETA 00:16:08
2023-03-06 20:28:34 [INFO]	[TRAIN] epoch: 647, iter: 10990/16000, loss: 0.1986, lr: 0.003517, batch_cost: 0.2692, reader_cost: 0.04280, ips: 29.7216 samples/sec | ETA 00:22:28
2023-03-06 20:28:36 [INFO]	[TRAIN] epoch: 648, iter: 11000/16000, loss: 0.2334, lr: 0.003511, batch_cost: 0.2572, reader_cost: 0.04802, ips: 31.1100 samples/sec | ETA 00:21:25
2023-03-06 20:28:36 [INFO]	Start evaluating (total_samples: 119, total_iters: 60)...
60/60 - 3s - batch_cost: 0.0573 - reader cost: 0.0024
2023-03-06 20:28:40 [INFO]	[EVAL] #Images: 119 mIoU: 0.7871 Acc: 0.9348 Kappa: 0.7481 Dice: 0.8740
2023-03-06 20:28:40 [INFO]	[EVAL] Class IoU: 
[0.926  0.6482]
2023-03-06 20:28:40 [INFO]	[EVAL] Class Precision: 
[0.9663 0.7658]
2023-03-06 20:28:40 [INFO]	[EVAL] Class Recall: 
[0.9569 0.8084]
2023-03-06 20:28:41 [INFO]	[EVAL] The model with the best validation mIoU (0.7871) was saved at iter 11000.
2023-03-06 20:28:43 [INFO]	[TRAIN] epoch: 648, iter: 11010/16000, loss: 0.2021, lr: 0.003505, batch_cost: 0.1919, reader_cost: 0.00028, ips: 41.6887 samples/sec | ETA 00:15:57
2023-03-06 20:28:45 [INFO]	[TRAIN] epoch: 649, iter: 11020/16000, loss: 0.2054, lr: 0.003498, batch_cost: 0.2469, reader_cost: 0.03682, ips: 32.3979 samples/sec | ETA 00:20:29
2023-03-06 20:28:48 [INFO]	[TRAIN] epoch: 649, iter: 11030/16000, loss: 0.1837, lr: 0.003492, batch_cost: 0.2286, reader_cost: 0.00031, ips: 34.9915 samples/sec | ETA 00:18:56
2023-03-06 20:28:51 [INFO]	[TRAIN] epoch: 650, iter: 11040/16000, loss: 0.2155, lr: 0.003486, batch_cost: 0.3502, reader_cost: 0.11139, ips: 22.8448 samples/sec | ETA 00:28:56
2023-03-06 20:28:53 [INFO]	[TRAIN] epoch: 650, iter: 11050/16000, loss: 0.2135, lr: 0.003479, batch_cost: 0.2261, reader_cost: 0.00031, ips: 35.3771 samples/sec | ETA 00:18:39
2023-03-06 20:28:56 [INFO]	[TRAIN] epoch: 651, iter: 11060/16000, loss: 0.2060, lr: 0.003473, batch_cost: 0.2514, reader_cost: 0.04119, ips: 31.8275 samples/sec | ETA 00:20:41
2023-03-06 20:28:58 [INFO]	[TRAIN] epoch: 652, iter: 11070/16000, loss: 0.1628, lr: 0.003467, batch_cost: 0.2445, reader_cost: 0.04715, ips: 32.7218 samples/sec | ETA 00:20:05
2023-03-06 20:29:00 [INFO]	[TRAIN] epoch: 652, iter: 11080/16000, loss: 0.2585, lr: 0.003461, batch_cost: 0.1852, reader_cost: 0.00029, ips: 43.1867 samples/sec | ETA 00:15:11
2023-03-06 20:29:03 [INFO]	[TRAIN] epoch: 653, iter: 11090/16000, loss: 0.2810, lr: 0.003454, batch_cost: 0.2558, reader_cost: 0.05629, ips: 31.2728 samples/sec | ETA 00:20:56
2023-03-06 20:29:05 [INFO]	[TRAIN] epoch: 653, iter: 11100/16000, loss: 0.1753, lr: 0.003448, batch_cost: 0.2400, reader_cost: 0.00029, ips: 33.3320 samples/sec | ETA 00:19:36
2023-03-06 20:29:08 [INFO]	[TRAIN] epoch: 654, iter: 11110/16000, loss: 0.4005, lr: 0.003442, batch_cost: 0.2800, reader_cost: 0.05438, ips: 28.5716 samples/sec | ETA 00:22:49
2023-03-06 20:29:11 [INFO]	[TRAIN] epoch: 655, iter: 11120/16000, loss: 0.2396, lr: 0.003435, batch_cost: 0.2535, reader_cost: 0.05212, ips: 31.5610 samples/sec | ETA 00:20:36
2023-03-06 20:29:13 [INFO]	[TRAIN] epoch: 655, iter: 11130/16000, loss: 0.2208, lr: 0.003429, batch_cost: 0.1932, reader_cost: 0.00028, ips: 41.4020 samples/sec | ETA 00:15:41
2023-03-06 20:29:15 [INFO]	[TRAIN] epoch: 656, iter: 11140/16000, loss: 0.3115, lr: 0.003423, batch_cost: 0.2445, reader_cost: 0.04635, ips: 32.7186 samples/sec | ETA 00:19:48
2023-03-06 20:29:17 [INFO]	[TRAIN] epoch: 656, iter: 11150/16000, loss: 0.1852, lr: 0.003416, batch_cost: 0.1904, reader_cost: 0.00029, ips: 42.0061 samples/sec | ETA 00:15:23
2023-03-06 20:29:19 [INFO]	[TRAIN] epoch: 657, iter: 11160/16000, loss: 0.2130, lr: 0.003410, batch_cost: 0.2517, reader_cost: 0.04835, ips: 31.7779 samples/sec | ETA 00:20:18
2023-03-06 20:29:22 [INFO]	[TRAIN] epoch: 658, iter: 11170/16000, loss: 0.1929, lr: 0.003403, batch_cost: 0.2643, reader_cost: 0.06286, ips: 30.2744 samples/sec | ETA 00:21:16
2023-03-06 20:29:24 [INFO]	[TRAIN] epoch: 658, iter: 11180/16000, loss: 0.1836, lr: 0.003397, batch_cost: 0.1809, reader_cost: 0.00028, ips: 44.2156 samples/sec | ETA 00:14:32
2023-03-06 20:29:26 [INFO]	[TRAIN] epoch: 659, iter: 11190/16000, loss: 0.2139, lr: 0.003391, batch_cost: 0.2348, reader_cost: 0.03970, ips: 34.0736 samples/sec | ETA 00:18:49
2023-03-06 20:29:28 [INFO]	[TRAIN] epoch: 659, iter: 11200/16000, loss: 0.2906, lr: 0.003384, batch_cost: 0.1865, reader_cost: 0.00027, ips: 42.8844 samples/sec | ETA 00:14:55
2023-03-06 20:29:31 [INFO]	[TRAIN] epoch: 660, iter: 11210/16000, loss: 0.1959, lr: 0.003378, batch_cost: 0.2610, reader_cost: 0.05541, ips: 30.6517 samples/sec | ETA 00:20:50
2023-03-06 20:29:33 [INFO]	[TRAIN] epoch: 660, iter: 11220/16000, loss: 0.2034, lr: 0.003372, batch_cost: 0.1861, reader_cost: 0.00024, ips: 42.9875 samples/sec | ETA 00:14:49
2023-03-06 20:29:35 [INFO]	[TRAIN] epoch: 661, iter: 11230/16000, loss: 0.2016, lr: 0.003365, batch_cost: 0.2545, reader_cost: 0.04207, ips: 31.4283 samples/sec | ETA 00:20:14
2023-03-06 20:29:38 [INFO]	[TRAIN] epoch: 662, iter: 11240/16000, loss: 0.1738, lr: 0.003359, batch_cost: 0.2698, reader_cost: 0.05961, ips: 29.6476 samples/sec | ETA 00:21:24
2023-03-06 20:29:40 [INFO]	[TRAIN] epoch: 662, iter: 11250/16000, loss: 0.1937, lr: 0.003353, batch_cost: 0.1947, reader_cost: 0.00026, ips: 41.0837 samples/sec | ETA 00:15:24
2023-03-06 20:29:42 [INFO]	[TRAIN] epoch: 663, iter: 11260/16000, loss: 0.2201, lr: 0.003346, batch_cost: 0.2651, reader_cost: 0.03300, ips: 30.1793 samples/sec | ETA 00:20:56
2023-03-06 20:29:45 [INFO]	[TRAIN] epoch: 663, iter: 11270/16000, loss: 0.1835, lr: 0.003340, batch_cost: 0.2373, reader_cost: 0.00027, ips: 33.7117 samples/sec | ETA 00:18:42
2023-03-06 20:29:47 [INFO]	[TRAIN] epoch: 664, iter: 11280/16000, loss: 0.2762, lr: 0.003334, batch_cost: 0.2608, reader_cost: 0.04841, ips: 30.6734 samples/sec | ETA 00:20:31
2023-03-06 20:29:50 [INFO]	[TRAIN] epoch: 665, iter: 11290/16000, loss: 0.1740, lr: 0.003327, batch_cost: 0.2524, reader_cost: 0.04276, ips: 31.6923 samples/sec | ETA 00:19:48
2023-03-06 20:29:52 [INFO]	[TRAIN] epoch: 665, iter: 11300/16000, loss: 0.1647, lr: 0.003321, batch_cost: 0.1913, reader_cost: 0.00025, ips: 41.8243 samples/sec | ETA 00:14:58
2023-03-06 20:29:54 [INFO]	[TRAIN] epoch: 666, iter: 11310/16000, loss: 0.2152, lr: 0.003315, batch_cost: 0.2490, reader_cost: 0.04706, ips: 32.1322 samples/sec | ETA 00:19:27
2023-03-06 20:29:56 [INFO]	[TRAIN] epoch: 666, iter: 11320/16000, loss: 0.2595, lr: 0.003308, batch_cost: 0.1834, reader_cost: 0.00027, ips: 43.6171 samples/sec | ETA 00:14:18
2023-03-06 20:29:59 [INFO]	[TRAIN] epoch: 667, iter: 11330/16000, loss: 0.2030, lr: 0.003302, batch_cost: 0.2441, reader_cost: 0.04056, ips: 32.7714 samples/sec | ETA 00:19:00
2023-03-06 20:30:01 [INFO]	[TRAIN] epoch: 668, iter: 11340/16000, loss: 0.1483, lr: 0.003296, batch_cost: 0.2581, reader_cost: 0.05518, ips: 31.0012 samples/sec | ETA 00:20:02
2023-03-06 20:30:03 [INFO]	[TRAIN] epoch: 668, iter: 11350/16000, loss: 0.3064, lr: 0.003289, batch_cost: 0.2022, reader_cost: 0.00032, ips: 39.5690 samples/sec | ETA 00:15:40
2023-03-06 20:30:06 [INFO]	[TRAIN] epoch: 669, iter: 11360/16000, loss: 0.1853, lr: 0.003283, batch_cost: 0.2615, reader_cost: 0.06278, ips: 30.5931 samples/sec | ETA 00:20:13
2023-03-06 20:30:08 [INFO]	[TRAIN] epoch: 669, iter: 11370/16000, loss: 0.2314, lr: 0.003276, batch_cost: 0.1928, reader_cost: 0.00025, ips: 41.4886 samples/sec | ETA 00:14:52
2023-03-06 20:30:10 [INFO]	[TRAIN] epoch: 670, iter: 11380/16000, loss: 0.2865, lr: 0.003270, batch_cost: 0.2644, reader_cost: 0.04445, ips: 30.2534 samples/sec | ETA 00:20:21
2023-03-06 20:30:12 [INFO]	[TRAIN] epoch: 670, iter: 11390/16000, loss: 0.1941, lr: 0.003264, batch_cost: 0.1934, reader_cost: 0.00027, ips: 41.3545 samples/sec | ETA 00:14:51
2023-03-06 20:30:15 [INFO]	[TRAIN] epoch: 671, iter: 11400/16000, loss: 0.1792, lr: 0.003257, batch_cost: 0.2588, reader_cost: 0.05764, ips: 30.9112 samples/sec | ETA 00:19:50
2023-03-06 20:30:17 [INFO]	[TRAIN] epoch: 672, iter: 11410/16000, loss: 0.2541, lr: 0.003251, batch_cost: 0.2457, reader_cost: 0.03163, ips: 32.5661 samples/sec | ETA 00:18:47
2023-03-06 20:30:19 [INFO]	[TRAIN] epoch: 672, iter: 11420/16000, loss: 0.2034, lr: 0.003245, batch_cost: 0.1904, reader_cost: 0.00033, ips: 42.0201 samples/sec | ETA 00:14:31
2023-03-06 20:30:22 [INFO]	[TRAIN] epoch: 673, iter: 11430/16000, loss: 0.2050, lr: 0.003238, batch_cost: 0.2383, reader_cost: 0.03613, ips: 33.5686 samples/sec | ETA 00:18:09
2023-03-06 20:30:23 [INFO]	[TRAIN] epoch: 673, iter: 11440/16000, loss: 0.2277, lr: 0.003232, batch_cost: 0.1793, reader_cost: 0.00027, ips: 44.6296 samples/sec | ETA 00:13:37
2023-03-06 20:30:26 [INFO]	[TRAIN] epoch: 674, iter: 11450/16000, loss: 0.2225, lr: 0.003225, batch_cost: 0.2472, reader_cost: 0.03615, ips: 32.3565 samples/sec | ETA 00:18:44
2023-03-06 20:30:28 [INFO]	[TRAIN] epoch: 675, iter: 11460/16000, loss: 0.3322, lr: 0.003219, batch_cost: 0.2422, reader_cost: 0.04079, ips: 33.0275 samples/sec | ETA 00:18:19
2023-03-06 20:30:30 [INFO]	[TRAIN] epoch: 675, iter: 11470/16000, loss: 0.2305, lr: 0.003213, batch_cost: 0.1941, reader_cost: 0.00030, ips: 41.2143 samples/sec | ETA 00:14:39
2023-03-06 20:30:33 [INFO]	[TRAIN] epoch: 676, iter: 11480/16000, loss: 0.2339, lr: 0.003206, batch_cost: 0.2553, reader_cost: 0.05067, ips: 31.3409 samples/sec | ETA 00:19:13
2023-03-06 20:30:35 [INFO]	[TRAIN] epoch: 676, iter: 11490/16000, loss: 0.1623, lr: 0.003200, batch_cost: 0.2086, reader_cost: 0.00026, ips: 38.3516 samples/sec | ETA 00:15:40
2023-03-06 20:30:38 [INFO]	[TRAIN] epoch: 677, iter: 11500/16000, loss: 0.2255, lr: 0.003194, batch_cost: 0.2740, reader_cost: 0.04733, ips: 29.1966 samples/sec | ETA 00:20:33
2023-03-06 20:30:41 [INFO]	[TRAIN] epoch: 678, iter: 11510/16000, loss: 0.2132, lr: 0.003187, batch_cost: 0.2880, reader_cost: 0.04383, ips: 27.7773 samples/sec | ETA 00:21:33
2023-03-06 20:30:42 [INFO]	[TRAIN] epoch: 678, iter: 11520/16000, loss: 0.2277, lr: 0.003181, batch_cost: 0.1894, reader_cost: 0.00029, ips: 42.2497 samples/sec | ETA 00:14:08
2023-03-06 20:30:45 [INFO]	[TRAIN] epoch: 679, iter: 11530/16000, loss: 0.2172, lr: 0.003174, batch_cost: 0.2464, reader_cost: 0.03422, ips: 32.4717 samples/sec | ETA 00:18:21
2023-03-06 20:30:47 [INFO]	[TRAIN] epoch: 679, iter: 11540/16000, loss: 0.1626, lr: 0.003168, batch_cost: 0.1931, reader_cost: 0.00024, ips: 41.4274 samples/sec | ETA 00:14:21
2023-03-06 20:30:50 [INFO]	[TRAIN] epoch: 680, iter: 11550/16000, loss: 0.1565, lr: 0.003162, batch_cost: 0.2742, reader_cost: 0.03310, ips: 29.1730 samples/sec | ETA 00:20:20
2023-03-06 20:30:52 [INFO]	[TRAIN] epoch: 680, iter: 11560/16000, loss: 0.1985, lr: 0.003155, batch_cost: 0.2295, reader_cost: 0.00028, ips: 34.8558 samples/sec | ETA 00:16:59
2023-03-06 20:30:55 [INFO]	[TRAIN] epoch: 681, iter: 11570/16000, loss: 0.1812, lr: 0.003149, batch_cost: 0.2854, reader_cost: 0.05341, ips: 28.0319 samples/sec | ETA 00:21:04
2023-03-06 20:30:58 [INFO]	[TRAIN] epoch: 682, iter: 11580/16000, loss: 0.2409, lr: 0.003142, batch_cost: 0.2771, reader_cost: 0.05025, ips: 28.8704 samples/sec | ETA 00:20:24
2023-03-06 20:31:00 [INFO]	[TRAIN] epoch: 682, iter: 11590/16000, loss: 0.2576, lr: 0.003136, batch_cost: 0.2207, reader_cost: 0.00029, ips: 36.2557 samples/sec | ETA 00:16:13
2023-03-06 20:31:02 [INFO]	[TRAIN] epoch: 683, iter: 11600/16000, loss: 0.2871, lr: 0.003130, batch_cost: 0.2560, reader_cost: 0.03939, ips: 31.2540 samples/sec | ETA 00:18:46
2023-03-06 20:31:04 [INFO]	[TRAIN] epoch: 683, iter: 11610/16000, loss: 0.1969, lr: 0.003123, batch_cost: 0.1925, reader_cost: 0.00028, ips: 41.5652 samples/sec | ETA 00:14:04
2023-03-06 20:31:07 [INFO]	[TRAIN] epoch: 684, iter: 11620/16000, loss: 0.1510, lr: 0.003117, batch_cost: 0.2466, reader_cost: 0.03438, ips: 32.4406 samples/sec | ETA 00:18:00
2023-03-06 20:31:09 [INFO]	[TRAIN] epoch: 685, iter: 11630/16000, loss: 0.1960, lr: 0.003110, batch_cost: 0.2502, reader_cost: 0.05013, ips: 31.9705 samples/sec | ETA 00:18:13
2023-03-06 20:31:11 [INFO]	[TRAIN] epoch: 685, iter: 11640/16000, loss: 0.1864, lr: 0.003104, batch_cost: 0.1935, reader_cost: 0.00031, ips: 41.3494 samples/sec | ETA 00:14:03
2023-03-06 20:31:14 [INFO]	[TRAIN] epoch: 686, iter: 11650/16000, loss: 0.2100, lr: 0.003098, batch_cost: 0.2444, reader_cost: 0.03233, ips: 32.7310 samples/sec | ETA 00:17:43
2023-03-06 20:31:15 [INFO]	[TRAIN] epoch: 686, iter: 11660/16000, loss: 0.2113, lr: 0.003091, batch_cost: 0.1918, reader_cost: 0.00035, ips: 41.7048 samples/sec | ETA 00:13:52
2023-03-06 20:31:18 [INFO]	[TRAIN] epoch: 687, iter: 11670/16000, loss: 0.2253, lr: 0.003085, batch_cost: 0.2981, reader_cost: 0.07828, ips: 26.8391 samples/sec | ETA 00:21:30
2023-03-06 20:31:21 [INFO]	[TRAIN] epoch: 688, iter: 11680/16000, loss: 0.1877, lr: 0.003078, batch_cost: 0.2747, reader_cost: 0.04968, ips: 29.1279 samples/sec | ETA 00:19:46
2023-03-06 20:31:23 [INFO]	[TRAIN] epoch: 688, iter: 11690/16000, loss: 0.2230, lr: 0.003072, batch_cost: 0.2098, reader_cost: 0.00032, ips: 38.1281 samples/sec | ETA 00:15:04
2023-03-06 20:31:26 [INFO]	[TRAIN] epoch: 689, iter: 11700/16000, loss: 0.2242, lr: 0.003066, batch_cost: 0.2399, reader_cost: 0.03923, ips: 33.3474 samples/sec | ETA 00:17:11
2023-03-06 20:31:28 [INFO]	[TRAIN] epoch: 689, iter: 11710/16000, loss: 0.2249, lr: 0.003059, batch_cost: 0.1902, reader_cost: 0.00028, ips: 42.0585 samples/sec | ETA 00:13:36
2023-03-06 20:31:30 [INFO]	[TRAIN] epoch: 690, iter: 11720/16000, loss: 0.1756, lr: 0.003053, batch_cost: 0.2629, reader_cost: 0.06665, ips: 30.4251 samples/sec | ETA 00:18:45
2023-03-06 20:31:32 [INFO]	[TRAIN] epoch: 690, iter: 11730/16000, loss: 0.2135, lr: 0.003046, batch_cost: 0.1879, reader_cost: 0.00025, ips: 42.5695 samples/sec | ETA 00:13:22
2023-03-06 20:31:35 [INFO]	[TRAIN] epoch: 691, iter: 11740/16000, loss: 0.2899, lr: 0.003040, batch_cost: 0.2859, reader_cost: 0.04875, ips: 27.9778 samples/sec | ETA 00:20:18
2023-03-06 20:31:38 [INFO]	[TRAIN] epoch: 692, iter: 11750/16000, loss: 0.1772, lr: 0.003033, batch_cost: 0.2681, reader_cost: 0.04787, ips: 29.8432 samples/sec | ETA 00:18:59
2023-03-06 20:31:40 [INFO]	[TRAIN] epoch: 692, iter: 11760/16000, loss: 0.2615, lr: 0.003027, batch_cost: 0.1889, reader_cost: 0.00027, ips: 42.3563 samples/sec | ETA 00:13:20
2023-03-06 20:31:42 [INFO]	[TRAIN] epoch: 693, iter: 11770/16000, loss: 0.1920, lr: 0.003021, batch_cost: 0.2568, reader_cost: 0.05330, ips: 31.1506 samples/sec | ETA 00:18:06
2023-03-06 20:31:44 [INFO]	[TRAIN] epoch: 693, iter: 11780/16000, loss: 0.2168, lr: 0.003014, batch_cost: 0.1896, reader_cost: 0.00028, ips: 42.1937 samples/sec | ETA 00:13:20
2023-03-06 20:31:47 [INFO]	[TRAIN] epoch: 694, iter: 11790/16000, loss: 0.1539, lr: 0.003008, batch_cost: 0.2536, reader_cost: 0.05286, ips: 31.5482 samples/sec | ETA 00:17:47
2023-03-06 20:31:49 [INFO]	[TRAIN] epoch: 695, iter: 11800/16000, loss: 0.2716, lr: 0.003001, batch_cost: 0.2429, reader_cost: 0.04109, ips: 32.9392 samples/sec | ETA 00:17:00
2023-03-06 20:31:52 [INFO]	[TRAIN] epoch: 695, iter: 11810/16000, loss: 0.1812, lr: 0.002995, batch_cost: 0.2887, reader_cost: 0.00037, ips: 27.7059 samples/sec | ETA 00:20:09
2023-03-06 20:31:54 [INFO]	[TRAIN] epoch: 696, iter: 11820/16000, loss: 0.1897, lr: 0.002988, batch_cost: 0.2633, reader_cost: 0.04299, ips: 30.3788 samples/sec | ETA 00:18:20
2023-03-06 20:31:56 [INFO]	[TRAIN] epoch: 696, iter: 11830/16000, loss: 0.2933, lr: 0.002982, batch_cost: 0.1896, reader_cost: 0.00029, ips: 42.1894 samples/sec | ETA 00:13:10
2023-03-06 20:31:59 [INFO]	[TRAIN] epoch: 697, iter: 11840/16000, loss: 0.2426, lr: 0.002976, batch_cost: 0.3104, reader_cost: 0.05276, ips: 25.7710 samples/sec | ETA 00:21:31
2023-03-06 20:32:02 [INFO]	[TRAIN] epoch: 698, iter: 11850/16000, loss: 0.2116, lr: 0.002969, batch_cost: 0.2685, reader_cost: 0.05975, ips: 29.7916 samples/sec | ETA 00:18:34
2023-03-06 20:32:04 [INFO]	[TRAIN] epoch: 698, iter: 11860/16000, loss: 0.2159, lr: 0.002963, batch_cost: 0.1909, reader_cost: 0.00027, ips: 41.9143 samples/sec | ETA 00:13:10
2023-03-06 20:32:07 [INFO]	[TRAIN] epoch: 699, iter: 11870/16000, loss: 0.2280, lr: 0.002956, batch_cost: 0.2623, reader_cost: 0.05250, ips: 30.5013 samples/sec | ETA 00:18:03
2023-03-06 20:32:09 [INFO]	[TRAIN] epoch: 699, iter: 11880/16000, loss: 0.2920, lr: 0.002950, batch_cost: 0.2018, reader_cost: 0.00026, ips: 39.6514 samples/sec | ETA 00:13:51
2023-03-06 20:32:11 [INFO]	[TRAIN] epoch: 700, iter: 11890/16000, loss: 0.3036, lr: 0.002943, batch_cost: 0.2550, reader_cost: 0.03985, ips: 31.3716 samples/sec | ETA 00:17:28
2023-03-06 20:32:14 [INFO]	[TRAIN] epoch: 700, iter: 11900/16000, loss: 0.1974, lr: 0.002937, batch_cost: 0.2277, reader_cost: 0.00024, ips: 35.1410 samples/sec | ETA 00:15:33
2023-03-06 20:32:16 [INFO]	[TRAIN] epoch: 701, iter: 11910/16000, loss: 0.1715, lr: 0.002930, batch_cost: 0.2616, reader_cost: 0.04244, ips: 30.5808 samples/sec | ETA 00:17:49
2023-03-06 20:32:19 [INFO]	[TRAIN] epoch: 702, iter: 11920/16000, loss: 0.1540, lr: 0.002924, batch_cost: 0.2480, reader_cost: 0.04340, ips: 32.2620 samples/sec | ETA 00:16:51
2023-03-06 20:32:21 [INFO]	[TRAIN] epoch: 702, iter: 11930/16000, loss: 0.2419, lr: 0.002918, batch_cost: 0.1869, reader_cost: 0.00029, ips: 42.8150 samples/sec | ETA 00:12:40
2023-03-06 20:32:23 [INFO]	[TRAIN] epoch: 703, iter: 11940/16000, loss: 0.1974, lr: 0.002911, batch_cost: 0.2553, reader_cost: 0.04274, ips: 31.3386 samples/sec | ETA 00:17:16
2023-03-06 20:32:25 [INFO]	[TRAIN] epoch: 703, iter: 11950/16000, loss: 0.2990, lr: 0.002905, batch_cost: 0.2264, reader_cost: 0.00024, ips: 35.3319 samples/sec | ETA 00:15:17
2023-03-06 20:32:28 [INFO]	[TRAIN] epoch: 704, iter: 11960/16000, loss: 0.2324, lr: 0.002898, batch_cost: 0.2508, reader_cost: 0.05009, ips: 31.8956 samples/sec | ETA 00:16:53
2023-03-06 20:32:30 [INFO]	[TRAIN] epoch: 705, iter: 11970/16000, loss: 0.1617, lr: 0.002892, batch_cost: 0.2447, reader_cost: 0.04527, ips: 32.6887 samples/sec | ETA 00:16:26
2023-03-06 20:32:32 [INFO]	[TRAIN] epoch: 705, iter: 11980/16000, loss: 0.2148, lr: 0.002885, batch_cost: 0.1888, reader_cost: 0.00029, ips: 42.3731 samples/sec | ETA 00:12:38
2023-03-06 20:32:35 [INFO]	[TRAIN] epoch: 706, iter: 11990/16000, loss: 0.2107, lr: 0.002879, batch_cost: 0.2616, reader_cost: 0.04685, ips: 30.5832 samples/sec | ETA 00:17:28
2023-03-06 20:32:37 [INFO]	[TRAIN] epoch: 706, iter: 12000/16000, loss: 0.1519, lr: 0.002872, batch_cost: 0.1936, reader_cost: 0.00029, ips: 41.3240 samples/sec | ETA 00:12:54
2023-03-06 20:32:37 [INFO]	Start evaluating (total_samples: 119, total_iters: 60)...
60/60 - 3s - batch_cost: 0.0551 - reader cost: 0.0020
2023-03-06 20:32:40 [INFO]	[EVAL] #Images: 119 mIoU: 0.7831 Acc: 0.9317 Kappa: 0.7432 Dice: 0.8715
2023-03-06 20:32:40 [INFO]	[EVAL] Class IoU: 
[0.9221 0.6441]
2023-03-06 20:32:40 [INFO]	[EVAL] Class Precision: 
[0.9701 0.7402]
2023-03-06 20:32:40 [INFO]	[EVAL] Class Recall: 
[0.9491 0.8323]
2023-03-06 20:32:41 [INFO]	[EVAL] The model with the best validation mIoU (0.7871) was saved at iter 11000.
2023-03-06 20:32:43 [INFO]	[TRAIN] epoch: 707, iter: 12010/16000, loss: 0.2338, lr: 0.002866, batch_cost: 0.2676, reader_cost: 0.05260, ips: 29.8991 samples/sec | ETA 00:17:47
2023-03-06 20:32:46 [INFO]	[TRAIN] epoch: 708, iter: 12020/16000, loss: 0.2840, lr: 0.002859, batch_cost: 0.2456, reader_cost: 0.03757, ips: 32.5732 samples/sec | ETA 00:16:17
2023-03-06 20:32:48 [INFO]	[TRAIN] epoch: 708, iter: 12030/16000, loss: 0.2202, lr: 0.002853, batch_cost: 0.2001, reader_cost: 0.00170, ips: 39.9861 samples/sec | ETA 00:13:14
2023-03-06 20:32:50 [INFO]	[TRAIN] epoch: 709, iter: 12040/16000, loss: 0.1941, lr: 0.002847, batch_cost: 0.2449, reader_cost: 0.04489, ips: 32.6694 samples/sec | ETA 00:16:09
2023-03-06 20:32:52 [INFO]	[TRAIN] epoch: 709, iter: 12050/16000, loss: 0.2468, lr: 0.002840, batch_cost: 0.1863, reader_cost: 0.00023, ips: 42.9457 samples/sec | ETA 00:12:15
2023-03-06 20:32:55 [INFO]	[TRAIN] epoch: 710, iter: 12060/16000, loss: 0.1799, lr: 0.002834, batch_cost: 0.2609, reader_cost: 0.04436, ips: 30.6661 samples/sec | ETA 00:17:07
2023-03-06 20:32:57 [INFO]	[TRAIN] epoch: 710, iter: 12070/16000, loss: 0.1781, lr: 0.002827, batch_cost: 0.1895, reader_cost: 0.00027, ips: 42.2104 samples/sec | ETA 00:12:24
2023-03-06 20:32:59 [INFO]	[TRAIN] epoch: 711, iter: 12080/16000, loss: 0.2352, lr: 0.002821, batch_cost: 0.2368, reader_cost: 0.04308, ips: 33.7893 samples/sec | ETA 00:15:28
2023-03-06 20:33:01 [INFO]	[TRAIN] epoch: 712, iter: 12090/16000, loss: 0.2128, lr: 0.002814, batch_cost: 0.2361, reader_cost: 0.04425, ips: 33.8870 samples/sec | ETA 00:15:23
2023-03-06 20:33:03 [INFO]	[TRAIN] epoch: 712, iter: 12100/16000, loss: 0.2258, lr: 0.002808, batch_cost: 0.1903, reader_cost: 0.00028, ips: 42.0413 samples/sec | ETA 00:12:22
2023-03-06 20:33:06 [INFO]	[TRAIN] epoch: 713, iter: 12110/16000, loss: 0.1501, lr: 0.002801, batch_cost: 0.2610, reader_cost: 0.05442, ips: 30.6546 samples/sec | ETA 00:16:55
2023-03-06 20:33:08 [INFO]	[TRAIN] epoch: 713, iter: 12120/16000, loss: 0.2224, lr: 0.002795, batch_cost: 0.1789, reader_cost: 0.00024, ips: 44.7184 samples/sec | ETA 00:11:34
2023-03-06 20:33:10 [INFO]	[TRAIN] epoch: 714, iter: 12130/16000, loss: 0.2654, lr: 0.002788, batch_cost: 0.2671, reader_cost: 0.05972, ips: 29.9509 samples/sec | ETA 00:17:13
2023-03-06 20:33:13 [INFO]	[TRAIN] epoch: 715, iter: 12140/16000, loss: 0.2589, lr: 0.002782, batch_cost: 0.2728, reader_cost: 0.05191, ips: 29.3212 samples/sec | ETA 00:17:33
2023-03-06 20:33:17 [INFO]	[TRAIN] epoch: 715, iter: 12150/16000, loss: 0.2683, lr: 0.002775, batch_cost: 0.3914, reader_cost: 0.00149, ips: 20.4398 samples/sec | ETA 00:25:06
2023-03-06 20:33:22 [INFO]	[TRAIN] epoch: 716, iter: 12160/16000, loss: 0.2186, lr: 0.002769, batch_cost: 0.4584, reader_cost: 0.05873, ips: 17.4526 samples/sec | ETA 00:29:20
2023-03-06 20:33:25 [INFO]	[TRAIN] epoch: 716, iter: 12170/16000, loss: 0.1764, lr: 0.002762, batch_cost: 0.3353, reader_cost: 0.00035, ips: 23.8585 samples/sec | ETA 00:21:24
2023-03-06 20:33:28 [INFO]	[TRAIN] epoch: 717, iter: 12180/16000, loss: 0.2178, lr: 0.002756, batch_cost: 0.2845, reader_cost: 0.05931, ips: 28.1209 samples/sec | ETA 00:18:06
2023-03-06 20:33:30 [INFO]	[TRAIN] epoch: 718, iter: 12190/16000, loss: 0.2206, lr: 0.002749, batch_cost: 0.2313, reader_cost: 0.04001, ips: 34.5847 samples/sec | ETA 00:14:41
2023-03-06 20:33:32 [INFO]	[TRAIN] epoch: 718, iter: 12200/16000, loss: 0.2073, lr: 0.002743, batch_cost: 0.2081, reader_cost: 0.00028, ips: 38.4445 samples/sec | ETA 00:13:10
2023-03-06 20:33:35 [INFO]	[TRAIN] epoch: 719, iter: 12210/16000, loss: 0.2161, lr: 0.002736, batch_cost: 0.2474, reader_cost: 0.03837, ips: 32.3363 samples/sec | ETA 00:15:37
2023-03-06 20:33:37 [INFO]	[TRAIN] epoch: 719, iter: 12220/16000, loss: 0.1833, lr: 0.002730, batch_cost: 0.1855, reader_cost: 0.00025, ips: 43.1212 samples/sec | ETA 00:11:41
2023-03-06 20:33:39 [INFO]	[TRAIN] epoch: 720, iter: 12230/16000, loss: 0.1381, lr: 0.002723, batch_cost: 0.2473, reader_cost: 0.04575, ips: 32.3445 samples/sec | ETA 00:15:32
2023-03-06 20:33:41 [INFO]	[TRAIN] epoch: 720, iter: 12240/16000, loss: 0.2352, lr: 0.002717, batch_cost: 0.1801, reader_cost: 0.00022, ips: 44.4274 samples/sec | ETA 00:11:17
2023-03-06 20:33:44 [INFO]	[TRAIN] epoch: 721, iter: 12250/16000, loss: 0.2156, lr: 0.002710, batch_cost: 0.2837, reader_cost: 0.04738, ips: 28.1958 samples/sec | ETA 00:17:43
2023-03-06 20:33:46 [INFO]	[TRAIN] epoch: 722, iter: 12260/16000, loss: 0.1583, lr: 0.002704, batch_cost: 0.2581, reader_cost: 0.05933, ips: 30.9940 samples/sec | ETA 00:16:05
2023-03-06 20:33:48 [INFO]	[TRAIN] epoch: 722, iter: 12270/16000, loss: 0.2770, lr: 0.002697, batch_cost: 0.2022, reader_cost: 0.00029, ips: 39.5609 samples/sec | ETA 00:12:34
2023-03-06 20:33:51 [INFO]	[TRAIN] epoch: 723, iter: 12280/16000, loss: 0.1787, lr: 0.002691, batch_cost: 0.2571, reader_cost: 0.03631, ips: 31.1104 samples/sec | ETA 00:15:56
2023-03-06 20:33:53 [INFO]	[TRAIN] epoch: 723, iter: 12290/16000, loss: 0.2156, lr: 0.002684, batch_cost: 0.2018, reader_cost: 0.00029, ips: 39.6481 samples/sec | ETA 00:12:28
2023-03-06 20:33:55 [INFO]	[TRAIN] epoch: 724, iter: 12300/16000, loss: 0.2723, lr: 0.002678, batch_cost: 0.2557, reader_cost: 0.04765, ips: 31.2848 samples/sec | ETA 00:15:46
2023-03-06 20:33:58 [INFO]	[TRAIN] epoch: 725, iter: 12310/16000, loss: 0.2027, lr: 0.002671, batch_cost: 0.2559, reader_cost: 0.05521, ips: 31.2673 samples/sec | ETA 00:15:44
2023-03-06 20:34:00 [INFO]	[TRAIN] epoch: 725, iter: 12320/16000, loss: 0.2535, lr: 0.002665, batch_cost: 0.1939, reader_cost: 0.00025, ips: 41.2599 samples/sec | ETA 00:11:53
2023-03-06 20:34:03 [INFO]	[TRAIN] epoch: 726, iter: 12330/16000, loss: 0.1789, lr: 0.002658, batch_cost: 0.2705, reader_cost: 0.05166, ips: 29.5793 samples/sec | ETA 00:16:32
2023-03-06 20:34:05 [INFO]	[TRAIN] epoch: 726, iter: 12340/16000, loss: 0.1478, lr: 0.002652, batch_cost: 0.1888, reader_cost: 0.00025, ips: 42.3726 samples/sec | ETA 00:11:31
2023-03-06 20:34:07 [INFO]	[TRAIN] epoch: 727, iter: 12350/16000, loss: 0.1541, lr: 0.002645, batch_cost: 0.2726, reader_cost: 0.04436, ips: 29.3513 samples/sec | ETA 00:16:34
2023-03-06 20:34:10 [INFO]	[TRAIN] epoch: 728, iter: 12360/16000, loss: 0.1531, lr: 0.002639, batch_cost: 0.2607, reader_cost: 0.03925, ips: 30.6923 samples/sec | ETA 00:15:48
2023-03-06 20:34:12 [INFO]	[TRAIN] epoch: 728, iter: 12370/16000, loss: 0.2085, lr: 0.002632, batch_cost: 0.2211, reader_cost: 0.00033, ips: 36.1876 samples/sec | ETA 00:13:22
2023-03-06 20:34:15 [INFO]	[TRAIN] epoch: 729, iter: 12380/16000, loss: 0.2228, lr: 0.002626, batch_cost: 0.2676, reader_cost: 0.03767, ips: 29.8931 samples/sec | ETA 00:16:08
2023-03-06 20:34:17 [INFO]	[TRAIN] epoch: 729, iter: 12390/16000, loss: 0.1977, lr: 0.002619, batch_cost: 0.2250, reader_cost: 0.00031, ips: 35.5589 samples/sec | ETA 00:13:32
2023-03-06 20:34:20 [INFO]	[TRAIN] epoch: 730, iter: 12400/16000, loss: 0.2294, lr: 0.002613, batch_cost: 0.2768, reader_cost: 0.03792, ips: 28.9036 samples/sec | ETA 00:16:36
2023-03-06 20:34:22 [INFO]	[TRAIN] epoch: 730, iter: 12410/16000, loss: 0.3513, lr: 0.002606, batch_cost: 0.2302, reader_cost: 0.00029, ips: 34.7544 samples/sec | ETA 00:13:46
2023-03-06 20:34:25 [INFO]	[TRAIN] epoch: 731, iter: 12420/16000, loss: 0.1531, lr: 0.002600, batch_cost: 0.2465, reader_cost: 0.03316, ips: 32.4481 samples/sec | ETA 00:14:42
2023-03-06 20:34:27 [INFO]	[TRAIN] epoch: 732, iter: 12430/16000, loss: 0.2819, lr: 0.002593, batch_cost: 0.2424, reader_cost: 0.04227, ips: 33.0057 samples/sec | ETA 00:14:25
2023-03-06 20:34:29 [INFO]	[TRAIN] epoch: 732, iter: 12440/16000, loss: 0.1914, lr: 0.002586, batch_cost: 0.1896, reader_cost: 0.00029, ips: 42.2034 samples/sec | ETA 00:11:14
2023-03-06 20:34:31 [INFO]	[TRAIN] epoch: 733, iter: 12450/16000, loss: 0.1548, lr: 0.002580, batch_cost: 0.2474, reader_cost: 0.05028, ips: 32.3361 samples/sec | ETA 00:14:38
2023-03-06 20:34:33 [INFO]	[TRAIN] epoch: 733, iter: 12460/16000, loss: 0.1697, lr: 0.002573, batch_cost: 0.1881, reader_cost: 0.00029, ips: 42.5259 samples/sec | ETA 00:11:05
2023-03-06 20:34:36 [INFO]	[TRAIN] epoch: 734, iter: 12470/16000, loss: 0.1790, lr: 0.002567, batch_cost: 0.2652, reader_cost: 0.04112, ips: 30.1629 samples/sec | ETA 00:15:36
2023-03-06 20:34:38 [INFO]	[TRAIN] epoch: 735, iter: 12480/16000, loss: 0.2311, lr: 0.002560, batch_cost: 0.2467, reader_cost: 0.04689, ips: 32.4245 samples/sec | ETA 00:14:28
2023-03-06 20:34:40 [INFO]	[TRAIN] epoch: 735, iter: 12490/16000, loss: 0.1946, lr: 0.002554, batch_cost: 0.1870, reader_cost: 0.00030, ips: 42.7805 samples/sec | ETA 00:10:56
2023-03-06 20:34:43 [INFO]	[TRAIN] epoch: 736, iter: 12500/16000, loss: 0.1609, lr: 0.002547, batch_cost: 0.2391, reader_cost: 0.03765, ips: 33.4569 samples/sec | ETA 00:13:56
2023-03-06 20:34:45 [INFO]	[TRAIN] epoch: 736, iter: 12510/16000, loss: 0.1877, lr: 0.002541, batch_cost: 0.1886, reader_cost: 0.00029, ips: 42.4221 samples/sec | ETA 00:10:58
2023-03-06 20:34:47 [INFO]	[TRAIN] epoch: 737, iter: 12520/16000, loss: 0.2125, lr: 0.002534, batch_cost: 0.2646, reader_cost: 0.05891, ips: 30.2385 samples/sec | ETA 00:15:20
2023-03-06 20:34:50 [INFO]	[TRAIN] epoch: 738, iter: 12530/16000, loss: 0.2510, lr: 0.002528, batch_cost: 0.2434, reader_cost: 0.04847, ips: 32.8642 samples/sec | ETA 00:14:04
2023-03-06 20:34:52 [INFO]	[TRAIN] epoch: 738, iter: 12540/16000, loss: 0.1817, lr: 0.002521, batch_cost: 0.2048, reader_cost: 0.01451, ips: 39.0621 samples/sec | ETA 00:11:48
2023-03-06 20:34:54 [INFO]	[TRAIN] epoch: 739, iter: 12550/16000, loss: 0.2083, lr: 0.002514, batch_cost: 0.2538, reader_cost: 0.04354, ips: 31.5246 samples/sec | ETA 00:14:35
2023-03-06 20:34:56 [INFO]	[TRAIN] epoch: 739, iter: 12560/16000, loss: 0.1800, lr: 0.002508, batch_cost: 0.2011, reader_cost: 0.00037, ips: 39.7909 samples/sec | ETA 00:11:31
2023-03-06 20:34:59 [INFO]	[TRAIN] epoch: 740, iter: 12570/16000, loss: 0.2260, lr: 0.002501, batch_cost: 0.2561, reader_cost: 0.04592, ips: 31.2381 samples/sec | ETA 00:14:38
2023-03-06 20:35:01 [INFO]	[TRAIN] epoch: 740, iter: 12580/16000, loss: 0.2446, lr: 0.002495, batch_cost: 0.1791, reader_cost: 0.00030, ips: 44.6736 samples/sec | ETA 00:10:12
2023-03-06 20:35:03 [INFO]	[TRAIN] epoch: 741, iter: 12590/16000, loss: 0.1836, lr: 0.002488, batch_cost: 0.2536, reader_cost: 0.04848, ips: 31.5415 samples/sec | ETA 00:14:24
2023-03-06 20:35:06 [INFO]	[TRAIN] epoch: 742, iter: 12600/16000, loss: 0.2192, lr: 0.002482, batch_cost: 0.2517, reader_cost: 0.03802, ips: 31.7837 samples/sec | ETA 00:14:15
2023-03-06 20:35:07 [INFO]	[TRAIN] epoch: 742, iter: 12610/16000, loss: 0.1912, lr: 0.002475, batch_cost: 0.1818, reader_cost: 0.00028, ips: 44.0020 samples/sec | ETA 00:10:16
2023-03-06 20:35:10 [INFO]	[TRAIN] epoch: 743, iter: 12620/16000, loss: 0.1425, lr: 0.002468, batch_cost: 0.2843, reader_cost: 0.09193, ips: 28.1362 samples/sec | ETA 00:16:01
2023-03-06 20:35:12 [INFO]	[TRAIN] epoch: 743, iter: 12630/16000, loss: 0.2431, lr: 0.002462, batch_cost: 0.1851, reader_cost: 0.00025, ips: 43.2240 samples/sec | ETA 00:10:23
2023-03-06 20:35:15 [INFO]	[TRAIN] epoch: 744, iter: 12640/16000, loss: 0.1999, lr: 0.002455, batch_cost: 0.2496, reader_cost: 0.04422, ips: 32.0508 samples/sec | ETA 00:13:58
2023-03-06 20:35:17 [INFO]	[TRAIN] epoch: 745, iter: 12650/16000, loss: 0.2355, lr: 0.002449, batch_cost: 0.2551, reader_cost: 0.05858, ips: 31.3645 samples/sec | ETA 00:14:14
2023-03-06 20:35:19 [INFO]	[TRAIN] epoch: 745, iter: 12660/16000, loss: 0.3391, lr: 0.002442, batch_cost: 0.1877, reader_cost: 0.00026, ips: 42.6317 samples/sec | ETA 00:10:26
2023-03-06 20:35:21 [INFO]	[TRAIN] epoch: 746, iter: 12670/16000, loss: 0.2413, lr: 0.002436, batch_cost: 0.2412, reader_cost: 0.03928, ips: 33.1714 samples/sec | ETA 00:13:23
2023-03-06 20:35:23 [INFO]	[TRAIN] epoch: 746, iter: 12680/16000, loss: 0.1657, lr: 0.002429, batch_cost: 0.1800, reader_cost: 0.00027, ips: 44.4393 samples/sec | ETA 00:09:57
2023-03-06 20:35:26 [INFO]	[TRAIN] epoch: 747, iter: 12690/16000, loss: 0.4281, lr: 0.002422, batch_cost: 0.2323, reader_cost: 0.03807, ips: 34.4402 samples/sec | ETA 00:12:48
2023-03-06 20:35:28 [INFO]	[TRAIN] epoch: 748, iter: 12700/16000, loss: 0.1867, lr: 0.002416, batch_cost: 0.2402, reader_cost: 0.04965, ips: 33.3079 samples/sec | ETA 00:13:12
2023-03-06 20:35:30 [INFO]	[TRAIN] epoch: 748, iter: 12710/16000, loss: 0.1869, lr: 0.002409, batch_cost: 0.1872, reader_cost: 0.00030, ips: 42.7337 samples/sec | ETA 00:10:15
2023-03-06 20:35:33 [INFO]	[TRAIN] epoch: 749, iter: 12720/16000, loss: 0.2311, lr: 0.002403, batch_cost: 0.2609, reader_cost: 0.06150, ips: 30.6605 samples/sec | ETA 00:14:15
2023-03-06 20:35:34 [INFO]	[TRAIN] epoch: 749, iter: 12730/16000, loss: 0.1916, lr: 0.002396, batch_cost: 0.1886, reader_cost: 0.00027, ips: 42.4111 samples/sec | ETA 00:10:16
2023-03-06 20:35:37 [INFO]	[TRAIN] epoch: 750, iter: 12740/16000, loss: 0.1971, lr: 0.002390, batch_cost: 0.2627, reader_cost: 0.03921, ips: 30.4550 samples/sec | ETA 00:14:16
2023-03-06 20:35:39 [INFO]	[TRAIN] epoch: 750, iter: 12750/16000, loss: 0.2066, lr: 0.002383, batch_cost: 0.1944, reader_cost: 0.00023, ips: 41.1462 samples/sec | ETA 00:10:31
2023-03-06 20:35:42 [INFO]	[TRAIN] epoch: 751, iter: 12760/16000, loss: 0.2096, lr: 0.002376, batch_cost: 0.2848, reader_cost: 0.04306, ips: 28.0913 samples/sec | ETA 00:15:22
2023-03-06 20:35:45 [INFO]	[TRAIN] epoch: 752, iter: 12770/16000, loss: 0.1809, lr: 0.002370, batch_cost: 0.2740, reader_cost: 0.04889, ips: 29.1961 samples/sec | ETA 00:14:45
2023-03-06 20:35:46 [INFO]	[TRAIN] epoch: 752, iter: 12780/16000, loss: 0.2790, lr: 0.002363, batch_cost: 0.1844, reader_cost: 0.00029, ips: 43.3742 samples/sec | ETA 00:09:53
2023-03-06 20:35:49 [INFO]	[TRAIN] epoch: 753, iter: 12790/16000, loss: 0.2044, lr: 0.002357, batch_cost: 0.2459, reader_cost: 0.05060, ips: 32.5400 samples/sec | ETA 00:13:09
2023-03-06 20:35:51 [INFO]	[TRAIN] epoch: 753, iter: 12800/16000, loss: 0.1856, lr: 0.002350, batch_cost: 0.1932, reader_cost: 0.00029, ips: 41.4095 samples/sec | ETA 00:10:18
2023-03-06 20:35:53 [INFO]	[TRAIN] epoch: 754, iter: 12810/16000, loss: 0.2233, lr: 0.002343, batch_cost: 0.2565, reader_cost: 0.04630, ips: 31.1898 samples/sec | ETA 00:13:38
2023-03-06 20:35:56 [INFO]	[TRAIN] epoch: 755, iter: 12820/16000, loss: 0.1779, lr: 0.002337, batch_cost: 0.2409, reader_cost: 0.03903, ips: 33.2153 samples/sec | ETA 00:12:45
2023-03-06 20:35:58 [INFO]	[TRAIN] epoch: 755, iter: 12830/16000, loss: 0.1423, lr: 0.002330, batch_cost: 0.1836, reader_cost: 0.00026, ips: 43.5645 samples/sec | ETA 00:09:42
2023-03-06 20:36:00 [INFO]	[TRAIN] epoch: 756, iter: 12840/16000, loss: 0.2404, lr: 0.002323, batch_cost: 0.2526, reader_cost: 0.04256, ips: 31.6711 samples/sec | ETA 00:13:18
2023-03-06 20:36:02 [INFO]	[TRAIN] epoch: 756, iter: 12850/16000, loss: 0.2493, lr: 0.002317, batch_cost: 0.1989, reader_cost: 0.00028, ips: 40.2299 samples/sec | ETA 00:10:26
2023-03-06 20:36:05 [INFO]	[TRAIN] epoch: 757, iter: 12860/16000, loss: 0.2000, lr: 0.002310, batch_cost: 0.2927, reader_cost: 0.05262, ips: 27.3321 samples/sec | ETA 00:15:19
2023-03-06 20:36:08 [INFO]	[TRAIN] epoch: 758, iter: 12870/16000, loss: 0.2817, lr: 0.002304, batch_cost: 0.2525, reader_cost: 0.04736, ips: 31.6809 samples/sec | ETA 00:13:10
2023-03-06 20:36:10 [INFO]	[TRAIN] epoch: 758, iter: 12880/16000, loss: 0.1968, lr: 0.002297, batch_cost: 0.2004, reader_cost: 0.00028, ips: 39.9214 samples/sec | ETA 00:10:25
2023-03-06 20:36:12 [INFO]	[TRAIN] epoch: 759, iter: 12890/16000, loss: 0.2033, lr: 0.002290, batch_cost: 0.2510, reader_cost: 0.05407, ips: 31.8763 samples/sec | ETA 00:13:00
2023-03-06 20:36:14 [INFO]	[TRAIN] epoch: 759, iter: 12900/16000, loss: 0.2544, lr: 0.002284, batch_cost: 0.1957, reader_cost: 0.00029, ips: 40.8686 samples/sec | ETA 00:10:06
2023-03-06 20:36:17 [INFO]	[TRAIN] epoch: 760, iter: 12910/16000, loss: 0.2194, lr: 0.002277, batch_cost: 0.2495, reader_cost: 0.05534, ips: 32.0696 samples/sec | ETA 00:12:50
2023-03-06 20:36:18 [INFO]	[TRAIN] epoch: 760, iter: 12920/16000, loss: 0.1753, lr: 0.002270, batch_cost: 0.1901, reader_cost: 0.00028, ips: 42.0898 samples/sec | ETA 00:09:45
2023-03-06 20:36:21 [INFO]	[TRAIN] epoch: 761, iter: 12930/16000, loss: 0.2119, lr: 0.002264, batch_cost: 0.2578, reader_cost: 0.03467, ips: 31.0363 samples/sec | ETA 00:13:11
2023-03-06 20:36:24 [INFO]	[TRAIN] epoch: 762, iter: 12940/16000, loss: 0.2025, lr: 0.002257, batch_cost: 0.2581, reader_cost: 0.05930, ips: 30.9906 samples/sec | ETA 00:13:09
2023-03-06 20:36:26 [INFO]	[TRAIN] epoch: 762, iter: 12950/16000, loss: 0.2500, lr: 0.002251, batch_cost: 0.1907, reader_cost: 0.00031, ips: 41.9520 samples/sec | ETA 00:09:41
2023-03-06 20:36:28 [INFO]	[TRAIN] epoch: 763, iter: 12960/16000, loss: 0.2105, lr: 0.002244, batch_cost: 0.2571, reader_cost: 0.04819, ips: 31.1144 samples/sec | ETA 00:13:01
2023-03-06 20:36:30 [INFO]	[TRAIN] epoch: 763, iter: 12970/16000, loss: 0.1864, lr: 0.002237, batch_cost: 0.1901, reader_cost: 0.00029, ips: 42.0857 samples/sec | ETA 00:09:35
2023-03-06 20:36:33 [INFO]	[TRAIN] epoch: 764, iter: 12980/16000, loss: 0.2308, lr: 0.002231, batch_cost: 0.2624, reader_cost: 0.06448, ips: 30.4874 samples/sec | ETA 00:13:12
2023-03-06 20:36:35 [INFO]	[TRAIN] epoch: 765, iter: 12990/16000, loss: 0.2665, lr: 0.002224, batch_cost: 0.2511, reader_cost: 0.05200, ips: 31.8646 samples/sec | ETA 00:12:35
2023-03-06 20:36:37 [INFO]	[TRAIN] epoch: 765, iter: 13000/16000, loss: 0.2497, lr: 0.002217, batch_cost: 0.2009, reader_cost: 0.00036, ips: 39.8299 samples/sec | ETA 00:10:02
2023-03-06 20:36:37 [INFO]	Start evaluating (total_samples: 119, total_iters: 60)...
60/60 - 3s - batch_cost: 0.0576 - reader cost: 0.0020
2023-03-06 20:36:41 [INFO]	[EVAL] #Images: 119 mIoU: 0.7773 Acc: 0.9289 Kappa: 0.7353 Dice: 0.8675
2023-03-06 20:36:41 [INFO]	[EVAL] Class IoU: 
[0.9188 0.6358]
2023-03-06 20:36:41 [INFO]	[EVAL] Class Precision: 
[0.9706 0.7266]
2023-03-06 20:36:41 [INFO]	[EVAL] Class Recall: 
[0.9451 0.8358]
2023-03-06 20:36:41 [INFO]	[EVAL] The model with the best validation mIoU (0.7871) was saved at iter 11000.
2023-03-06 20:36:44 [INFO]	[TRAIN] epoch: 766, iter: 13010/16000, loss: 0.2208, lr: 0.002211, batch_cost: 0.2714, reader_cost: 0.05092, ips: 29.4746 samples/sec | ETA 00:13:31
2023-03-06 20:36:46 [INFO]	[TRAIN] epoch: 766, iter: 13020/16000, loss: 0.1784, lr: 0.002204, batch_cost: 0.1899, reader_cost: 0.00027, ips: 42.1239 samples/sec | ETA 00:09:25
2023-03-06 20:36:49 [INFO]	[TRAIN] epoch: 767, iter: 13030/16000, loss: 0.1769, lr: 0.002197, batch_cost: 0.2656, reader_cost: 0.05926, ips: 30.1209 samples/sec | ETA 00:13:08
2023-03-06 20:36:51 [INFO]	[TRAIN] epoch: 768, iter: 13040/16000, loss: 0.1775, lr: 0.002191, batch_cost: 0.2571, reader_cost: 0.05458, ips: 31.1185 samples/sec | ETA 00:12:40
2023-03-06 20:36:53 [INFO]	[TRAIN] epoch: 768, iter: 13050/16000, loss: 0.2501, lr: 0.002184, batch_cost: 0.1963, reader_cost: 0.00028, ips: 40.7532 samples/sec | ETA 00:09:39
2023-03-06 20:36:56 [INFO]	[TRAIN] epoch: 769, iter: 13060/16000, loss: 0.2207, lr: 0.002177, batch_cost: 0.2569, reader_cost: 0.04342, ips: 31.1443 samples/sec | ETA 00:12:35
2023-03-06 20:36:58 [INFO]	[TRAIN] epoch: 769, iter: 13070/16000, loss: 0.1945, lr: 0.002171, batch_cost: 0.1918, reader_cost: 0.00029, ips: 41.7147 samples/sec | ETA 00:09:21
2023-03-06 20:37:00 [INFO]	[TRAIN] epoch: 770, iter: 13080/16000, loss: 0.1810, lr: 0.002164, batch_cost: 0.2560, reader_cost: 0.03816, ips: 31.2531 samples/sec | ETA 00:12:27
2023-03-06 20:37:02 [INFO]	[TRAIN] epoch: 770, iter: 13090/16000, loss: 0.1911, lr: 0.002157, batch_cost: 0.1888, reader_cost: 0.00025, ips: 42.3835 samples/sec | ETA 00:09:09
2023-03-06 20:37:05 [INFO]	[TRAIN] epoch: 771, iter: 13100/16000, loss: 0.1786, lr: 0.002151, batch_cost: 0.2680, reader_cost: 0.04382, ips: 29.8530 samples/sec | ETA 00:12:57
2023-03-06 20:37:08 [INFO]	[TRAIN] epoch: 772, iter: 13110/16000, loss: 0.1968, lr: 0.002144, batch_cost: 0.3047, reader_cost: 0.04383, ips: 26.2545 samples/sec | ETA 00:14:40
2023-03-06 20:37:10 [INFO]	[TRAIN] epoch: 772, iter: 13120/16000, loss: 0.1445, lr: 0.002137, batch_cost: 0.1984, reader_cost: 0.00031, ips: 40.3265 samples/sec | ETA 00:09:31
2023-03-06 20:37:12 [INFO]	[TRAIN] epoch: 773, iter: 13130/16000, loss: 0.1791, lr: 0.002131, batch_cost: 0.2526, reader_cost: 0.05240, ips: 31.6674 samples/sec | ETA 00:12:05
2023-03-06 20:37:14 [INFO]	[TRAIN] epoch: 773, iter: 13140/16000, loss: 0.2038, lr: 0.002124, batch_cost: 0.1851, reader_cost: 0.00025, ips: 43.2315 samples/sec | ETA 00:08:49
2023-03-06 20:37:17 [INFO]	[TRAIN] epoch: 774, iter: 13150/16000, loss: 0.1965, lr: 0.002117, batch_cost: 0.2450, reader_cost: 0.04472, ips: 32.6587 samples/sec | ETA 00:11:38
2023-03-06 20:37:19 [INFO]	[TRAIN] epoch: 775, iter: 13160/16000, loss: 0.2135, lr: 0.002111, batch_cost: 0.2447, reader_cost: 0.03744, ips: 32.6977 samples/sec | ETA 00:11:34
2023-03-06 20:37:21 [INFO]	[TRAIN] epoch: 775, iter: 13170/16000, loss: 0.1837, lr: 0.002104, batch_cost: 0.1992, reader_cost: 0.00027, ips: 40.1668 samples/sec | ETA 00:09:23
2023-03-06 20:37:24 [INFO]	[TRAIN] epoch: 776, iter: 13180/16000, loss: 0.2005, lr: 0.002097, batch_cost: 0.2705, reader_cost: 0.04833, ips: 29.5775 samples/sec | ETA 00:12:42
2023-03-06 20:37:26 [INFO]	[TRAIN] epoch: 776, iter: 13190/16000, loss: 0.2708, lr: 0.002091, batch_cost: 0.1985, reader_cost: 0.00310, ips: 40.3096 samples/sec | ETA 00:09:17
2023-03-06 20:37:28 [INFO]	[TRAIN] epoch: 777, iter: 13200/16000, loss: 0.1832, lr: 0.002084, batch_cost: 0.2573, reader_cost: 0.04677, ips: 31.0919 samples/sec | ETA 00:12:00
2023-03-06 20:37:31 [INFO]	[TRAIN] epoch: 778, iter: 13210/16000, loss: 0.2160, lr: 0.002077, batch_cost: 0.2502, reader_cost: 0.04714, ips: 31.9805 samples/sec | ETA 00:11:37
2023-03-06 20:37:33 [INFO]	[TRAIN] epoch: 778, iter: 13220/16000, loss: 0.1861, lr: 0.002070, batch_cost: 0.1988, reader_cost: 0.00034, ips: 40.2411 samples/sec | ETA 00:09:12
2023-03-06 20:37:35 [INFO]	[TRAIN] epoch: 779, iter: 13230/16000, loss: 0.2466, lr: 0.002064, batch_cost: 0.2538, reader_cost: 0.04111, ips: 31.5254 samples/sec | ETA 00:11:42
2023-03-06 20:37:37 [INFO]	[TRAIN] epoch: 779, iter: 13240/16000, loss: 0.1572, lr: 0.002057, batch_cost: 0.2013, reader_cost: 0.00029, ips: 39.7437 samples/sec | ETA 00:09:15
2023-03-06 20:37:40 [INFO]	[TRAIN] epoch: 780, iter: 13250/16000, loss: 0.1700, lr: 0.002050, batch_cost: 0.2513, reader_cost: 0.03888, ips: 31.8287 samples/sec | ETA 00:11:31
2023-03-06 20:37:42 [INFO]	[TRAIN] epoch: 780, iter: 13260/16000, loss: 0.2016, lr: 0.002044, batch_cost: 0.1924, reader_cost: 0.00027, ips: 41.5707 samples/sec | ETA 00:08:47
2023-03-06 20:37:44 [INFO]	[TRAIN] epoch: 781, iter: 13270/16000, loss: 0.1746, lr: 0.002037, batch_cost: 0.2378, reader_cost: 0.04152, ips: 33.6410 samples/sec | ETA 00:10:49
2023-03-06 20:37:47 [INFO]	[TRAIN] epoch: 782, iter: 13280/16000, loss: 0.4112, lr: 0.002030, batch_cost: 0.2419, reader_cost: 0.05004, ips: 33.0767 samples/sec | ETA 00:10:57
2023-03-06 20:37:48 [INFO]	[TRAIN] epoch: 782, iter: 13290/16000, loss: 0.2054, lr: 0.002024, batch_cost: 0.1808, reader_cost: 0.00024, ips: 44.2583 samples/sec | ETA 00:08:09
2023-03-06 20:37:51 [INFO]	[TRAIN] epoch: 783, iter: 13300/16000, loss: 0.2265, lr: 0.002017, batch_cost: 0.2463, reader_cost: 0.04564, ips: 32.4842 samples/sec | ETA 00:11:04
2023-03-06 20:37:53 [INFO]	[TRAIN] epoch: 783, iter: 13310/16000, loss: 0.1608, lr: 0.002010, batch_cost: 0.1980, reader_cost: 0.00025, ips: 40.4084 samples/sec | ETA 00:08:52
2023-03-06 20:37:56 [INFO]	[TRAIN] epoch: 784, iter: 13320/16000, loss: 0.2173, lr: 0.002003, batch_cost: 0.2626, reader_cost: 0.04092, ips: 30.4674 samples/sec | ETA 00:11:43
2023-03-06 20:37:58 [INFO]	[TRAIN] epoch: 785, iter: 13330/16000, loss: 0.2261, lr: 0.001997, batch_cost: 0.2470, reader_cost: 0.04278, ips: 32.3879 samples/sec | ETA 00:10:59
2023-03-06 20:38:00 [INFO]	[TRAIN] epoch: 785, iter: 13340/16000, loss: 0.1579, lr: 0.001990, batch_cost: 0.2009, reader_cost: 0.00031, ips: 39.8280 samples/sec | ETA 00:08:54
2023-03-06 20:38:03 [INFO]	[TRAIN] epoch: 786, iter: 13350/16000, loss: 0.2389, lr: 0.001983, batch_cost: 0.2668, reader_cost: 0.04399, ips: 29.9804 samples/sec | ETA 00:11:47
2023-03-06 20:38:05 [INFO]	[TRAIN] epoch: 786, iter: 13360/16000, loss: 0.2319, lr: 0.001976, batch_cost: 0.1943, reader_cost: 0.00032, ips: 41.1630 samples/sec | ETA 00:08:33
2023-03-06 20:38:07 [INFO]	[TRAIN] epoch: 787, iter: 13370/16000, loss: 0.1661, lr: 0.001970, batch_cost: 0.2476, reader_cost: 0.04643, ips: 32.3121 samples/sec | ETA 00:10:51
2023-03-06 20:38:10 [INFO]	[TRAIN] epoch: 788, iter: 13380/16000, loss: 0.1947, lr: 0.001963, batch_cost: 0.2488, reader_cost: 0.04351, ips: 32.1550 samples/sec | ETA 00:10:51
2023-03-06 20:38:12 [INFO]	[TRAIN] epoch: 788, iter: 13390/16000, loss: 0.2483, lr: 0.001956, batch_cost: 0.2056, reader_cost: 0.00919, ips: 38.9080 samples/sec | ETA 00:08:56
2023-03-06 20:38:14 [INFO]	[TRAIN] epoch: 789, iter: 13400/16000, loss: 0.2316, lr: 0.001949, batch_cost: 0.2430, reader_cost: 0.04939, ips: 32.9265 samples/sec | ETA 00:10:31
2023-03-06 20:38:16 [INFO]	[TRAIN] epoch: 789, iter: 13410/16000, loss: 0.1336, lr: 0.001943, batch_cost: 0.1988, reader_cost: 0.00026, ips: 40.2439 samples/sec | ETA 00:08:34
2023-03-06 20:38:19 [INFO]	[TRAIN] epoch: 790, iter: 13420/16000, loss: 0.1734, lr: 0.001936, batch_cost: 0.2554, reader_cost: 0.03802, ips: 31.3248 samples/sec | ETA 00:10:58
2023-03-06 20:38:20 [INFO]	[TRAIN] epoch: 790, iter: 13430/16000, loss: 0.2193, lr: 0.001929, batch_cost: 0.1860, reader_cost: 0.00026, ips: 43.0184 samples/sec | ETA 00:07:57
2023-03-06 20:38:23 [INFO]	[TRAIN] epoch: 791, iter: 13440/16000, loss: 0.1915, lr: 0.001922, batch_cost: 0.2458, reader_cost: 0.05014, ips: 32.5462 samples/sec | ETA 00:10:29
2023-03-06 20:38:25 [INFO]	[TRAIN] epoch: 792, iter: 13450/16000, loss: 0.1881, lr: 0.001916, batch_cost: 0.2303, reader_cost: 0.03902, ips: 34.7420 samples/sec | ETA 00:09:47
2023-03-06 20:38:27 [INFO]	[TRAIN] epoch: 792, iter: 13460/16000, loss: 0.2784, lr: 0.001909, batch_cost: 0.1965, reader_cost: 0.00027, ips: 40.7135 samples/sec | ETA 00:08:19
2023-03-06 20:38:30 [INFO]	[TRAIN] epoch: 793, iter: 13470/16000, loss: 0.2649, lr: 0.001902, batch_cost: 0.2603, reader_cost: 0.03851, ips: 30.7383 samples/sec | ETA 00:10:58
2023-03-06 20:38:32 [INFO]	[TRAIN] epoch: 793, iter: 13480/16000, loss: 0.2569, lr: 0.001895, batch_cost: 0.2039, reader_cost: 0.00026, ips: 39.2385 samples/sec | ETA 00:08:33
2023-03-06 20:38:34 [INFO]	[TRAIN] epoch: 794, iter: 13490/16000, loss: 0.1439, lr: 0.001889, batch_cost: 0.2489, reader_cost: 0.04202, ips: 32.1389 samples/sec | ETA 00:10:24
2023-03-06 20:38:37 [INFO]	[TRAIN] epoch: 795, iter: 13500/16000, loss: 0.1992, lr: 0.001882, batch_cost: 0.2512, reader_cost: 0.04338, ips: 31.8425 samples/sec | ETA 00:10:28
2023-03-06 20:38:39 [INFO]	[TRAIN] epoch: 795, iter: 13510/16000, loss: 0.2836, lr: 0.001875, batch_cost: 0.1924, reader_cost: 0.00030, ips: 41.5753 samples/sec | ETA 00:07:59
2023-03-06 20:38:41 [INFO]	[TRAIN] epoch: 796, iter: 13520/16000, loss: 0.2202, lr: 0.001868, batch_cost: 0.2439, reader_cost: 0.04312, ips: 32.8055 samples/sec | ETA 00:10:04
2023-03-06 20:38:43 [INFO]	[TRAIN] epoch: 796, iter: 13530/16000, loss: 0.2230, lr: 0.001862, batch_cost: 0.1926, reader_cost: 0.00031, ips: 41.5360 samples/sec | ETA 00:07:55
2023-03-06 20:38:46 [INFO]	[TRAIN] epoch: 797, iter: 13540/16000, loss: 0.2369, lr: 0.001855, batch_cost: 0.2679, reader_cost: 0.05664, ips: 29.8569 samples/sec | ETA 00:10:59
2023-03-06 20:38:48 [INFO]	[TRAIN] epoch: 798, iter: 13550/16000, loss: 0.1771, lr: 0.001848, batch_cost: 0.2629, reader_cost: 0.04416, ips: 30.4355 samples/sec | ETA 00:10:43
2023-03-06 20:38:50 [INFO]	[TRAIN] epoch: 798, iter: 13560/16000, loss: 0.2020, lr: 0.001841, batch_cost: 0.1995, reader_cost: 0.00028, ips: 40.0993 samples/sec | ETA 00:08:06
2023-03-06 20:38:53 [INFO]	[TRAIN] epoch: 799, iter: 13570/16000, loss: 0.1562, lr: 0.001834, batch_cost: 0.2440, reader_cost: 0.04432, ips: 32.7927 samples/sec | ETA 00:09:52
2023-03-06 20:38:55 [INFO]	[TRAIN] epoch: 799, iter: 13580/16000, loss: 0.1841, lr: 0.001828, batch_cost: 0.1851, reader_cost: 0.00027, ips: 43.2193 samples/sec | ETA 00:07:27
2023-03-06 20:38:57 [INFO]	[TRAIN] epoch: 800, iter: 13590/16000, loss: 0.1892, lr: 0.001821, batch_cost: 0.2411, reader_cost: 0.03821, ips: 33.1758 samples/sec | ETA 00:09:41
2023-03-06 20:38:59 [INFO]	[TRAIN] epoch: 800, iter: 13600/16000, loss: 0.2038, lr: 0.001814, batch_cost: 0.1803, reader_cost: 0.00026, ips: 44.3764 samples/sec | ETA 00:07:12
2023-03-06 20:39:02 [INFO]	[TRAIN] epoch: 801, iter: 13610/16000, loss: 0.2743, lr: 0.001807, batch_cost: 0.2822, reader_cost: 0.04344, ips: 28.3497 samples/sec | ETA 00:11:14
2023-03-06 20:39:04 [INFO]	[TRAIN] epoch: 802, iter: 13620/16000, loss: 0.3106, lr: 0.001800, batch_cost: 0.2438, reader_cost: 0.04095, ips: 32.8080 samples/sec | ETA 00:09:40
2023-03-06 20:39:06 [INFO]	[TRAIN] epoch: 802, iter: 13630/16000, loss: 0.2609, lr: 0.001794, batch_cost: 0.1898, reader_cost: 0.00031, ips: 42.1555 samples/sec | ETA 00:07:29
2023-03-06 20:39:09 [INFO]	[TRAIN] epoch: 803, iter: 13640/16000, loss: 0.2144, lr: 0.001787, batch_cost: 0.2638, reader_cost: 0.04520, ips: 30.3249 samples/sec | ETA 00:10:22
2023-03-06 20:39:11 [INFO]	[TRAIN] epoch: 803, iter: 13650/16000, loss: 0.1504, lr: 0.001780, batch_cost: 0.2000, reader_cost: 0.00026, ips: 39.9938 samples/sec | ETA 00:07:50
2023-03-06 20:39:13 [INFO]	[TRAIN] epoch: 804, iter: 13660/16000, loss: 0.1998, lr: 0.001773, batch_cost: 0.2625, reader_cost: 0.05265, ips: 30.4796 samples/sec | ETA 00:10:14
2023-03-06 20:39:16 [INFO]	[TRAIN] epoch: 805, iter: 13670/16000, loss: 0.1942, lr: 0.001766, batch_cost: 0.2553, reader_cost: 0.05285, ips: 31.3383 samples/sec | ETA 00:09:54
2023-03-06 20:39:18 [INFO]	[TRAIN] epoch: 805, iter: 13680/16000, loss: 0.2203, lr: 0.001760, batch_cost: 0.1869, reader_cost: 0.00025, ips: 42.7958 samples/sec | ETA 00:07:13
2023-03-06 20:39:20 [INFO]	[TRAIN] epoch: 806, iter: 13690/16000, loss: 0.2231, lr: 0.001753, batch_cost: 0.2536, reader_cost: 0.04872, ips: 31.5434 samples/sec | ETA 00:09:45
2023-03-06 20:39:22 [INFO]	[TRAIN] epoch: 806, iter: 13700/16000, loss: 0.1955, lr: 0.001746, batch_cost: 0.1882, reader_cost: 0.00033, ips: 42.5027 samples/sec | ETA 00:07:12
2023-03-06 20:39:25 [INFO]	[TRAIN] epoch: 807, iter: 13710/16000, loss: 0.1904, lr: 0.001739, batch_cost: 0.2411, reader_cost: 0.04099, ips: 33.1840 samples/sec | ETA 00:09:12
2023-03-06 20:39:27 [INFO]	[TRAIN] epoch: 808, iter: 13720/16000, loss: 0.2398, lr: 0.001732, batch_cost: 0.2573, reader_cost: 0.06112, ips: 31.0957 samples/sec | ETA 00:09:46
2023-03-06 20:39:30 [INFO]	[TRAIN] epoch: 808, iter: 13730/16000, loss: 0.1767, lr: 0.001725, batch_cost: 0.2773, reader_cost: 0.00033, ips: 28.8450 samples/sec | ETA 00:10:29
2023-03-06 20:39:32 [INFO]	[TRAIN] epoch: 809, iter: 13740/16000, loss: 0.2441, lr: 0.001719, batch_cost: 0.2468, reader_cost: 0.04033, ips: 32.4093 samples/sec | ETA 00:09:17
2023-03-06 20:39:34 [INFO]	[TRAIN] epoch: 809, iter: 13750/16000, loss: 0.2592, lr: 0.001712, batch_cost: 0.1782, reader_cost: 0.00026, ips: 44.8830 samples/sec | ETA 00:06:41
2023-03-06 20:39:37 [INFO]	[TRAIN] epoch: 810, iter: 13760/16000, loss: 0.3072, lr: 0.001705, batch_cost: 0.2609, reader_cost: 0.05199, ips: 30.6652 samples/sec | ETA 00:09:44
2023-03-06 20:39:39 [INFO]	[TRAIN] epoch: 810, iter: 13770/16000, loss: 0.1493, lr: 0.001698, batch_cost: 0.1956, reader_cost: 0.00244, ips: 40.8940 samples/sec | ETA 00:07:16
2023-03-06 20:39:41 [INFO]	[TRAIN] epoch: 811, iter: 13780/16000, loss: 0.2445, lr: 0.001691, batch_cost: 0.2592, reader_cost: 0.05763, ips: 30.8595 samples/sec | ETA 00:09:35
2023-03-06 20:39:44 [INFO]	[TRAIN] epoch: 812, iter: 13790/16000, loss: 0.1963, lr: 0.001684, batch_cost: 0.2896, reader_cost: 0.04705, ips: 27.6218 samples/sec | ETA 00:10:40
2023-03-06 20:39:46 [INFO]	[TRAIN] epoch: 812, iter: 13800/16000, loss: 0.2712, lr: 0.001677, batch_cost: 0.1964, reader_cost: 0.00031, ips: 40.7340 samples/sec | ETA 00:07:12
2023-03-06 20:39:49 [INFO]	[TRAIN] epoch: 813, iter: 13810/16000, loss: 0.1714, lr: 0.001671, batch_cost: 0.2665, reader_cost: 0.05995, ips: 30.0141 samples/sec | ETA 00:09:43
2023-03-06 20:39:51 [INFO]	[TRAIN] epoch: 813, iter: 13820/16000, loss: 0.1945, lr: 0.001664, batch_cost: 0.1899, reader_cost: 0.00029, ips: 42.1289 samples/sec | ETA 00:06:53
2023-03-06 20:39:54 [INFO]	[TRAIN] epoch: 814, iter: 13830/16000, loss: 0.1726, lr: 0.001657, batch_cost: 0.2858, reader_cost: 0.04773, ips: 27.9884 samples/sec | ETA 00:10:20
2023-03-06 20:39:57 [INFO]	[TRAIN] epoch: 815, iter: 13840/16000, loss: 0.1821, lr: 0.001650, batch_cost: 0.2820, reader_cost: 0.05511, ips: 28.3689 samples/sec | ETA 00:10:09
2023-03-06 20:39:59 [INFO]	[TRAIN] epoch: 815, iter: 13850/16000, loss: 0.1745, lr: 0.001643, batch_cost: 0.2238, reader_cost: 0.00031, ips: 35.7426 samples/sec | ETA 00:08:01
2023-03-06 20:40:02 [INFO]	[TRAIN] epoch: 816, iter: 13860/16000, loss: 0.1648, lr: 0.001636, batch_cost: 0.2863, reader_cost: 0.05254, ips: 27.9419 samples/sec | ETA 00:10:12
2023-03-06 20:40:04 [INFO]	[TRAIN] epoch: 816, iter: 13870/16000, loss: 0.1975, lr: 0.001629, batch_cost: 0.2280, reader_cost: 0.00036, ips: 35.0913 samples/sec | ETA 00:08:05
2023-03-06 20:40:07 [INFO]	[TRAIN] epoch: 817, iter: 13880/16000, loss: 0.2498, lr: 0.001622, batch_cost: 0.2929, reader_cost: 0.05505, ips: 27.3130 samples/sec | ETA 00:10:20
2023-03-06 20:40:10 [INFO]	[TRAIN] epoch: 818, iter: 13890/16000, loss: 0.2027, lr: 0.001616, batch_cost: 0.2846, reader_cost: 0.04618, ips: 28.1081 samples/sec | ETA 00:10:00
2023-03-06 20:40:12 [INFO]	[TRAIN] epoch: 818, iter: 13900/16000, loss: 0.2800, lr: 0.001609, batch_cost: 0.1989, reader_cost: 0.00032, ips: 40.2299 samples/sec | ETA 00:06:57
2023-03-06 20:40:14 [INFO]	[TRAIN] epoch: 819, iter: 13910/16000, loss: 0.2480, lr: 0.001602, batch_cost: 0.2478, reader_cost: 0.04483, ips: 32.2809 samples/sec | ETA 00:08:37
2023-03-06 20:40:16 [INFO]	[TRAIN] epoch: 819, iter: 13920/16000, loss: 0.2164, lr: 0.001595, batch_cost: 0.1949, reader_cost: 0.00029, ips: 41.0410 samples/sec | ETA 00:06:45
2023-03-06 20:40:19 [INFO]	[TRAIN] epoch: 820, iter: 13930/16000, loss: 0.1951, lr: 0.001588, batch_cost: 0.2583, reader_cost: 0.04946, ips: 30.9682 samples/sec | ETA 00:08:54
2023-03-06 20:40:21 [INFO]	[TRAIN] epoch: 820, iter: 13940/16000, loss: 0.2083, lr: 0.001581, batch_cost: 0.1850, reader_cost: 0.00027, ips: 43.2319 samples/sec | ETA 00:06:21
2023-03-06 20:40:23 [INFO]	[TRAIN] epoch: 821, iter: 13950/16000, loss: 0.1908, lr: 0.001574, batch_cost: 0.2669, reader_cost: 0.04099, ips: 29.9712 samples/sec | ETA 00:09:07
2023-03-06 20:40:26 [INFO]	[TRAIN] epoch: 822, iter: 13960/16000, loss: 0.1941, lr: 0.001567, batch_cost: 0.2446, reader_cost: 0.04938, ips: 32.7084 samples/sec | ETA 00:08:18
2023-03-06 20:40:28 [INFO]	[TRAIN] epoch: 822, iter: 13970/16000, loss: 0.2297, lr: 0.001560, batch_cost: 0.1924, reader_cost: 0.00029, ips: 41.5797 samples/sec | ETA 00:06:30
2023-03-06 20:40:30 [INFO]	[TRAIN] epoch: 823, iter: 13980/16000, loss: 0.1956, lr: 0.001553, batch_cost: 0.2468, reader_cost: 0.04584, ips: 32.4180 samples/sec | ETA 00:08:18
2023-03-06 20:40:32 [INFO]	[TRAIN] epoch: 823, iter: 13990/16000, loss: 0.1656, lr: 0.001547, batch_cost: 0.1883, reader_cost: 0.00027, ips: 42.4770 samples/sec | ETA 00:06:18
2023-03-06 20:40:34 [INFO]	[TRAIN] epoch: 824, iter: 14000/16000, loss: 0.2052, lr: 0.001540, batch_cost: 0.2493, reader_cost: 0.05035, ips: 32.0885 samples/sec | ETA 00:08:18
2023-03-06 20:40:34 [INFO]	Start evaluating (total_samples: 119, total_iters: 60)...
60/60 - 3s - batch_cost: 0.0542 - reader cost: 0.0020
2023-03-06 20:40:38 [INFO]	[EVAL] #Images: 119 mIoU: 0.7685 Acc: 0.9260 Kappa: 0.7227 Dice: 0.8612
2023-03-06 20:40:38 [INFO]	[EVAL] Class IoU: 
[0.9158 0.6213]
2023-03-06 20:40:38 [INFO]	[EVAL] Class Precision: 
[0.9674 0.7215]
2023-03-06 20:40:38 [INFO]	[EVAL] Class Recall: 
[0.945  0.8172]
2023-03-06 20:40:38 [INFO]	[EVAL] The model with the best validation mIoU (0.7871) was saved at iter 11000.
2023-03-06 20:40:41 [INFO]	[TRAIN] epoch: 825, iter: 14010/16000, loss: 0.1881, lr: 0.001533, batch_cost: 0.2543, reader_cost: 0.05834, ips: 31.4539 samples/sec | ETA 00:08:26
2023-03-06 20:40:43 [INFO]	[TRAIN] epoch: 825, iter: 14020/16000, loss: 0.1437, lr: 0.001526, batch_cost: 0.1896, reader_cost: 0.00032, ips: 42.1904 samples/sec | ETA 00:06:15
2023-03-06 20:40:45 [INFO]	[TRAIN] epoch: 826, iter: 14030/16000, loss: 0.2041, lr: 0.001519, batch_cost: 0.2439, reader_cost: 0.04297, ips: 32.7981 samples/sec | ETA 00:08:00
2023-03-06 20:40:47 [INFO]	[TRAIN] epoch: 826, iter: 14040/16000, loss: 0.2043, lr: 0.001512, batch_cost: 0.1943, reader_cost: 0.00028, ips: 41.1808 samples/sec | ETA 00:06:20
2023-03-06 20:40:50 [INFO]	[TRAIN] epoch: 827, iter: 14050/16000, loss: 0.1581, lr: 0.001505, batch_cost: 0.2525, reader_cost: 0.05152, ips: 31.6814 samples/sec | ETA 00:08:12
2023-03-06 20:40:52 [INFO]	[TRAIN] epoch: 828, iter: 14060/16000, loss: 0.1832, lr: 0.001498, batch_cost: 0.2492, reader_cost: 0.05489, ips: 32.0981 samples/sec | ETA 00:08:03
2023-03-06 20:40:54 [INFO]	[TRAIN] epoch: 828, iter: 14070/16000, loss: 0.1695, lr: 0.001491, batch_cost: 0.1926, reader_cost: 0.00038, ips: 41.5396 samples/sec | ETA 00:06:11
2023-03-06 20:40:57 [INFO]	[TRAIN] epoch: 829, iter: 14080/16000, loss: 0.1852, lr: 0.001484, batch_cost: 0.2350, reader_cost: 0.04286, ips: 34.0362 samples/sec | ETA 00:07:31
2023-03-06 20:40:58 [INFO]	[TRAIN] epoch: 829, iter: 14090/16000, loss: 0.2486, lr: 0.001477, batch_cost: 0.1900, reader_cost: 0.00025, ips: 42.1070 samples/sec | ETA 00:06:02
2023-03-06 20:41:01 [INFO]	[TRAIN] epoch: 830, iter: 14100/16000, loss: 0.2734, lr: 0.001470, batch_cost: 0.2544, reader_cost: 0.04902, ips: 31.4417 samples/sec | ETA 00:08:03
2023-03-06 20:41:03 [INFO]	[TRAIN] epoch: 830, iter: 14110/16000, loss: 0.1801, lr: 0.001463, batch_cost: 0.1925, reader_cost: 0.00439, ips: 41.5613 samples/sec | ETA 00:06:03
2023-03-06 20:41:05 [INFO]	[TRAIN] epoch: 831, iter: 14120/16000, loss: 0.2330, lr: 0.001456, batch_cost: 0.2573, reader_cost: 0.04373, ips: 31.0898 samples/sec | ETA 00:08:03
2023-03-06 20:41:08 [INFO]	[TRAIN] epoch: 832, iter: 14130/16000, loss: 0.2336, lr: 0.001449, batch_cost: 0.2567, reader_cost: 0.04060, ips: 31.1639 samples/sec | ETA 00:08:00
2023-03-06 20:41:10 [INFO]	[TRAIN] epoch: 832, iter: 14140/16000, loss: 0.2240, lr: 0.001442, batch_cost: 0.2287, reader_cost: 0.00032, ips: 34.9727 samples/sec | ETA 00:07:05
2023-03-06 20:41:13 [INFO]	[TRAIN] epoch: 833, iter: 14150/16000, loss: 0.1996, lr: 0.001435, batch_cost: 0.2557, reader_cost: 0.03246, ips: 31.2828 samples/sec | ETA 00:07:53
2023-03-06 20:41:15 [INFO]	[TRAIN] epoch: 833, iter: 14160/16000, loss: 0.1786, lr: 0.001428, batch_cost: 0.1937, reader_cost: 0.00028, ips: 41.3082 samples/sec | ETA 00:05:56
2023-03-06 20:41:17 [INFO]	[TRAIN] epoch: 834, iter: 14170/16000, loss: 0.1731, lr: 0.001421, batch_cost: 0.2494, reader_cost: 0.03781, ips: 32.0711 samples/sec | ETA 00:07:36
2023-03-06 20:41:20 [INFO]	[TRAIN] epoch: 835, iter: 14180/16000, loss: 0.1702, lr: 0.001414, batch_cost: 0.2481, reader_cost: 0.04818, ips: 32.2430 samples/sec | ETA 00:07:31
2023-03-06 20:41:22 [INFO]	[TRAIN] epoch: 835, iter: 14190/16000, loss: 0.2123, lr: 0.001407, batch_cost: 0.1919, reader_cost: 0.00027, ips: 41.6912 samples/sec | ETA 00:05:47
2023-03-06 20:41:25 [INFO]	[TRAIN] epoch: 836, iter: 14200/16000, loss: 0.2151, lr: 0.001400, batch_cost: 0.3098, reader_cost: 0.07250, ips: 25.8247 samples/sec | ETA 00:09:17
2023-03-06 20:41:27 [INFO]	[TRAIN] epoch: 836, iter: 14210/16000, loss: 0.1545, lr: 0.001393, batch_cost: 0.2244, reader_cost: 0.00031, ips: 35.6521 samples/sec | ETA 00:06:41
2023-03-06 20:41:30 [INFO]	[TRAIN] epoch: 837, iter: 14220/16000, loss: 0.3450, lr: 0.001386, batch_cost: 0.2836, reader_cost: 0.04503, ips: 28.2059 samples/sec | ETA 00:08:24
2023-03-06 20:41:33 [INFO]	[TRAIN] epoch: 838, iter: 14230/16000, loss: 0.2327, lr: 0.001379, batch_cost: 0.2849, reader_cost: 0.04816, ips: 28.0789 samples/sec | ETA 00:08:24
2023-03-06 20:41:35 [INFO]	[TRAIN] epoch: 838, iter: 14240/16000, loss: 0.1443, lr: 0.001372, batch_cost: 0.1908, reader_cost: 0.00027, ips: 41.9215 samples/sec | ETA 00:05:35
2023-03-06 20:41:37 [INFO]	[TRAIN] epoch: 839, iter: 14250/16000, loss: 0.1486, lr: 0.001365, batch_cost: 0.2503, reader_cost: 0.04502, ips: 31.9625 samples/sec | ETA 00:07:18
2023-03-06 20:41:39 [INFO]	[TRAIN] epoch: 839, iter: 14260/16000, loss: 0.2091, lr: 0.001358, batch_cost: 0.1910, reader_cost: 0.00031, ips: 41.8907 samples/sec | ETA 00:05:32
2023-03-06 20:41:42 [INFO]	[TRAIN] epoch: 840, iter: 14270/16000, loss: 0.2259, lr: 0.001351, batch_cost: 0.2619, reader_cost: 0.06276, ips: 30.5408 samples/sec | ETA 00:07:33
2023-03-06 20:41:44 [INFO]	[TRAIN] epoch: 840, iter: 14280/16000, loss: 0.1947, lr: 0.001344, batch_cost: 0.1913, reader_cost: 0.00030, ips: 41.8129 samples/sec | ETA 00:05:29
2023-03-06 20:41:46 [INFO]	[TRAIN] epoch: 841, iter: 14290/16000, loss: 0.2208, lr: 0.001337, batch_cost: 0.2586, reader_cost: 0.06232, ips: 30.9307 samples/sec | ETA 00:07:22
2023-03-06 20:41:49 [INFO]	[TRAIN] epoch: 842, iter: 14300/16000, loss: 0.1857, lr: 0.001330, batch_cost: 0.2469, reader_cost: 0.04885, ips: 32.4005 samples/sec | ETA 00:06:59
2023-03-06 20:41:51 [INFO]	[TRAIN] epoch: 842, iter: 14310/16000, loss: 0.1877, lr: 0.001323, batch_cost: 0.1950, reader_cost: 0.00029, ips: 41.0353 samples/sec | ETA 00:05:29
2023-03-06 20:41:53 [INFO]	[TRAIN] epoch: 843, iter: 14320/16000, loss: 0.1253, lr: 0.001316, batch_cost: 0.2428, reader_cost: 0.04443, ips: 32.9439 samples/sec | ETA 00:06:47
2023-03-06 20:41:55 [INFO]	[TRAIN] epoch: 843, iter: 14330/16000, loss: 0.2150, lr: 0.001309, batch_cost: 0.1784, reader_cost: 0.00026, ips: 44.8314 samples/sec | ETA 00:04:58
2023-03-06 20:41:57 [INFO]	[TRAIN] epoch: 844, iter: 14340/16000, loss: 0.1735, lr: 0.001302, batch_cost: 0.2502, reader_cost: 0.05461, ips: 31.9722 samples/sec | ETA 00:06:55
2023-03-06 20:42:00 [INFO]	[TRAIN] epoch: 845, iter: 14350/16000, loss: 0.2108, lr: 0.001295, batch_cost: 0.2701, reader_cost: 0.07639, ips: 29.6147 samples/sec | ETA 00:07:25
2023-03-06 20:42:02 [INFO]	[TRAIN] epoch: 845, iter: 14360/16000, loss: 0.2142, lr: 0.001288, batch_cost: 0.1965, reader_cost: 0.00027, ips: 40.7189 samples/sec | ETA 00:05:22
2023-03-06 20:42:05 [INFO]	[TRAIN] epoch: 846, iter: 14370/16000, loss: 0.2969, lr: 0.001281, batch_cost: 0.2637, reader_cost: 0.04106, ips: 30.3361 samples/sec | ETA 00:07:09
2023-03-06 20:42:07 [INFO]	[TRAIN] epoch: 846, iter: 14380/16000, loss: 0.1634, lr: 0.001274, batch_cost: 0.2230, reader_cost: 0.00031, ips: 35.8771 samples/sec | ETA 00:06:01
2023-03-06 20:42:09 [INFO]	[TRAIN] epoch: 847, iter: 14390/16000, loss: 0.1994, lr: 0.001267, batch_cost: 0.2570, reader_cost: 0.04242, ips: 31.1324 samples/sec | ETA 00:06:53
2023-03-06 20:42:12 [INFO]	[TRAIN] epoch: 848, iter: 14400/16000, loss: 0.2196, lr: 0.001260, batch_cost: 0.2543, reader_cost: 0.03559, ips: 31.4597 samples/sec | ETA 00:06:46
2023-03-06 20:42:14 [INFO]	[TRAIN] epoch: 848, iter: 14410/16000, loss: 0.1868, lr: 0.001253, batch_cost: 0.1910, reader_cost: 0.00032, ips: 41.8817 samples/sec | ETA 00:05:03
2023-03-06 20:42:16 [INFO]	[TRAIN] epoch: 849, iter: 14420/16000, loss: 0.3553, lr: 0.001245, batch_cost: 0.2516, reader_cost: 0.04017, ips: 31.7992 samples/sec | ETA 00:06:37
2023-03-06 20:42:18 [INFO]	[TRAIN] epoch: 849, iter: 14430/16000, loss: 0.2385, lr: 0.001238, batch_cost: 0.1957, reader_cost: 0.00027, ips: 40.8709 samples/sec | ETA 00:05:07
2023-03-06 20:42:21 [INFO]	[TRAIN] epoch: 850, iter: 14440/16000, loss: 0.2051, lr: 0.001231, batch_cost: 0.2484, reader_cost: 0.04532, ips: 32.2113 samples/sec | ETA 00:06:27
2023-03-06 20:42:23 [INFO]	[TRAIN] epoch: 850, iter: 14450/16000, loss: 0.1606, lr: 0.001224, batch_cost: 0.1855, reader_cost: 0.00026, ips: 43.1256 samples/sec | ETA 00:04:47
2023-03-06 20:42:25 [INFO]	[TRAIN] epoch: 851, iter: 14460/16000, loss: 0.1921, lr: 0.001217, batch_cost: 0.2579, reader_cost: 0.06302, ips: 31.0230 samples/sec | ETA 00:06:37
2023-03-06 20:42:28 [INFO]	[TRAIN] epoch: 852, iter: 14470/16000, loss: 0.1783, lr: 0.001210, batch_cost: 0.2574, reader_cost: 0.04813, ips: 31.0825 samples/sec | ETA 00:06:33
2023-03-06 20:42:30 [INFO]	[TRAIN] epoch: 852, iter: 14480/16000, loss: 0.2740, lr: 0.001203, batch_cost: 0.1972, reader_cost: 0.00032, ips: 40.5778 samples/sec | ETA 00:04:59
2023-03-06 20:42:32 [INFO]	[TRAIN] epoch: 853, iter: 14490/16000, loss: 0.2618, lr: 0.001196, batch_cost: 0.2477, reader_cost: 0.04400, ips: 32.2931 samples/sec | ETA 00:06:14
2023-03-06 20:42:34 [INFO]	[TRAIN] epoch: 853, iter: 14500/16000, loss: 0.2279, lr: 0.001189, batch_cost: 0.1831, reader_cost: 0.00026, ips: 43.6954 samples/sec | ETA 00:04:34
2023-03-06 20:42:37 [INFO]	[TRAIN] epoch: 854, iter: 14510/16000, loss: 0.1891, lr: 0.001181, batch_cost: 0.2684, reader_cost: 0.05597, ips: 29.8058 samples/sec | ETA 00:06:39
2023-03-06 20:42:39 [INFO]	[TRAIN] epoch: 855, iter: 14520/16000, loss: 0.1842, lr: 0.001174, batch_cost: 0.2528, reader_cost: 0.06044, ips: 31.6484 samples/sec | ETA 00:06:14
2023-03-06 20:42:41 [INFO]	[TRAIN] epoch: 855, iter: 14530/16000, loss: 0.1605, lr: 0.001167, batch_cost: 0.1912, reader_cost: 0.00031, ips: 41.8489 samples/sec | ETA 00:04:41
2023-03-06 20:42:44 [INFO]	[TRAIN] epoch: 856, iter: 14540/16000, loss: 0.1649, lr: 0.001160, batch_cost: 0.2588, reader_cost: 0.04720, ips: 30.9132 samples/sec | ETA 00:06:17
2023-03-06 20:42:46 [INFO]	[TRAIN] epoch: 856, iter: 14550/16000, loss: 0.2621, lr: 0.001153, batch_cost: 0.2024, reader_cost: 0.00027, ips: 39.5264 samples/sec | ETA 00:04:53
2023-03-06 20:42:48 [INFO]	[TRAIN] epoch: 857, iter: 14560/16000, loss: 0.1780, lr: 0.001146, batch_cost: 0.2598, reader_cost: 0.04155, ips: 30.7916 samples/sec | ETA 00:06:14
2023-03-06 20:42:51 [INFO]	[TRAIN] epoch: 858, iter: 14570/16000, loss: 0.2379, lr: 0.001139, batch_cost: 0.2891, reader_cost: 0.09310, ips: 27.6748 samples/sec | ETA 00:06:53
2023-03-06 20:42:53 [INFO]	[TRAIN] epoch: 858, iter: 14580/16000, loss: 0.1804, lr: 0.001131, batch_cost: 0.1795, reader_cost: 0.00027, ips: 44.5605 samples/sec | ETA 00:04:14
2023-03-06 20:42:56 [INFO]	[TRAIN] epoch: 859, iter: 14590/16000, loss: 0.1992, lr: 0.001124, batch_cost: 0.2486, reader_cost: 0.05808, ips: 32.1833 samples/sec | ETA 00:05:50
2023-03-06 20:42:58 [INFO]	[TRAIN] epoch: 859, iter: 14600/16000, loss: 0.2192, lr: 0.001117, batch_cost: 0.1911, reader_cost: 0.00027, ips: 41.8533 samples/sec | ETA 00:04:27
2023-03-06 20:43:00 [INFO]	[TRAIN] epoch: 860, iter: 14610/16000, loss: 0.2031, lr: 0.001110, batch_cost: 0.2690, reader_cost: 0.04315, ips: 29.7366 samples/sec | ETA 00:06:13
2023-03-06 20:43:02 [INFO]	[TRAIN] epoch: 860, iter: 14620/16000, loss: 0.1949, lr: 0.001103, batch_cost: 0.1956, reader_cost: 0.00038, ips: 40.9007 samples/sec | ETA 00:04:29
2023-03-06 20:43:05 [INFO]	[TRAIN] epoch: 861, iter: 14630/16000, loss: 0.1532, lr: 0.001096, batch_cost: 0.2672, reader_cost: 0.05257, ips: 29.9412 samples/sec | ETA 00:06:06
2023-03-06 20:43:07 [INFO]	[TRAIN] epoch: 862, iter: 14640/16000, loss: 0.2065, lr: 0.001088, batch_cost: 0.2553, reader_cost: 0.04560, ips: 31.3375 samples/sec | ETA 00:05:47
2023-03-06 20:43:09 [INFO]	[TRAIN] epoch: 862, iter: 14650/16000, loss: 0.2380, lr: 0.001081, batch_cost: 0.1966, reader_cost: 0.00031, ips: 40.6927 samples/sec | ETA 00:04:25
2023-03-06 20:43:12 [INFO]	[TRAIN] epoch: 863, iter: 14660/16000, loss: 0.2318, lr: 0.001074, batch_cost: 0.2477, reader_cost: 0.04850, ips: 32.3003 samples/sec | ETA 00:05:31
2023-03-06 20:43:14 [INFO]	[TRAIN] epoch: 863, iter: 14670/16000, loss: 0.2455, lr: 0.001067, batch_cost: 0.1869, reader_cost: 0.00023, ips: 42.8111 samples/sec | ETA 00:04:08
2023-03-06 20:43:17 [INFO]	[TRAIN] epoch: 864, iter: 14680/16000, loss: 0.1552, lr: 0.001060, batch_cost: 0.2886, reader_cost: 0.04597, ips: 27.7222 samples/sec | ETA 00:06:20
2023-03-06 20:43:19 [INFO]	[TRAIN] epoch: 865, iter: 14690/16000, loss: 0.1808, lr: 0.001052, batch_cost: 0.2426, reader_cost: 0.04718, ips: 32.9818 samples/sec | ETA 00:05:17
2023-03-06 20:43:21 [INFO]	[TRAIN] epoch: 865, iter: 14700/16000, loss: 0.1398, lr: 0.001045, batch_cost: 0.1871, reader_cost: 0.00028, ips: 42.7555 samples/sec | ETA 00:04:03
2023-03-06 20:43:24 [INFO]	[TRAIN] epoch: 866, iter: 14710/16000, loss: 0.2007, lr: 0.001038, batch_cost: 0.2674, reader_cost: 0.06973, ips: 29.9218 samples/sec | ETA 00:05:44
2023-03-06 20:43:25 [INFO]	[TRAIN] epoch: 866, iter: 14720/16000, loss: 0.1505, lr: 0.001031, batch_cost: 0.1886, reader_cost: 0.00030, ips: 42.4248 samples/sec | ETA 00:04:01
2023-03-06 20:43:28 [INFO]	[TRAIN] epoch: 867, iter: 14730/16000, loss: 0.1665, lr: 0.001023, batch_cost: 0.2517, reader_cost: 0.05106, ips: 31.7814 samples/sec | ETA 00:05:19
2023-03-06 20:43:30 [INFO]	[TRAIN] epoch: 868, iter: 14740/16000, loss: 0.2497, lr: 0.001016, batch_cost: 0.2437, reader_cost: 0.04851, ips: 32.8212 samples/sec | ETA 00:05:07
2023-03-06 20:43:32 [INFO]	[TRAIN] epoch: 868, iter: 14750/16000, loss: 0.1936, lr: 0.001009, batch_cost: 0.1850, reader_cost: 0.00030, ips: 43.2492 samples/sec | ETA 00:03:51
2023-03-06 20:43:35 [INFO]	[TRAIN] epoch: 869, iter: 14760/16000, loss: 0.2314, lr: 0.001002, batch_cost: 0.2350, reader_cost: 0.04405, ips: 34.0447 samples/sec | ETA 00:04:51
2023-03-06 20:43:37 [INFO]	[TRAIN] epoch: 869, iter: 14770/16000, loss: 0.2236, lr: 0.000994, batch_cost: 0.1928, reader_cost: 0.00028, ips: 41.5040 samples/sec | ETA 00:03:57
2023-03-06 20:43:39 [INFO]	[TRAIN] epoch: 870, iter: 14780/16000, loss: 0.2813, lr: 0.000987, batch_cost: 0.2655, reader_cost: 0.03663, ips: 30.1263 samples/sec | ETA 00:05:23
2023-03-06 20:43:42 [INFO]	[TRAIN] epoch: 870, iter: 14790/16000, loss: 0.2039, lr: 0.000980, batch_cost: 0.2282, reader_cost: 0.00032, ips: 35.0505 samples/sec | ETA 00:04:36
2023-03-06 20:43:44 [INFO]	[TRAIN] epoch: 871, iter: 14800/16000, loss: 0.2162, lr: 0.000972, batch_cost: 0.2832, reader_cost: 0.05152, ips: 28.2445 samples/sec | ETA 00:05:39
2023-03-06 20:43:47 [INFO]	[TRAIN] epoch: 872, iter: 14810/16000, loss: 0.1917, lr: 0.000965, batch_cost: 0.2850, reader_cost: 0.05454, ips: 28.0751 samples/sec | ETA 00:05:39
2023-03-06 20:43:50 [INFO]	[TRAIN] epoch: 872, iter: 14820/16000, loss: 0.1921, lr: 0.000958, batch_cost: 0.2311, reader_cost: 0.00032, ips: 34.6228 samples/sec | ETA 00:04:32
2023-03-06 20:43:52 [INFO]	[TRAIN] epoch: 873, iter: 14830/16000, loss: 0.1402, lr: 0.000951, batch_cost: 0.2817, reader_cost: 0.04565, ips: 28.4034 samples/sec | ETA 00:05:29
2023-03-06 20:43:55 [INFO]	[TRAIN] epoch: 873, iter: 14840/16000, loss: 0.3426, lr: 0.000943, batch_cost: 0.2207, reader_cost: 0.00029, ips: 36.2555 samples/sec | ETA 00:04:15
2023-03-06 20:43:57 [INFO]	[TRAIN] epoch: 874, iter: 14850/16000, loss: 0.1361, lr: 0.000936, batch_cost: 0.2799, reader_cost: 0.05027, ips: 28.5833 samples/sec | ETA 00:05:21
2023-03-06 20:44:00 [INFO]	[TRAIN] epoch: 875, iter: 14860/16000, loss: 0.2189, lr: 0.000929, batch_cost: 0.2703, reader_cost: 0.03829, ips: 29.6001 samples/sec | ETA 00:05:08
2023-03-06 20:44:02 [INFO]	[TRAIN] epoch: 875, iter: 14870/16000, loss: 0.2218, lr: 0.000921, batch_cost: 0.2242, reader_cost: 0.00033, ips: 35.6835 samples/sec | ETA 00:04:13
2023-03-06 20:44:05 [INFO]	[TRAIN] epoch: 876, iter: 14880/16000, loss: 0.2752, lr: 0.000914, batch_cost: 0.2621, reader_cost: 0.04947, ips: 30.5196 samples/sec | ETA 00:04:53
2023-03-06 20:44:07 [INFO]	[TRAIN] epoch: 876, iter: 14890/16000, loss: 0.1865, lr: 0.000907, batch_cost: 0.1887, reader_cost: 0.00030, ips: 42.3854 samples/sec | ETA 00:03:29
2023-03-06 20:44:09 [INFO]	[TRAIN] epoch: 877, iter: 14900/16000, loss: 0.1605, lr: 0.000899, batch_cost: 0.2624, reader_cost: 0.05292, ips: 30.4834 samples/sec | ETA 00:04:48
2023-03-06 20:44:12 [INFO]	[TRAIN] epoch: 878, iter: 14910/16000, loss: 0.1506, lr: 0.000892, batch_cost: 0.2711, reader_cost: 0.03335, ips: 29.5081 samples/sec | ETA 00:04:55
2023-03-06 20:44:14 [INFO]	[TRAIN] epoch: 878, iter: 14920/16000, loss: 0.1861, lr: 0.000885, batch_cost: 0.1859, reader_cost: 0.00028, ips: 43.0266 samples/sec | ETA 00:03:20
2023-03-06 20:44:17 [INFO]	[TRAIN] epoch: 879, iter: 14930/16000, loss: 0.1971, lr: 0.000877, batch_cost: 0.2570, reader_cost: 0.04704, ips: 31.1295 samples/sec | ETA 00:04:34
2023-03-06 20:44:19 [INFO]	[TRAIN] epoch: 879, iter: 14940/16000, loss: 0.1839, lr: 0.000870, batch_cost: 0.2054, reader_cost: 0.00031, ips: 38.9444 samples/sec | ETA 00:03:37
2023-03-06 20:44:21 [INFO]	[TRAIN] epoch: 880, iter: 14950/16000, loss: 0.1496, lr: 0.000862, batch_cost: 0.2639, reader_cost: 0.05390, ips: 30.3191 samples/sec | ETA 00:04:37
2023-03-06 20:44:23 [INFO]	[TRAIN] epoch: 880, iter: 14960/16000, loss: 0.1957, lr: 0.000855, batch_cost: 0.1972, reader_cost: 0.00043, ips: 40.5680 samples/sec | ETA 00:03:25
2023-03-06 20:44:26 [INFO]	[TRAIN] epoch: 881, iter: 14970/16000, loss: 0.2072, lr: 0.000848, batch_cost: 0.2537, reader_cost: 0.04174, ips: 31.5354 samples/sec | ETA 00:04:21
2023-03-06 20:44:28 [INFO]	[TRAIN] epoch: 882, iter: 14980/16000, loss: 0.1697, lr: 0.000840, batch_cost: 0.2468, reader_cost: 0.04334, ips: 32.4206 samples/sec | ETA 00:04:11
2023-03-06 20:44:30 [INFO]	[TRAIN] epoch: 882, iter: 14990/16000, loss: 0.3085, lr: 0.000833, batch_cost: 0.1921, reader_cost: 0.00030, ips: 41.6493 samples/sec | ETA 00:03:14
2023-03-06 20:44:34 [INFO]	[TRAIN] epoch: 883, iter: 15000/16000, loss: 0.2248, lr: 0.000825, batch_cost: 0.3674, reader_cost: 0.07172, ips: 21.7773 samples/sec | ETA 00:06:07
2023-03-06 20:44:34 [INFO]	Start evaluating (total_samples: 119, total_iters: 60)...
60/60 - 6s - batch_cost: 0.1005 - reader cost: 0.0023
2023-03-06 20:44:40 [INFO]	[EVAL] #Images: 119 mIoU: 0.7902 Acc: 0.9354 Kappa: 0.7526 Dice: 0.8763
2023-03-06 20:44:40 [INFO]	[EVAL] Class IoU: 
[0.9264 0.6539]
2023-03-06 20:44:40 [INFO]	[EVAL] Class Precision: 
[0.9685 0.762 ]
2023-03-06 20:44:40 [INFO]	[EVAL] Class Recall: 
[0.9552 0.8217]
2023-03-06 20:44:41 [INFO]	[EVAL] The model with the best validation mIoU (0.7902) was saved at iter 15000.
2023-03-06 20:44:45 [INFO]	[TRAIN] epoch: 883, iter: 15010/16000, loss: 0.2260, lr: 0.000818, batch_cost: 0.3097, reader_cost: 0.00271, ips: 25.8297 samples/sec | ETA 00:05:06
2023-03-06 20:44:48 [INFO]	[TRAIN] epoch: 884, iter: 15020/16000, loss: 0.2771, lr: 0.000811, batch_cost: 0.2962, reader_cost: 0.06614, ips: 27.0068 samples/sec | ETA 00:04:50
2023-03-06 20:44:50 [INFO]	[TRAIN] epoch: 885, iter: 15030/16000, loss: 0.1730, lr: 0.000803, batch_cost: 0.2578, reader_cost: 0.05070, ips: 31.0344 samples/sec | ETA 00:04:10
2023-03-06 20:44:52 [INFO]	[TRAIN] epoch: 885, iter: 15040/16000, loss: 0.2060, lr: 0.000796, batch_cost: 0.2070, reader_cost: 0.00031, ips: 38.6554 samples/sec | ETA 00:03:18
2023-03-06 20:44:55 [INFO]	[TRAIN] epoch: 886, iter: 15050/16000, loss: 0.2304, lr: 0.000788, batch_cost: 0.2524, reader_cost: 0.05173, ips: 31.6952 samples/sec | ETA 00:03:59
2023-03-06 20:44:57 [INFO]	[TRAIN] epoch: 886, iter: 15060/16000, loss: 0.2317, lr: 0.000781, batch_cost: 0.1900, reader_cost: 0.00033, ips: 42.1006 samples/sec | ETA 00:02:58
2023-03-06 20:44:59 [INFO]	[TRAIN] epoch: 887, iter: 15070/16000, loss: 0.2502, lr: 0.000773, batch_cost: 0.2602, reader_cost: 0.03886, ips: 30.7401 samples/sec | ETA 00:04:02
2023-03-06 20:45:02 [INFO]	[TRAIN] epoch: 888, iter: 15080/16000, loss: 0.1831, lr: 0.000766, batch_cost: 0.2500, reader_cost: 0.05186, ips: 31.9976 samples/sec | ETA 00:03:50
2023-03-06 20:45:04 [INFO]	[TRAIN] epoch: 888, iter: 15090/16000, loss: 0.2572, lr: 0.000758, batch_cost: 0.1899, reader_cost: 0.00033, ips: 42.1333 samples/sec | ETA 00:02:52
2023-03-06 20:45:06 [INFO]	[TRAIN] epoch: 889, iter: 15100/16000, loss: 0.1801, lr: 0.000751, batch_cost: 0.2393, reader_cost: 0.03706, ips: 33.4371 samples/sec | ETA 00:03:35
2023-03-06 20:45:08 [INFO]	[TRAIN] epoch: 889, iter: 15110/16000, loss: 0.1722, lr: 0.000743, batch_cost: 0.1892, reader_cost: 0.00030, ips: 42.2834 samples/sec | ETA 00:02:48
2023-03-06 20:45:11 [INFO]	[TRAIN] epoch: 890, iter: 15120/16000, loss: 0.1685, lr: 0.000736, batch_cost: 0.2617, reader_cost: 0.05544, ips: 30.5702 samples/sec | ETA 00:03:50
2023-03-06 20:45:12 [INFO]	[TRAIN] epoch: 890, iter: 15130/16000, loss: 0.2262, lr: 0.000728, batch_cost: 0.1908, reader_cost: 0.00027, ips: 41.9332 samples/sec | ETA 00:02:45
2023-03-06 20:45:15 [INFO]	[TRAIN] epoch: 891, iter: 15140/16000, loss: 0.2329, lr: 0.000721, batch_cost: 0.2730, reader_cost: 0.04033, ips: 29.3060 samples/sec | ETA 00:03:54
2023-03-06 20:45:18 [INFO]	[TRAIN] epoch: 892, iter: 15150/16000, loss: 0.1672, lr: 0.000713, batch_cost: 0.2753, reader_cost: 0.05286, ips: 29.0596 samples/sec | ETA 00:03:54
2023-03-06 20:45:20 [INFO]	[TRAIN] epoch: 892, iter: 15160/16000, loss: 0.1953, lr: 0.000706, batch_cost: 0.1889, reader_cost: 0.00040, ips: 42.3456 samples/sec | ETA 00:02:38
2023-03-06 20:45:22 [INFO]	[TRAIN] epoch: 893, iter: 15170/16000, loss: 0.1552, lr: 0.000698, batch_cost: 0.2584, reader_cost: 0.04462, ips: 30.9577 samples/sec | ETA 00:03:34
2023-03-06 20:45:24 [INFO]	[TRAIN] epoch: 893, iter: 15180/16000, loss: 0.2067, lr: 0.000691, batch_cost: 0.1891, reader_cost: 0.00033, ips: 42.3152 samples/sec | ETA 00:02:35
2023-03-06 20:45:27 [INFO]	[TRAIN] epoch: 894, iter: 15190/16000, loss: 0.2073, lr: 0.000683, batch_cost: 0.2531, reader_cost: 0.06148, ips: 31.6059 samples/sec | ETA 00:03:25
2023-03-06 20:45:29 [INFO]	[TRAIN] epoch: 895, iter: 15200/16000, loss: 0.1594, lr: 0.000675, batch_cost: 0.2421, reader_cost: 0.03408, ips: 33.0436 samples/sec | ETA 00:03:13
2023-03-06 20:45:31 [INFO]	[TRAIN] epoch: 895, iter: 15210/16000, loss: 0.3164, lr: 0.000668, batch_cost: 0.1900, reader_cost: 0.00034, ips: 42.1136 samples/sec | ETA 00:02:30
2023-03-06 20:45:34 [INFO]	[TRAIN] epoch: 896, iter: 15220/16000, loss: 0.1867, lr: 0.000660, batch_cost: 0.2517, reader_cost: 0.05371, ips: 31.7807 samples/sec | ETA 00:03:16
2023-03-06 20:45:36 [INFO]	[TRAIN] epoch: 896, iter: 15230/16000, loss: 0.1411, lr: 0.000653, batch_cost: 0.1973, reader_cost: 0.00028, ips: 40.5454 samples/sec | ETA 00:02:31
2023-03-06 20:45:38 [INFO]	[TRAIN] epoch: 897, iter: 15240/16000, loss: 0.2288, lr: 0.000645, batch_cost: 0.2390, reader_cost: 0.04099, ips: 33.4673 samples/sec | ETA 00:03:01
2023-03-06 20:45:40 [INFO]	[TRAIN] epoch: 898, iter: 15250/16000, loss: 0.2864, lr: 0.000637, batch_cost: 0.2336, reader_cost: 0.04038, ips: 34.2489 samples/sec | ETA 00:02:55
2023-03-06 20:45:42 [INFO]	[TRAIN] epoch: 898, iter: 15260/16000, loss: 0.2909, lr: 0.000630, batch_cost: 0.1852, reader_cost: 0.00029, ips: 43.2072 samples/sec | ETA 00:02:17
2023-03-06 20:45:45 [INFO]	[TRAIN] epoch: 899, iter: 15270/16000, loss: 0.1656, lr: 0.000622, batch_cost: 0.2423, reader_cost: 0.04065, ips: 33.0164 samples/sec | ETA 00:02:56
2023-03-06 20:45:47 [INFO]	[TRAIN] epoch: 899, iter: 15280/16000, loss: 0.2791, lr: 0.000614, batch_cost: 0.1921, reader_cost: 0.00028, ips: 41.6554 samples/sec | ETA 00:02:18
2023-03-06 20:45:49 [INFO]	[TRAIN] epoch: 900, iter: 15290/16000, loss: 0.2383, lr: 0.000607, batch_cost: 0.2494, reader_cost: 0.04912, ips: 32.0789 samples/sec | ETA 00:02:57
2023-03-06 20:45:51 [INFO]	[TRAIN] epoch: 900, iter: 15300/16000, loss: 0.2134, lr: 0.000599, batch_cost: 0.1930, reader_cost: 0.00029, ips: 41.4424 samples/sec | ETA 00:02:15
2023-03-06 20:45:53 [INFO]	[TRAIN] epoch: 901, iter: 15310/16000, loss: 0.2138, lr: 0.000591, batch_cost: 0.2485, reader_cost: 0.04177, ips: 32.1940 samples/sec | ETA 00:02:51
2023-03-06 20:45:56 [INFO]	[TRAIN] epoch: 902, iter: 15320/16000, loss: 0.2530, lr: 0.000584, batch_cost: 0.2620, reader_cost: 0.05497, ips: 30.5305 samples/sec | ETA 00:02:58
2023-03-06 20:45:58 [INFO]	[TRAIN] epoch: 902, iter: 15330/16000, loss: 0.1626, lr: 0.000576, batch_cost: 0.1862, reader_cost: 0.00028, ips: 42.9687 samples/sec | ETA 00:02:04
2023-03-06 20:46:00 [INFO]	[TRAIN] epoch: 903, iter: 15340/16000, loss: 0.1581, lr: 0.000568, batch_cost: 0.2516, reader_cost: 0.04380, ips: 31.7968 samples/sec | ETA 00:02:46
2023-03-06 20:46:02 [INFO]	[TRAIN] epoch: 903, iter: 15350/16000, loss: 0.2080, lr: 0.000560, batch_cost: 0.1904, reader_cost: 0.00035, ips: 42.0110 samples/sec | ETA 00:02:03
2023-03-06 20:46:05 [INFO]	[TRAIN] epoch: 904, iter: 15360/16000, loss: 0.2534, lr: 0.000553, batch_cost: 0.2616, reader_cost: 0.05489, ips: 30.5789 samples/sec | ETA 00:02:47
2023-03-06 20:46:07 [INFO]	[TRAIN] epoch: 905, iter: 15370/16000, loss: 0.1992, lr: 0.000545, batch_cost: 0.2367, reader_cost: 0.04285, ips: 33.7915 samples/sec | ETA 00:02:29
2023-03-06 20:46:09 [INFO]	[TRAIN] epoch: 905, iter: 15380/16000, loss: 0.2051, lr: 0.000537, batch_cost: 0.1857, reader_cost: 0.00030, ips: 43.0863 samples/sec | ETA 00:01:55
2023-03-06 20:46:12 [INFO]	[TRAIN] epoch: 906, iter: 15390/16000, loss: 0.2016, lr: 0.000529, batch_cost: 0.2739, reader_cost: 0.03820, ips: 29.2092 samples/sec | ETA 00:02:47
2023-03-06 20:46:14 [INFO]	[TRAIN] epoch: 906, iter: 15400/16000, loss: 0.1980, lr: 0.000522, batch_cost: 0.2151, reader_cost: 0.00026, ips: 37.1994 samples/sec | ETA 00:02:09
2023-03-06 20:46:17 [INFO]	[TRAIN] epoch: 907, iter: 15410/16000, loss: 0.2154, lr: 0.000514, batch_cost: 0.2473, reader_cost: 0.04826, ips: 32.3522 samples/sec | ETA 00:02:25
2023-03-06 20:46:19 [INFO]	[TRAIN] epoch: 908, iter: 15420/16000, loss: 0.1942, lr: 0.000506, batch_cost: 0.2398, reader_cost: 0.04732, ips: 33.3663 samples/sec | ETA 00:02:19
2023-03-06 20:46:21 [INFO]	[TRAIN] epoch: 908, iter: 15430/16000, loss: 0.1869, lr: 0.000498, batch_cost: 0.1901, reader_cost: 0.00030, ips: 42.0760 samples/sec | ETA 00:01:48
2023-03-06 20:46:23 [INFO]	[TRAIN] epoch: 909, iter: 15440/16000, loss: 0.1619, lr: 0.000490, batch_cost: 0.2461, reader_cost: 0.05065, ips: 32.5075 samples/sec | ETA 00:02:17
2023-03-06 20:46:25 [INFO]	[TRAIN] epoch: 909, iter: 15450/16000, loss: 0.1754, lr: 0.000482, batch_cost: 0.1874, reader_cost: 0.00029, ips: 42.6811 samples/sec | ETA 00:01:43
2023-03-06 20:46:28 [INFO]	[TRAIN] epoch: 910, iter: 15460/16000, loss: 0.2319, lr: 0.000474, batch_cost: 0.2482, reader_cost: 0.04305, ips: 32.2339 samples/sec | ETA 00:02:14
2023-03-06 20:46:30 [INFO]	[TRAIN] epoch: 910, iter: 15470/16000, loss: 0.1713, lr: 0.000467, batch_cost: 0.1913, reader_cost: 0.00027, ips: 41.8224 samples/sec | ETA 00:01:41
2023-03-06 20:46:32 [INFO]	[TRAIN] epoch: 911, iter: 15480/16000, loss: 0.1700, lr: 0.000459, batch_cost: 0.2588, reader_cost: 0.04877, ips: 30.9136 samples/sec | ETA 00:02:14
2023-03-06 20:46:35 [INFO]	[TRAIN] epoch: 912, iter: 15490/16000, loss: 0.1405, lr: 0.000451, batch_cost: 0.2567, reader_cost: 0.05786, ips: 31.1616 samples/sec | ETA 00:02:10
2023-03-06 20:46:37 [INFO]	[TRAIN] epoch: 912, iter: 15500/16000, loss: 0.2878, lr: 0.000443, batch_cost: 0.1901, reader_cost: 0.00031, ips: 42.0765 samples/sec | ETA 00:01:35
2023-03-06 20:46:39 [INFO]	[TRAIN] epoch: 913, iter: 15510/16000, loss: 0.1867, lr: 0.000435, batch_cost: 0.2480, reader_cost: 0.04928, ips: 32.2620 samples/sec | ETA 00:02:01
2023-03-06 20:46:41 [INFO]	[TRAIN] epoch: 913, iter: 15520/16000, loss: 0.1868, lr: 0.000427, batch_cost: 0.1941, reader_cost: 0.00029, ips: 41.2238 samples/sec | ETA 00:01:33
2023-03-06 20:46:44 [INFO]	[TRAIN] epoch: 914, iter: 15530/16000, loss: 0.1408, lr: 0.000419, batch_cost: 0.2579, reader_cost: 0.03958, ips: 31.0193 samples/sec | ETA 00:02:01
2023-03-06 20:46:46 [INFO]	[TRAIN] epoch: 915, iter: 15540/16000, loss: 0.3056, lr: 0.000411, batch_cost: 0.2629, reader_cost: 0.05929, ips: 30.4311 samples/sec | ETA 00:02:00
2023-03-06 20:46:48 [INFO]	[TRAIN] epoch: 915, iter: 15550/16000, loss: 0.1989, lr: 0.000403, batch_cost: 0.1871, reader_cost: 0.00026, ips: 42.7654 samples/sec | ETA 00:01:24
2023-03-06 20:46:51 [INFO]	[TRAIN] epoch: 916, iter: 15560/16000, loss: 0.1649, lr: 0.000395, batch_cost: 0.2557, reader_cost: 0.05691, ips: 31.2887 samples/sec | ETA 00:01:52
2023-03-06 20:46:53 [INFO]	[TRAIN] epoch: 916, iter: 15570/16000, loss: 0.2474, lr: 0.000387, batch_cost: 0.2163, reader_cost: 0.00030, ips: 36.9797 samples/sec | ETA 00:01:33
2023-03-06 20:46:56 [INFO]	[TRAIN] epoch: 917, iter: 15580/16000, loss: 0.2070, lr: 0.000379, batch_cost: 0.2773, reader_cost: 0.05250, ips: 28.8482 samples/sec | ETA 00:01:56
2023-03-06 20:46:58 [INFO]	[TRAIN] epoch: 918, iter: 15590/16000, loss: 0.2126, lr: 0.000370, batch_cost: 0.2785, reader_cost: 0.04612, ips: 28.7220 samples/sec | ETA 00:01:54
2023-03-06 20:47:01 [INFO]	[TRAIN] epoch: 918, iter: 15600/16000, loss: 0.2072, lr: 0.000362, batch_cost: 0.2179, reader_cost: 0.00036, ips: 36.7153 samples/sec | ETA 00:01:27
2023-03-06 20:47:03 [INFO]	[TRAIN] epoch: 919, iter: 15610/16000, loss: 0.1781, lr: 0.000354, batch_cost: 0.2815, reader_cost: 0.05677, ips: 28.4233 samples/sec | ETA 00:01:49
2023-03-06 20:47:06 [INFO]	[TRAIN] epoch: 919, iter: 15620/16000, loss: 0.1537, lr: 0.000346, batch_cost: 0.2110, reader_cost: 0.00029, ips: 37.9110 samples/sec | ETA 00:01:20
2023-03-06 20:47:08 [INFO]	[TRAIN] epoch: 920, iter: 15630/16000, loss: 0.1828, lr: 0.000338, batch_cost: 0.2382, reader_cost: 0.04327, ips: 33.5871 samples/sec | ETA 00:01:28
2023-03-06 20:47:10 [INFO]	[TRAIN] epoch: 920, iter: 15640/16000, loss: 0.2129, lr: 0.000330, batch_cost: 0.1877, reader_cost: 0.00024, ips: 42.6295 samples/sec | ETA 00:01:07
2023-03-06 20:47:13 [INFO]	[TRAIN] epoch: 921, iter: 15650/16000, loss: 0.2098, lr: 0.000321, batch_cost: 0.2665, reader_cost: 0.06225, ips: 30.0146 samples/sec | ETA 00:01:33
2023-03-06 20:47:15 [INFO]	[TRAIN] epoch: 922, iter: 15660/16000, loss: 0.1618, lr: 0.000313, batch_cost: 0.2587, reader_cost: 0.05655, ips: 30.9292 samples/sec | ETA 00:01:27
2023-03-06 20:47:17 [INFO]	[TRAIN] epoch: 922, iter: 15670/16000, loss: 0.1641, lr: 0.000305, batch_cost: 0.2034, reader_cost: 0.00029, ips: 39.3300 samples/sec | ETA 00:01:07
2023-03-06 20:47:20 [INFO]	[TRAIN] epoch: 923, iter: 15680/16000, loss: 0.1767, lr: 0.000297, batch_cost: 0.2600, reader_cost: 0.05529, ips: 30.7679 samples/sec | ETA 00:01:23
2023-03-06 20:47:22 [INFO]	[TRAIN] epoch: 923, iter: 15690/16000, loss: 0.1406, lr: 0.000288, batch_cost: 0.1860, reader_cost: 0.00037, ips: 42.9996 samples/sec | ETA 00:00:57
2023-03-06 20:47:24 [INFO]	[TRAIN] epoch: 924, iter: 15700/16000, loss: 0.2010, lr: 0.000280, batch_cost: 0.2539, reader_cost: 0.04669, ips: 31.5082 samples/sec | ETA 00:01:16
2023-03-06 20:47:27 [INFO]	[TRAIN] epoch: 925, iter: 15710/16000, loss: 0.2393, lr: 0.000272, batch_cost: 0.2392, reader_cost: 0.04287, ips: 33.4451 samples/sec | ETA 00:01:09
2023-03-06 20:47:28 [INFO]	[TRAIN] epoch: 925, iter: 15720/16000, loss: 0.1594, lr: 0.000263, batch_cost: 0.1855, reader_cost: 0.00027, ips: 43.1178 samples/sec | ETA 00:00:51
2023-03-06 20:47:31 [INFO]	[TRAIN] epoch: 926, iter: 15730/16000, loss: 0.2569, lr: 0.000255, batch_cost: 0.2481, reader_cost: 0.04482, ips: 32.2484 samples/sec | ETA 00:01:06
2023-03-06 20:47:33 [INFO]	[TRAIN] epoch: 926, iter: 15740/16000, loss: 0.1764, lr: 0.000246, batch_cost: 0.1863, reader_cost: 0.00024, ips: 42.9457 samples/sec | ETA 00:00:48
2023-03-06 20:47:36 [INFO]	[TRAIN] epoch: 927, iter: 15750/16000, loss: 0.2175, lr: 0.000238, batch_cost: 0.2850, reader_cost: 0.04135, ips: 28.0733 samples/sec | ETA 00:01:11
2023-03-06 20:47:38 [INFO]	[TRAIN] epoch: 928, iter: 15760/16000, loss: 0.2386, lr: 0.000229, batch_cost: 0.2645, reader_cost: 0.04177, ips: 30.2444 samples/sec | ETA 00:01:03
2023-03-06 20:47:40 [INFO]	[TRAIN] epoch: 928, iter: 15770/16000, loss: 0.1917, lr: 0.000221, batch_cost: 0.1931, reader_cost: 0.00028, ips: 41.4224 samples/sec | ETA 00:00:44
2023-03-06 20:47:43 [INFO]	[TRAIN] epoch: 929, iter: 15780/16000, loss: 0.2876, lr: 0.000212, batch_cost: 0.2593, reader_cost: 0.05243, ips: 30.8576 samples/sec | ETA 00:00:57
2023-03-06 20:47:45 [INFO]	[TRAIN] epoch: 929, iter: 15790/16000, loss: 0.2084, lr: 0.000203, batch_cost: 0.1918, reader_cost: 0.00028, ips: 41.7117 samples/sec | ETA 00:00:40
2023-03-06 20:47:47 [INFO]	[TRAIN] epoch: 930, iter: 15800/16000, loss: 0.2078, lr: 0.000195, batch_cost: 0.2391, reader_cost: 0.03889, ips: 33.4654 samples/sec | ETA 00:00:47
2023-03-06 20:47:49 [INFO]	[TRAIN] epoch: 930, iter: 15810/16000, loss: 0.1412, lr: 0.000186, batch_cost: 0.1849, reader_cost: 0.00030, ips: 43.2567 samples/sec | ETA 00:00:35
2023-03-06 20:47:52 [INFO]	[TRAIN] epoch: 931, iter: 15820/16000, loss: 0.1830, lr: 0.000177, batch_cost: 0.2667, reader_cost: 0.04522, ips: 30.0011 samples/sec | ETA 00:00:47
2023-03-06 20:47:54 [INFO]	[TRAIN] epoch: 932, iter: 15830/16000, loss: 0.2646, lr: 0.000168, batch_cost: 0.2385, reader_cost: 0.03804, ips: 33.5439 samples/sec | ETA 00:00:40
2023-03-06 20:47:56 [INFO]	[TRAIN] epoch: 932, iter: 15840/16000, loss: 0.2048, lr: 0.000159, batch_cost: 0.1892, reader_cost: 0.00025, ips: 42.2904 samples/sec | ETA 00:00:30
2023-03-06 20:47:58 [INFO]	[TRAIN] epoch: 933, iter: 15850/16000, loss: 0.1529, lr: 0.000150, batch_cost: 0.2430, reader_cost: 0.04637, ips: 32.9239 samples/sec | ETA 00:00:36
2023-03-06 20:48:00 [INFO]	[TRAIN] epoch: 933, iter: 15860/16000, loss: 0.2499, lr: 0.000141, batch_cost: 0.1916, reader_cost: 0.00024, ips: 41.7485 samples/sec | ETA 00:00:26
2023-03-06 20:48:03 [INFO]	[TRAIN] epoch: 934, iter: 15870/16000, loss: 0.2022, lr: 0.000132, batch_cost: 0.2554, reader_cost: 0.04554, ips: 31.3214 samples/sec | ETA 00:00:33
2023-03-06 20:48:06 [INFO]	[TRAIN] epoch: 935, iter: 15880/16000, loss: 0.1918, lr: 0.000123, batch_cost: 0.2821, reader_cost: 0.04508, ips: 28.3598 samples/sec | ETA 00:00:33
2023-03-06 20:48:08 [INFO]	[TRAIN] epoch: 935, iter: 15890/16000, loss: 0.1887, lr: 0.000114, batch_cost: 0.2027, reader_cost: 0.00027, ips: 39.4608 samples/sec | ETA 00:00:22
2023-03-06 20:48:10 [INFO]	[TRAIN] epoch: 936, iter: 15900/16000, loss: 0.2632, lr: 0.000105, batch_cost: 0.2530, reader_cost: 0.06058, ips: 31.6191 samples/sec | ETA 00:00:25
2023-03-06 20:48:12 [INFO]	[TRAIN] epoch: 936, iter: 15910/16000, loss: 0.2172, lr: 0.000095, batch_cost: 0.1880, reader_cost: 0.00025, ips: 42.5629 samples/sec | ETA 00:00:16
2023-03-06 20:48:15 [INFO]	[TRAIN] epoch: 937, iter: 15920/16000, loss: 0.2130, lr: 0.000086, batch_cost: 0.2528, reader_cost: 0.04793, ips: 31.6499 samples/sec | ETA 00:00:20
2023-03-06 20:48:17 [INFO]	[TRAIN] epoch: 938, iter: 15930/16000, loss: 0.2277, lr: 0.000076, batch_cost: 0.2529, reader_cost: 0.04563, ips: 31.6368 samples/sec | ETA 00:00:17
2023-03-06 20:48:19 [INFO]	[TRAIN] epoch: 938, iter: 15940/16000, loss: 0.1479, lr: 0.000067, batch_cost: 0.1961, reader_cost: 0.00033, ips: 40.7900 samples/sec | ETA 00:00:11
2023-03-06 20:48:22 [INFO]	[TRAIN] epoch: 939, iter: 15950/16000, loss: 0.2496, lr: 0.000057, batch_cost: 0.2475, reader_cost: 0.04462, ips: 32.3230 samples/sec | ETA 00:00:12
2023-03-06 20:48:23 [INFO]	[TRAIN] epoch: 939, iter: 15960/16000, loss: 0.2454, lr: 0.000047, batch_cost: 0.1822, reader_cost: 0.00026, ips: 43.9008 samples/sec | ETA 00:00:07
2023-03-06 20:48:26 [INFO]	[TRAIN] epoch: 940, iter: 15970/16000, loss: 0.1467, lr: 0.000036, batch_cost: 0.2406, reader_cost: 0.04142, ips: 33.2563 samples/sec | ETA 00:00:07
2023-03-06 20:48:28 [INFO]	[TRAIN] epoch: 940, iter: 15980/16000, loss: 0.1595, lr: 0.000025, batch_cost: 0.1884, reader_cost: 0.00028, ips: 42.4641 samples/sec | ETA 00:00:03
2023-03-06 20:48:30 [INFO]	[TRAIN] epoch: 941, iter: 15990/16000, loss: 0.1734, lr: 0.000014, batch_cost: 0.2485, reader_cost: 0.04640, ips: 32.1876 samples/sec | ETA 00:00:02
2023-03-06 20:48:33 [INFO]	[TRAIN] epoch: 942, iter: 16000/16000, loss: 0.2076, lr: 0.000002, batch_cost: 0.2498, reader_cost: 0.04117, ips: 32.0206 samples/sec | ETA 00:00:00
2023-03-06 20:48:33 [INFO]	Start evaluating (total_samples: 119, total_iters: 60)...
60/60 - 3s - batch_cost: 0.0537 - reader cost: 0.0022
2023-03-06 20:48:36 [INFO]	[EVAL] #Images: 119 mIoU: 0.7934 Acc: 0.9363 Kappa: 0.7571 Dice: 0.8785
2023-03-06 20:48:36 [INFO]	[EVAL] Class IoU: 
[0.9273 0.6594]
2023-03-06 20:48:36 [INFO]	[EVAL] Class Precision: 
[0.97  0.762]
2023-03-06 20:48:36 [INFO]	[EVAL] Class Recall: 
[0.9548 0.8305]
2023-03-06 20:48:37 [INFO]	[EVAL] The model with the best validation mIoU (0.7934) was saved at iter 16000.
<class 'paddle.nn.layer.conv.Conv2D'>'s flops has been counted
Customize Function has been applied to <class 'paddle.nn.layer.norm.SyncBatchNorm'>
<class 'paddle.nn.layer.activation.ReLU'>'s flops has been counted
Cannot find suitable count function for <class 'paddleseg.models.layers.wrap_functions.Add'>. Treat it as zero FLOPs.
Cannot find suitable count function for <class 'paddle.nn.layer.common.Identity'>. Treat it as zero FLOPs.
Cannot find suitable count function for <class 'paddleseg.models.ocrnet.SpatialGatherBlock'>. Treat it as zero FLOPs.
Cannot find suitable count function for <class 'paddle.nn.layer.common.Dropout2D'>. Treat it as zero FLOPs.
Total Flops: 743414146     Total Params: 12109902
I0306 20:48:40.316507 24025 tcp_store.cc:257] receive shutdown event and so quit from MasterDaemon run loop
